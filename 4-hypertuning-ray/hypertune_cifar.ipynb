{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62314dbc",
   "metadata": {},
   "source": [
    "# Hypertune cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "518083dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = (\"data/raw/cifar10/\")\n",
    "TUNEDIR = (\"hypertune\")\n",
    "from loguru import logger\n",
    "import ray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db2c8596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import datasets, transforms\n",
    "# from loguru import logger\n",
    "from pathlib import Path\n",
    "\n",
    "# # Ensure the data directory exists before downloading dataset\n",
    "data_dir = Path(DATADIR).resolve()\n",
    "if not data_dir.exists():\n",
    "    data_dir.mkdir(parents=True)\n",
    "    logger.info(f\"Created {data_dir}\")\n",
    "\n",
    "tune_dir = Path(TUNEDIR).resolve()\n",
    "if not tune_dir.exists():\n",
    "    tune_dir.mkdir(parents=True)\n",
    "    logger.info(f\"Created {tune_dir}\")\n",
    "\n",
    "# # Create transformer to convert images to tensors\n",
    "# transformer = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# # Download CIFAR10 dataset\n",
    "# train_dataset = datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transformer)\n",
    "# test_dataset = datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transformer)\n",
    "\n",
    "# logger.info(\n",
    "#     f\"Dataset is now available:\\n\"\n",
    "#     f\"TRAIN: {train_dataset}\\n\"\n",
    "#     f\"TEST: {test_dataset}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85bd31bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d8454e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # Create data loaders for training and testing\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# # Inspect the shape of a batch of training data\n",
    "# for images, labels in train_loader:\n",
    "#     logger.info(f\"Image batch dimensions: {images.shape}\")\n",
    "#     logger.info(f\"Image label dimensions: {labels.shape}\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dee91836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(batch_size, data_dir):\n",
    "    from filelock import FileLock\n",
    "    from torchvision import datasets, transforms\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    with FileLock(data_dir / \".lock\"):\n",
    "        # Create transformer to convert images to tensors\n",
    "        transformer = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "        # Download CIFAR10 dataset\n",
    "        train_dataset = datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transformer, )\n",
    "        test_dataset = datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transformer)\n",
    "\n",
    "        # Create data loaders for training and testing\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def get_data_loaders_transforms(batch_size, data_dir):\n",
    "    from filelock import FileLock\n",
    "    from torchvision import datasets, transforms\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    with FileLock(data_dir / \".lock\"):\n",
    "        # Create transformer to convert images to tensors\n",
    "        transformer = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),  # random zoom\n",
    "            transforms.RandomHorizontalFlip(),                   # random flip\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "        # Download CIFAR10 dataset\n",
    "        train_dataset = datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transformer, )\n",
    "        test_dataset = datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transformer)\n",
    "\n",
    "        # Create data loaders for training and testing\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0ecbf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "config = {\n",
    "    # Fixed parameters\n",
    "    \"epochs\": 5,\n",
    "    \"data_dir\": Path(DATADIR).resolve(),\n",
    "    \"batch_size\": 64,\n",
    "    \"input_size\": 3,\n",
    "    \"output_size\": 20,\n",
    "    \"hidden_size\": 128,\n",
    "    \"dropout\": 0,\n",
    "    \"num_layers\": 5,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"loss_fn\": torch.nn.CrossEntropyLoss(), # suitable for multi-class classification\n",
    "    \"optimizer\": torch.optim.Adam,\n",
    "    # \"scheduler\": torch.optim.lr_scheduler.LRScheduler,\n",
    "    \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"metrics\": \"accuracy\",\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\", \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dabab42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Flatten: 1-1                           [-1, 3072]                --\n",
      "├─Linear: 1-2                            [-1, 128]                 393,344\n",
      "├─ReLU: 1-3                              [-1, 128]                 --\n",
      "├─Dropout: 1-4                           [-1, 128]                 --\n",
      "├─Linear: 1-5                            [-1, 128]                 16,512\n",
      "├─ReLU: 1-6                              [-1, 128]                 --\n",
      "├─Dropout: 1-7                           [-1, 128]                 --\n",
      "├─Linear: 1-8                            [-1, 128]                 16,512\n",
      "├─ReLU: 1-9                              [-1, 128]                 --\n",
      "├─Dropout: 1-10                          [-1, 128]                 --\n",
      "├─Linear: 1-11                           [-1, 128]                 16,512\n",
      "├─ReLU: 1-12                             [-1, 128]                 --\n",
      "├─Dropout: 1-13                          [-1, 128]                 --\n",
      "├─Linear: 1-14                           [-1, 128]                 16,512\n",
      "├─ReLU: 1-15                             [-1, 128]                 --\n",
      "├─Dropout: 1-16                          [-1, 128]                 --\n",
      "├─Linear: 1-17                           [-1, 20]                  2,580\n",
      "==========================================================================================\n",
      "Total params: 461,972\n",
      "Trainable params: 461,972\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.46\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 1.76\n",
      "Estimated Total Size (MB): 1.78\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Flatten: 1-1                           [-1, 3072]                --\n",
      "├─Linear: 1-2                            [-1, 128]                 393,344\n",
      "├─ReLU: 1-3                              [-1, 128]                 --\n",
      "├─Dropout: 1-4                           [-1, 128]                 --\n",
      "├─ResidualBlock: 1-5                     [-1, 128]                 --\n",
      "|    └─Sequential: 2-1                   [-1, 128]                 --\n",
      "|    |    └─Linear: 3-1                  [-1, 128]                 16,512\n",
      "|    |    └─ReLU: 3-2                    [-1, 128]                 --\n",
      "|    |    └─Dropout: 3-3                 [-1, 128]                 --\n",
      "├─ResidualBlock: 1-6                     [-1, 128]                 --\n",
      "|    └─Sequential: 2-2                   [-1, 128]                 --\n",
      "|    |    └─Linear: 3-4                  [-1, 128]                 16,512\n",
      "|    |    └─ReLU: 3-5                    [-1, 128]                 --\n",
      "|    |    └─Dropout: 3-6                 [-1, 128]                 --\n",
      "├─ResidualBlock: 1-7                     [-1, 128]                 --\n",
      "|    └─Sequential: 2-3                   [-1, 128]                 --\n",
      "|    |    └─Linear: 3-7                  [-1, 128]                 16,512\n",
      "|    |    └─ReLU: 3-8                    [-1, 128]                 --\n",
      "|    |    └─Dropout: 3-9                 [-1, 128]                 --\n",
      "├─ResidualBlock: 1-8                     [-1, 128]                 --\n",
      "|    └─Sequential: 2-4                   [-1, 128]                 --\n",
      "|    |    └─Linear: 3-10                 [-1, 128]                 16,512\n",
      "|    |    └─ReLU: 3-11                   [-1, 128]                 --\n",
      "|    |    └─Dropout: 3-12                [-1, 128]                 --\n",
      "├─Linear: 1-9                            [-1, 20]                  2,580\n",
      "==========================================================================================\n",
      "Total params: 461,972\n",
      "Trainable params: 461,972\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.59\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 1.76\n",
      "Estimated Total Size (MB): 1.78\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Flatten: 1-1                           [-1, 3072]                --\n",
      "├─Linear: 1-2                            [-1, 128]                 393,344\n",
      "├─BatchNorm1d: 1-3                       [-1, 128]                 256\n",
      "├─ReLU: 1-4                              [-1, 128]                 --\n",
      "├─Dropout: 1-5                           [-1, 128]                 --\n",
      "├─Linear: 1-6                            [-1, 128]                 16,512\n",
      "├─BatchNorm1d: 1-7                       [-1, 128]                 256\n",
      "├─ReLU: 1-8                              [-1, 128]                 --\n",
      "├─Dropout: 1-9                           [-1, 128]                 --\n",
      "├─Linear: 1-10                           [-1, 128]                 16,512\n",
      "├─BatchNorm1d: 1-11                      [-1, 128]                 256\n",
      "├─ReLU: 1-12                             [-1, 128]                 --\n",
      "├─Dropout: 1-13                          [-1, 128]                 --\n",
      "├─Linear: 1-14                           [-1, 128]                 16,512\n",
      "├─BatchNorm1d: 1-15                      [-1, 128]                 256\n",
      "├─ReLU: 1-16                             [-1, 128]                 --\n",
      "├─Dropout: 1-17                          [-1, 128]                 --\n",
      "├─Linear: 1-18                           [-1, 128]                 16,512\n",
      "├─BatchNorm1d: 1-19                      [-1, 128]                 256\n",
      "├─ReLU: 1-20                             [-1, 128]                 --\n",
      "├─Dropout: 1-21                          [-1, 128]                 --\n",
      "├─Linear: 1-22                           [-1, 20]                  2,580\n",
      "==========================================================================================\n",
      "Total params: 463,252\n",
      "Trainable params: 463,252\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.46\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 1.77\n",
      "Estimated Total Size (MB): 1.79\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Setup for simple neural network with learning curve plotting\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple feedforward neural network for image classification.\n",
    "\n",
    "    Args:\n",
    "        input_size (int): Number of input channels (e.g., 3 for RGB images).\n",
    "        hidden_size (int): Number of units in hidden layers.\n",
    "        output_size (int): Number of output classes.\n",
    "        dropout (float): Dropout probability for regularization.\n",
    "        num_layers (int): Number of hidden layers.\n",
    "\n",
    "    Methods:\n",
    "        forward(x): Forward pass through the network.\n",
    "        summary(): Prints a summary of the network architecture.\n",
    "        plot_learning_curve(): Plots the learning curve (loss and accuracy).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout, num_layers, use_residual=False, use_batchnorm=False):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.use_residual = use_residual\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        # For learning curve\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "\n",
    "        layers = []\n",
    "        # Flatten input image\n",
    "        layers.append(nn.Flatten())\n",
    "        # First linear layer from input to hidden\n",
    "        layers.append(nn.Linear(input_size * 32 * 32, hidden_size))\n",
    "        if self.use_batchnorm:\n",
    "            layers.append(nn.BatchNorm1d(hidden_size))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # Additional hidden layers with optional residual and batchnorm\n",
    "        for i in range(num_layers - 1):\n",
    "            linear = nn.Linear(hidden_size, hidden_size)\n",
    "            block = [linear]\n",
    "            if self.use_batchnorm:\n",
    "                block.append(nn.BatchNorm1d(hidden_size))\n",
    "            block.append(nn.ReLU())\n",
    "            block.append(nn.Dropout(dropout))\n",
    "            if self.use_residual:\n",
    "                # Residual block as a custom nn.Module\n",
    "                block = [ResidualBlock(hidden_size, block)]\n",
    "            layers.extend(block)\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(hidden_size, output_size))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, input_size, 32, 32).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output logits.\n",
    "        \"\"\"\n",
    "        return self.network(x) \n",
    "\n",
    "    def summary(self):\n",
    "        \"\"\"\n",
    "        Prints a summary of the network architecture using torchsummary.\n",
    "        \"\"\"\n",
    "        summary(self.network, (self.input_size, 32, 32))\n",
    "\n",
    "    def plot_learning_curve(self):\n",
    "        \"\"\"\n",
    "        Plots the learning curve (loss and accuracy).\n",
    "        \"\"\"\n",
    "        epochs = range(1, len(self.train_losses) + 1)\n",
    "        fig, ax1 = plt.subplots()\n",
    "        ax1.plot(epochs, self.train_losses, 'b-', label='Train Loss')\n",
    "        ax1.plot(epochs, self.val_losses, 'r-', label='Val Loss')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend(loc='upper left')\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(epochs, self.train_accuracies, 'b--', label='Train Acc')\n",
    "        ax2.plot(epochs, self.val_accuracies, 'r--', label='Val Acc')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.legend(loc='upper right')\n",
    "        plt.title('Learning Curve')\n",
    "        plt.show()\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, hidden_size, block_layers):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(*block_layers)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "\n",
    "model_NN = SimpleNN(\n",
    "    input_size=config[\"input_size\"],\n",
    "    hidden_size=config[\"hidden_size\"],\n",
    "    output_size=config[\"output_size\"],\n",
    "    dropout=config[\"dropout\"],\n",
    "    num_layers=config[\"num_layers\"]\n",
    ")\n",
    "model_NN_with_residual = SimpleNN(\n",
    "    input_size=config[\"input_size\"],\n",
    "    hidden_size=config[\"hidden_size\"],\n",
    "    output_size=config[\"output_size\"],\n",
    "    dropout=config[\"dropout\"],\n",
    "    num_layers=config[\"num_layers\"],\n",
    "    use_residual=True\n",
    ")\n",
    "model_NN_with_batchnorm = SimpleNN(\n",
    "    input_size=config[\"input_size\"],\n",
    "    hidden_size=config[\"hidden_size\"],\n",
    "    output_size=config[\"output_size\"],\n",
    "    dropout=config[\"dropout\"],\n",
    "    num_layers=config[\"num_layers\"],\n",
    "    use_batchnorm=True\n",
    ")\n",
    "\n",
    "# Show a summary of the model architecture\n",
    "model_NN.summary(); model_NN_with_residual.summary(); model_NN_with_batchnorm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ace8f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_one_epoch(model, train_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def evaluate(model, test_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def train_and_evaluate(model, config, logger):\n",
    "    train_loader, test_loader = get_data_loaders(config[\"batch_size\"], config[\"data_dir\"])\n",
    "    device = config[\"device\"]\n",
    "    model.to(device)\n",
    "    optimizer = config[\"optimizer\"](model.parameters(), lr=config[\"learning_rate\"])\n",
    "    loss_fn = config[\"loss_fn\"]\n",
    "    num_epochs = config[\"epochs\"]\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "        val_loss, val_accuracy = evaluate(model, test_loader, loss_fn, device)\n",
    "\n",
    "        model.train_losses.append(train_loss)\n",
    "        model.val_losses.append(val_loss)\n",
    "        model.train_accuracies.append(train_accuracy)\n",
    "        model.val_accuracies.append(val_accuracy)\n",
    "\n",
    "        logger.info(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {val_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Test Acc: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    return model.train_losses[-1], model.val_losses[-1], model.val_accuracies[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d94ffb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_evaluate(model_NN, config, logger)\n",
    "# model_NN.plot_learning_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "222c35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_evaluate(model_NN_with_residual, config, logger)\n",
    "# model_NN_with_residual.plot_learning_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76d423f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_evaluate(model_NN_with_batchnorm, config, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a2783ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mltrainer import Trainer, ReportTypes, TrainerSettings\n",
    "\n",
    "# model_NN2 = SimpleNN(\n",
    "#     input_size=config[\"input_size\"],\n",
    "#     hidden_size=config[\"hidden_size\"],\n",
    "#     output_size=config[\"output_size\"],\n",
    "#     dropout=config[\"dropout\"],\n",
    "#     num_layers=config[\"num_layers\"]\n",
    "# )\n",
    "\n",
    "# model_NN2.to(device)\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model_NN2,\n",
    "#     settings=TrainerSettings(\n",
    "#         epochs=config[\"epochs\"],\n",
    "#         metrics=[config[\"metrics\"]],\n",
    "#         logdir=Path(\"./logs\"),\n",
    "#         train_steps=len(train_loader),\n",
    "#         valid_steps=len(test_loader),\n",
    "#         reporttypes=[ReportTypes.TOML],\n",
    "#         scheduler_kwargs={\"patience\": 5},\n",
    "#         earlystop_kwargs={\"patience\": 5},\n",
    "#     ),\n",
    "#     loss_fn=config[\"loss_fn\"],\n",
    "#     optimizer=torch.optim.Adam,\n",
    "#     traindataloader=train_loader,\n",
    "#     validdataloader=test_loader,\n",
    "#     scheduler=config[\"scheduler\"],\n",
    "#     device=device,\n",
    "# )\n",
    "# trainer.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea6bb182",
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\n",
    "    # Fixed parameters\n",
    "    \"epochs\": 5,\n",
    "    \"data_dir\": Path(DATADIR).resolve(),\n",
    "    \"batch_size\": 64,\n",
    "    \"input_size\": 3,\n",
    "    \"output_size\": 20,\n",
    "    \"hidden_size\": 128,\n",
    "    \"dropout\": 0,\n",
    "    \"num_fully_connected_layers\": 2,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"loss_fn\": torch.nn.CrossEntropyLoss(), # suitable for multi-class classification\n",
    "    \"optimizer\": torch.optim.Adam,\n",
    "    # \"scheduler\": torch.optim.lr_scheduler.LRScheduler,\n",
    "    \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"metrics\": \"accuracy\",\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \n",
    "    # convolutional layer parameters\n",
    "    \"num_conv_layers\": 3,\n",
    "    \"filters\": 64,\n",
    "    \"kernel_size\": 3,\n",
    "    \"stride\": 1,\n",
    "    \"padding\": 1,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8d474d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 64, 32, 32]          1,792\n",
      "├─ReLU: 1-2                              [-1, 64, 32, 32]          --\n",
      "├─MaxPool2d: 1-3                         [-1, 64, 16, 16]          --\n",
      "├─Conv2d: 1-4                            [-1, 64, 16, 16]          36,928\n",
      "├─ReLU: 1-5                              [-1, 64, 16, 16]          --\n",
      "├─MaxPool2d: 1-6                         [-1, 64, 8, 8]            --\n",
      "├─Conv2d: 1-7                            [-1, 64, 8, 8]            36,928\n",
      "├─ReLU: 1-8                              [-1, 64, 8, 8]            --\n",
      "├─MaxPool2d: 1-9                         [-1, 64, 4, 4]            --\n",
      "├─Flatten: 1-10                          [-1, 1024]                --\n",
      "├─Linear: 1-11                           [-1, 128]                 131,200\n",
      "├─ReLU: 1-12                             [-1, 128]                 --\n",
      "├─Dropout: 1-13                          [-1, 128]                 --\n",
      "├─Linear: 1-14                           [-1, 128]                 16,512\n",
      "├─ReLU: 1-15                             [-1, 128]                 --\n",
      "├─Dropout: 1-16                          [-1, 128]                 --\n",
      "├─Linear: 1-17                           [-1, 20]                  2,580\n",
      "==========================================================================================\n",
      "Total params: 225,940\n",
      "Trainable params: 225,940\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 13.72\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.66\n",
      "Params size (MB): 0.86\n",
      "Estimated Total Size (MB): 1.53\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method SimpleCNN.summary of SimpleCNN(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Flatten(start_dim=1, end_dim=-1)\n",
       "    (10): Linear(in_features=1024, out_features=128, bias=True)\n",
       "    (11): ReLU()\n",
       "    (12): Dropout(p=0, inplace=False)\n",
       "    (13): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (14): ReLU()\n",
       "    (15): Dropout(p=0, inplace=False)\n",
       "    (16): Linear(in_features=128, out_features=20, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup for simple neural network\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple Convolutional Neural Network (CNN) for image classification.\n",
    "    Args:\n",
    "        input_size (int): Number of input channels (e.g., 3 for RGB images).\n",
    "        hidden_size (int): Number of units in the fully connected hidden layer.\n",
    "        output_size (int): Number of output classes.\n",
    "        dropout (float): Dropout probability for regularization.\n",
    "        num_conv_layers (int): Number of convolutional layers.\n",
    "        filters (int): Number of filters in each convolutional layer.\n",
    "        kernel_size (int): Size of the convolutional kernels.\n",
    "        stride (int): Stride for the convolutional layers.\n",
    "        padding (int): Padding for the convolutional layers.\n",
    "        num_fully_connected_layers (int): Number of fully connected layers.\n",
    "    Methods:\n",
    "        forward(x): Forward pass through the network.\n",
    "        summary(): Prints a summary of the network architecture.\n",
    "        plot_learning_curve(): Plots the training/validation loss and accuracy curves.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout, num_conv_layers, filters, kernel_size, stride, padding, num_fully_connected_layers):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        # For learning curve\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "\n",
    "        layers = []\n",
    "        in_channels = input_size\n",
    "\n",
    "        # Add convolutional layers\n",
    "        for _ in range(num_conv_layers):\n",
    "            layers.append(nn.Conv2d(in_channels, filters, kernel_size, stride, padding))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.MaxPool2d(2))\n",
    "            in_channels = filters\n",
    "\n",
    "        layers.append(nn.Flatten())\n",
    "\n",
    "        # Dynamically compute feature size after conv/pool layers\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, input_size, 32, 32)\n",
    "            for layer in layers:\n",
    "                dummy = layer(dummy)\n",
    "            feature_size = dummy.shape[1]\n",
    "\n",
    "        # Add the first fully connected layer\n",
    "        layers.append(nn.Linear(feature_size, hidden_size))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # Add additional fully connected layers if num_fully_connected_layers > 1\n",
    "        for _ in range(num_fully_connected_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(hidden_size, output_size))\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the network.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, input_size, 32, 32).\n",
    "        Returns:\n",
    "            torch.Tensor: Output logits.\n",
    "        \"\"\"\n",
    "        return self.network(x) \n",
    "\n",
    "    def summary(self):\n",
    "        \"\"\"\n",
    "        Prints a summary of the network architecture using torchsummary.\n",
    "        \"\"\"\n",
    "        summary(self.network, (self.input_size, 32, 32))\n",
    "    \n",
    "    def plot_learning_curve(self):\n",
    "        \"\"\"\n",
    "        Plots the learning curve (loss and accuracy).\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        epochs = range(1, len(self.train_losses) + 1)\n",
    "        fig, ax1 = plt.subplots()\n",
    "        ax1.plot(epochs, self.train_losses, 'b-', label='Train Loss')\n",
    "        ax1.plot(epochs, self.val_losses, 'r-', label='Val Loss')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend(loc='upper left')\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(epochs, self.train_accuracies, 'b--', label='Train Acc')\n",
    "        ax2.plot(epochs, self.val_accuracies, 'r--', label='Val Acc')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.legend(loc='upper right')\n",
    "        plt.title('Learning Curve')\n",
    "        plt.show()\n",
    "\n",
    "model_CNN = SimpleCNN(\n",
    "    input_size=config2[\"input_size\"],\n",
    "    hidden_size=config2[\"hidden_size\"],\n",
    "    output_size=config2[\"output_size\"],\n",
    "    dropout=config2[\"dropout\"],\n",
    "    num_conv_layers=config2[\"num_conv_layers\"],\n",
    "    filters=config2[\"filters\"],\n",
    "    kernel_size=config2[\"kernel_size\"],\n",
    "    stride=config2[\"stride\"],\n",
    "    padding=config2[\"padding\"],\n",
    "    num_fully_connected_layers=config2[\"num_fully_connected_layers\"]\n",
    ")\n",
    "\n",
    "# Show a summary of the model architecture\n",
    "model_CNN.summary(); model_CNN.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c102cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_evaluate(model_CNN, config2, logger)\n",
    "# model_CNN.plot_learning_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01a9df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mltrainer import Trainer, ReportTypes, TrainerSettings, metrics\n",
    "# model_CNN = SimpleNN(\n",
    "#     input_size=config2[\"input_size\"],\n",
    "#     hidden_size=config2[\"hidden_size\"],\n",
    "#     output_size=config2[\"output_size\"],\n",
    "#     dropout=config2[\"dropout\"],\n",
    "#     num_layers=config2[\"num_layers\"]\n",
    "# )\n",
    "\n",
    "# model_CNN.to(config2[\"device\"])\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model_CNN,\n",
    "#     settings=TrainerSettings(\n",
    "#         epochs=config2[\"epochs\"],\n",
    "#         metrics=[\n",
    "#             metrics.Accuracy()\n",
    "#         ],\n",
    "#         logdir=Path(\"./logs\"),\n",
    "#         train_steps=len(train_loader),\n",
    "#         valid_steps=len(test_loader),\n",
    "#         reporttypes=[ReportTypes.TOML],\n",
    "#         scheduler_kwargs={\"patience\": 5},\n",
    "#         earlystop_kwargs={\"patience\": 5},\n",
    "#     ),\n",
    "#     loss_fn=config2[\"loss_fn\"],\n",
    "#     optimizer=torch.optim.Adam,\n",
    "#     traindataloader=train_loader,\n",
    "#     validdataloader=test_loader,\n",
    "#     scheduler=config2[\"scheduler\"],\n",
    "#     device=config2[\"device\"],\n",
    "# )\n",
    "# trainer.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca44cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-10-19 16:09:23</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:00.53        </td></tr>\n",
       "<tr><td>Memory:      </td><td>10.7/31.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/20 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 6<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                                                                   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_and_evaluate_ray_60557_00015</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2025-10-19_16-09-04_231102_1857308/artifacts/2025-10-18_21-12-23/cnn_hyperparameter_gridsearch/driver_artifacts/train_and_evaluate_ray_60557_00015_15_filters=64,kernel_size=3,num_conv_layers=4,num_fully_connected_layers=2_2025-10-18_21-12-23/error.txt </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00035</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2025-10-19_16-09-04_231102_1857308/artifacts/2025-10-18_21-12-23/cnn_hyperparameter_gridsearch/driver_artifacts/train_and_evaluate_ray_60557_00035_35_filters=152,kernel_size=3,num_conv_layers=4,num_fully_connected_layers=4_2025-10-18_21-12-23/error.txt</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00016</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2025-10-19_16-09-04_231102_1857308/artifacts/2025-10-18_21-12-23/cnn_hyperparameter_gridsearch/driver_artifacts/train_and_evaluate_ray_60557_00016_16_filters=128,kernel_size=3,num_conv_layers=4,num_fully_connected_layers=2_2025-10-18_21-12-23/error.txt</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00033</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2025-10-19_16-09-04_231102_1857308/artifacts/2025-10-18_21-12-23/cnn_hyperparameter_gridsearch/driver_artifacts/train_and_evaluate_ray_60557_00033_33_filters=64,kernel_size=3,num_conv_layers=4,num_fully_connected_layers=4_2025-10-18_21-12-23/error.txt </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00034</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2025-10-19_16-09-04_231102_1857308/artifacts/2025-10-18_21-12-23/cnn_hyperparameter_gridsearch/driver_artifacts/train_and_evaluate_ray_60557_00034_34_filters=128,kernel_size=3,num_conv_layers=4,num_fully_connected_layers=4_2025-10-18_21-12-23/error.txt</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00017</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2025-10-19_16-09-04_231102_1857308/artifacts/2025-10-18_21-12-23/cnn_hyperparameter_gridsearch/driver_artifacts/train_and_evaluate_ray_60557_00017_17_filters=152,kernel_size=3,num_conv_layers=4,num_fully_connected_layers=2_2025-10-18_21-12-23/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  filters</th><th style=\"text-align: right;\">  kernel_size</th><th style=\"text-align: right;\">  num_conv_layers</th><th style=\"text-align: right;\">  num_fully_connected_\n",
       "layers</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  train_accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_and_evaluate_ray_60557_00005</td><td>TERMINATED</td><td>10.82.72.122:1670766</td><td style=\"text-align: right;\">      152</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1871.34 </td><td style=\"text-align: right;\">    0.865369</td><td style=\"text-align: right;\">  0.858346</td><td style=\"text-align: right;\">          69.486</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00011</td><td>TERMINATED</td><td>10.82.72.122:1670753</td><td style=\"text-align: right;\">      152</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1841.88 </td><td style=\"text-align: right;\">    0.993531</td><td style=\"text-align: right;\">  0.964723</td><td style=\"text-align: right;\">          64.558</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00029</td><td>TERMINATED</td><td>10.82.72.122:1670679</td><td style=\"text-align: right;\">      152</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1818.83 </td><td style=\"text-align: right;\">    1.06909 </td><td style=\"text-align: right;\">  1.03148 </td><td style=\"text-align: right;\">          61.854</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00023</td><td>TERMINATED</td><td>10.82.72.122:1670781</td><td style=\"text-align: right;\">      152</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1798.76 </td><td style=\"text-align: right;\">    0.929347</td><td style=\"text-align: right;\">  0.921948</td><td style=\"text-align: right;\">          67.404</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00014</td><td>TERMINATED</td><td>10.82.72.122:1670767</td><td style=\"text-align: right;\">      152</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1751.37 </td><td style=\"text-align: right;\">    1.17813 </td><td style=\"text-align: right;\">  1.12827 </td><td style=\"text-align: right;\">          57.392</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00020</td><td>TERMINATED</td><td>10.82.72.122:1670845</td><td style=\"text-align: right;\">      152</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1750.02 </td><td style=\"text-align: right;\">    0.927927</td><td style=\"text-align: right;\">  0.970115</td><td style=\"text-align: right;\">          67.178</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00008</td><td>TERMINATED</td><td>10.82.72.122:1670680</td><td style=\"text-align: right;\">      152</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1748.16 </td><td style=\"text-align: right;\">    1.00143 </td><td style=\"text-align: right;\">  1.09375 </td><td style=\"text-align: right;\">          64.448</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00002</td><td>TERMINATED</td><td>10.82.72.122:1670688</td><td style=\"text-align: right;\">      152</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1747.17 </td><td style=\"text-align: right;\">    0.874895</td><td style=\"text-align: right;\">  0.901638</td><td style=\"text-align: right;\">          69.04 </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00027</td><td>TERMINATED</td><td>10.82.72.122:1674522</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         412.958</td><td style=\"text-align: right;\">    1.16849 </td><td style=\"text-align: right;\">  1.10539 </td><td style=\"text-align: right;\">          58.074</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00026</td><td>TERMINATED</td><td>10.82.72.122:1670698</td><td style=\"text-align: right;\">      152</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1728.06 </td><td style=\"text-align: right;\">    1.01317 </td><td style=\"text-align: right;\">  0.958698</td><td style=\"text-align: right;\">          63.928</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00032</td><td>TERMINATED</td><td>10.82.72.122:1670689</td><td style=\"text-align: right;\">      152</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1723.36 </td><td style=\"text-align: right;\">    1.20005 </td><td style=\"text-align: right;\">  1.15451 </td><td style=\"text-align: right;\">          56.698</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00022</td><td>TERMINATED</td><td>10.82.72.122:1670751</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1571.22 </td><td style=\"text-align: right;\">    0.924181</td><td style=\"text-align: right;\">  0.918177</td><td style=\"text-align: right;\">          67.724</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00004</td><td>TERMINATED</td><td>10.82.72.122:1670752</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1538.63 </td><td style=\"text-align: right;\">    0.881966</td><td style=\"text-align: right;\">  0.90566 </td><td style=\"text-align: right;\">          69.082</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00010</td><td>TERMINATED</td><td>10.82.72.122:1670719</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1481.45 </td><td style=\"text-align: right;\">    1.03557 </td><td style=\"text-align: right;\">  1.03002 </td><td style=\"text-align: right;\">          63.292</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00028</td><td>TERMINATED</td><td>10.82.72.122:1670769</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1475.02 </td><td style=\"text-align: right;\">    1.08985 </td><td style=\"text-align: right;\">  1.03606 </td><td style=\"text-align: right;\">          61.066</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00001</td><td>TERMINATED</td><td>10.82.72.122:1670782</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1464.65 </td><td style=\"text-align: right;\">    0.892391</td><td style=\"text-align: right;\">  0.906145</td><td style=\"text-align: right;\">          68.366</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00031</td><td>TERMINATED</td><td>10.82.72.122:1670760</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1433.47 </td><td style=\"text-align: right;\">    1.23422 </td><td style=\"text-align: right;\">  1.1964  </td><td style=\"text-align: right;\">          54.99 </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00019</td><td>TERMINATED</td><td>10.82.72.122:1670745</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1423.27 </td><td style=\"text-align: right;\">    0.885421</td><td style=\"text-align: right;\">  1.02963 </td><td style=\"text-align: right;\">          68.87 </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00025</td><td>TERMINATED</td><td>10.82.72.122:1670770</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1335.24 </td><td style=\"text-align: right;\">    1.04584 </td><td style=\"text-align: right;\">  0.977771</td><td style=\"text-align: right;\">          62.334</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00007</td><td>TERMINATED</td><td>10.82.72.122:1670768</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1311.75 </td><td style=\"text-align: right;\">    1.02437 </td><td style=\"text-align: right;\">  1.03345 </td><td style=\"text-align: right;\">          63.736</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00013</td><td>TERMINATED</td><td>10.82.72.122:1670754</td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        1291.96 </td><td style=\"text-align: right;\">    1.18676 </td><td style=\"text-align: right;\">  1.10586 </td><td style=\"text-align: right;\">          56.75 </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00018</td><td>TERMINATED</td><td>10.82.72.122:1664110</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         703.918</td><td style=\"text-align: right;\">    0.962951</td><td style=\"text-align: right;\">  1.02043 </td><td style=\"text-align: right;\">          65.514</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00009</td><td>TERMINATED</td><td>10.82.72.122:1664155</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         657.968</td><td style=\"text-align: right;\">    1.09752 </td><td style=\"text-align: right;\">  1.1693  </td><td style=\"text-align: right;\">          60.686</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00021</td><td>TERMINATED</td><td>10.82.72.122:1651395</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         796.078</td><td style=\"text-align: right;\">    0.986069</td><td style=\"text-align: right;\">  0.977975</td><td style=\"text-align: right;\">          64.85 </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00003</td><td>TERMINATED</td><td>10.82.72.122:1651385</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         772.848</td><td style=\"text-align: right;\">    0.984557</td><td style=\"text-align: right;\">  0.96602 </td><td style=\"text-align: right;\">          65.202</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00024</td><td>TERMINATED</td><td>10.82.72.122:1651383</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         765.125</td><td style=\"text-align: right;\">    1.14984 </td><td style=\"text-align: right;\">  1.10467 </td><td style=\"text-align: right;\">          58.796</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00030</td><td>TERMINATED</td><td>10.82.72.122:1652868</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         709.509</td><td style=\"text-align: right;\">    1.33182 </td><td style=\"text-align: right;\">  1.26467 </td><td style=\"text-align: right;\">          50.834</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00000</td><td>TERMINATED</td><td>10.82.72.122:1651381</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         738.721</td><td style=\"text-align: right;\">    0.927062</td><td style=\"text-align: right;\">  0.930176</td><td style=\"text-align: right;\">          67.22 </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00006</td><td>TERMINATED</td><td>10.82.72.122:1651388</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         727.532</td><td style=\"text-align: right;\">    1.11387 </td><td style=\"text-align: right;\">  1.0356  </td><td style=\"text-align: right;\">          60.232</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00012</td><td>TERMINATED</td><td>10.82.72.122:1651382</td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         667.308</td><td style=\"text-align: right;\">    1.27741 </td><td style=\"text-align: right;\">  1.28672 </td><td style=\"text-align: right;\">          53.188</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00015</td><td>ERROR     </td><td>                    </td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00035</td><td>ERROR     </td><td>                    </td><td style=\"text-align: right;\">      152</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00016</td><td>ERROR     </td><td>                    </td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00033</td><td>ERROR     </td><td>                    </td><td style=\"text-align: right;\">       64</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00034</td><td>ERROR     </td><td>                    </td><td style=\"text-align: right;\">      128</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_60557_00017</td><td>ERROR     </td><td>                    </td><td style=\"text-align: right;\">      152</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">                </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 16:09:22,835\tINFO tune_controller.py:444 -- Restoring the run from the latest experiment state file: experiment_state-2025-10-19_14-42-35.json\n",
      "2025-10-19 16:09:23,699\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune/cnn_hyperparameter_gridsearch' in 0.5276s.\n",
      "2025-10-19 16:09:23,732\tERROR tune.py:1037 -- Trials did not complete: [train_and_evaluate_ray_60557_00015, train_and_evaluate_ray_60557_00035, train_and_evaluate_ray_60557_00016, train_and_evaluate_ray_60557_00033, train_and_evaluate_ray_60557_00034, train_and_evaluate_ray_60557_00017]\n",
      "2025-10-19 16:09:23,733\tINFO tune.py:1041 -- Total run time: 1.10 seconds (0.00 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "trial_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "train_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "timestamp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "checkpoint_dir_name",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "done",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "training_iteration",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "time_this_iter_s",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "time_total_s",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hostname",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "node_ip",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "time_since_restore",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "iterations_since_restore",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "experiment_tag",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "config/epochs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/data_dir",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "config/tune_dir",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "config/batch_size",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/input_size",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/output_size",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/hidden_size",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/dropout",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/num_fully_connected_layers",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/learning_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/loss_fn",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "config/optimizer",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "config/scheduler",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "config/metrics",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "config/device",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "config/num_conv_layers",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/filters",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/kernel_size",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/stride",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/padding",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "14aeb5bf-a3cc-454f-a560-b886e02d5baa",
       "rows": [
        [
         "60557_00005",
         "0.8653694896213234",
         "0.8583464580736343",
         "69.486",
         "69.92",
         "1760820842.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-54-02",
         "403.64898109436035",
         "1871.344081401825",
         "1670766.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1871.344081401825",
         "3.0",
         "5_filters=152,kernel_size=3,num_conv_layers=2,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "2.0",
         "152.0",
         "3.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00002",
         "0.8748945136509283",
         "0.9016384114125732",
         "69.04",
         "68.35",
         "1760820717.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-51-57",
         "444.56968212127686",
         "1747.172739982605",
         "1670688.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1747.172739982605",
         "3.0",
         "2_filters=152,kernel_size=2,num_conv_layers=2,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "2.0",
         "152.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00004",
         "0.881965663388867",
         "0.9056603187208723",
         "69.082",
         "68.3",
         "1760820509.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-48-29",
         "448.4934995174408",
         "1538.6261432170868",
         "1670752.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1538.6261432170868",
         "3.0",
         "4_filters=128,kernel_size=3,num_conv_layers=2,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "2.0",
         "128.0",
         "3.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00001",
         "0.892391116189225",
         "0.9061449219466774",
         "68.366",
         "68.94",
         "1760820435.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-47-15",
         "446.46467995643616",
         "1464.6482491493225",
         "1670782.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1464.6482491493225",
         "3.0",
         "1_filters=128,kernel_size=2,num_conv_layers=2,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "2.0",
         "128.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00022",
         "0.924181490450564",
         "0.9181767705899135",
         "67.724",
         "67.77",
         "1760820541.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-49-01",
         "425.71722197532654",
         "1571.2217280864716",
         "1670751.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1571.2217280864716",
         "3.0",
         "22_filters=128,kernel_size=3,num_conv_layers=2,num_fully_connected_layers=4",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "4.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "2.0",
         "128.0",
         "3.0",
         "1.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 37,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>checkpoint_dir_name</th>\n",
       "      <th>done</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>date</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>...</th>\n",
       "      <th>config/loss_fn</th>\n",
       "      <th>config/optimizer</th>\n",
       "      <th>config/scheduler</th>\n",
       "      <th>config/metrics</th>\n",
       "      <th>config/device</th>\n",
       "      <th>config/num_conv_layers</th>\n",
       "      <th>config/filters</th>\n",
       "      <th>config/kernel_size</th>\n",
       "      <th>config/stride</th>\n",
       "      <th>config/padding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60557_00005</th>\n",
       "      <td>0.865369</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>69.486</td>\n",
       "      <td>69.92</td>\n",
       "      <td>1.760821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-54-02</td>\n",
       "      <td>403.648981</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>2.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00002</th>\n",
       "      <td>0.874895</td>\n",
       "      <td>0.901638</td>\n",
       "      <td>69.040</td>\n",
       "      <td>68.35</td>\n",
       "      <td>1.760821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-51-57</td>\n",
       "      <td>444.569682</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>2.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00004</th>\n",
       "      <td>0.881966</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>69.082</td>\n",
       "      <td>68.30</td>\n",
       "      <td>1.760821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-48-29</td>\n",
       "      <td>448.493500</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>2.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00001</th>\n",
       "      <td>0.892391</td>\n",
       "      <td>0.906145</td>\n",
       "      <td>68.366</td>\n",
       "      <td>68.94</td>\n",
       "      <td>1.760820e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-47-15</td>\n",
       "      <td>446.464680</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>2.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00022</th>\n",
       "      <td>0.924181</td>\n",
       "      <td>0.918177</td>\n",
       "      <td>67.724</td>\n",
       "      <td>67.77</td>\n",
       "      <td>1.760821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-49-01</td>\n",
       "      <td>425.717222</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>2.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             train_loss  val_loss  train_accuracy  val_accuracy     timestamp  \\\n",
       "trial_id                                                                        \n",
       "60557_00005    0.865369  0.858346          69.486         69.92  1.760821e+09   \n",
       "60557_00002    0.874895  0.901638          69.040         68.35  1.760821e+09   \n",
       "60557_00004    0.881966  0.905660          69.082         68.30  1.760821e+09   \n",
       "60557_00001    0.892391  0.906145          68.366         68.94  1.760820e+09   \n",
       "60557_00022    0.924181  0.918177          67.724         67.77  1.760821e+09   \n",
       "\n",
       "             checkpoint_dir_name  done  training_iteration  \\\n",
       "trial_id                                                     \n",
       "60557_00005                  NaN  True                 3.0   \n",
       "60557_00002                  NaN  True                 3.0   \n",
       "60557_00004                  NaN  True                 3.0   \n",
       "60557_00001                  NaN  True                 3.0   \n",
       "60557_00022                  NaN  True                 3.0   \n",
       "\n",
       "                            date  time_this_iter_s  ...      config/loss_fn  \\\n",
       "trial_id                                            ...                       \n",
       "60557_00005  2025-10-18_22-54-02        403.648981  ...  CrossEntropyLoss()   \n",
       "60557_00002  2025-10-18_22-51-57        444.569682  ...  CrossEntropyLoss()   \n",
       "60557_00004  2025-10-18_22-48-29        448.493500  ...  CrossEntropyLoss()   \n",
       "60557_00001  2025-10-18_22-47-15        446.464680  ...  CrossEntropyLoss()   \n",
       "60557_00022  2025-10-18_22-49-01        425.717222  ...  CrossEntropyLoss()   \n",
       "\n",
       "                            config/optimizer  \\\n",
       "trial_id                                       \n",
       "60557_00005  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00002  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00004  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00001  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00022  <class 'torch.optim.adam.Adam'>   \n",
       "\n",
       "                                              config/scheduler config/metrics  \\\n",
       "trial_id                                                                        \n",
       "60557_00005  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00002  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00004  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00001  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00022  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "\n",
       "             config/device  config/num_conv_layers config/filters  \\\n",
       "trial_id                                                            \n",
       "60557_00005            cpu                     2.0          152.0   \n",
       "60557_00002            cpu                     2.0          152.0   \n",
       "60557_00004            cpu                     2.0          128.0   \n",
       "60557_00001            cpu                     2.0          128.0   \n",
       "60557_00022            cpu                     2.0          128.0   \n",
       "\n",
       "             config/kernel_size config/stride config/padding  \n",
       "trial_id                                                      \n",
       "60557_00005                 3.0           1.0            0.0  \n",
       "60557_00002                 2.0           1.0            0.0  \n",
       "60557_00004                 3.0           1.0            0.0  \n",
       "60557_00001                 2.0           1.0            0.0  \n",
       "60557_00022                 3.0           1.0            0.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 1/782 [00:00<05:13,  2.49it/s]\n",
      "Training:   0%|          | 2/782 [00:00<03:56,  3.30it/s]\n",
      "Training:   0%|          | 3/782 [00:00<03:26,  3.77it/s]\n",
      "Training:   1%|          | 4/782 [00:01<03:15,  3.98it/s]\n",
      "Training:   1%|          | 5/782 [00:01<03:11,  4.05it/s]\n",
      "Training:   1%|          | 6/782 [00:01<03:11,  4.05it/s]\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "Training:   1%|          | 5/782 [00:01<03:26,  3.76it/s]\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "Training:   0%|          | 1/782 [00:00<05:38,  2.31it/s]\u001b[32m [repeated 117x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Training:   4%|▍         | 35/782 [00:11<05:40,  2.19it/s]\u001b[32m [repeated 139x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "Training:   8%|▊         | 61/782 [00:20<05:34,  2.16it/s]\u001b[32m [repeated 136x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Training:  11%|█         | 83/782 [00:18<04:42,  2.48it/s]\u001b[32m [repeated 130x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:   3%|▎         | 26/782 [00:17<10:04,  1.25it/s]\u001b[32m [repeated 97x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 3/782 [00:06<28:35,  2.20s/it]\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 3/782 [00:03<11:31,  1.13it/s]\u001b[32m [repeated 101x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:   5%|▍         | 37/782 [00:28<09:07,  1.36it/s]\u001b[32m [repeated 146x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:   4%|▎         | 28/782 [00:26<10:10,  1.23it/s]\u001b[32m [repeated 152x across cluster]\u001b[0m\n",
      "Training:  14%|█▎        | 106/782 [00:56<09:05,  1.24it/s]\u001b[32m [repeated 155x across cluster]\u001b[0m\n",
      "Training:   8%|▊         | 59/782 [00:43<08:10,  1.47it/s]\u001b[32m [repeated 148x across cluster]\u001b[0m\n",
      "Training:   8%|▊         | 62/782 [00:28<04:57,  2.42it/s]\u001b[32m [repeated 149x across cluster]\u001b[0m\n",
      "Training:   7%|▋         | 54/782 [00:46<09:37,  1.26it/s]\u001b[32m [repeated 155x across cluster]\u001b[0m\n",
      "Training:  10%|▉         | 75/782 [00:42<06:09,  1.91it/s]\u001b[32m [repeated 153x across cluster]\u001b[0m\n",
      "Training:  16%|█▋        | 128/782 [01:17<08:18,  1.31it/s]\u001b[32m [repeated 146x across cluster]\u001b[0m\n",
      "Training:  19%|█▊        | 145/782 [01:26<07:41,  1.38it/s]\u001b[32m [repeated 150x across cluster]\u001b[0m\n",
      "Training:  10%|▉         | 76/782 [01:09<10:25,  1.13it/s]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  23%|██▎       | 182/782 [01:31<05:42,  1.75it/s]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  11%|█         | 84/782 [01:12<07:36,  1.53it/s]\u001b[32m [repeated 119x across cluster]\u001b[0m\n",
      "Training:  11%|█         | 86/782 [01:04<12:57,  1.12s/it]\u001b[32m [repeated 116x across cluster]\u001b[0m\n",
      "Training:  19%|█▉        | 149/782 [01:17<05:26,  1.94it/s]\u001b[32m [repeated 107x across cluster]\u001b[0m\n",
      "Training:  21%|██        | 162/782 [01:23<04:13,  2.45it/s]\u001b[32m [repeated 111x across cluster]\u001b[0m\n",
      "Training:  26%|██▋       | 206/782 [01:56<11:05,  1.15s/it]\u001b[32m [repeated 110x across cluster]\u001b[0m\n",
      "Training:  18%|█▊        | 138/782 [02:04<10:45,  1.00s/it]\u001b[32m [repeated 142x across cluster]\u001b[0m\n",
      "Training:  16%|█▋        | 129/782 [01:47<08:07,  1.34it/s]\u001b[32m [repeated 152x across cluster]\u001b[0m\n",
      "Training:  24%|██▍       | 191/782 [02:13<08:02,  1.23it/s]\u001b[32m [repeated 150x across cluster]\u001b[0m\n",
      "Training:  20%|█▉        | 155/782 [02:04<07:35,  1.38it/s]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  28%|██▊       | 222/782 [01:53<06:33,  1.42it/s]\u001b[32m [repeated 149x across cluster]\u001b[0m\n",
      "Training:  32%|███▏      | 249/782 [01:54<04:04,  2.18it/s]\u001b[32m [repeated 148x across cluster]\u001b[0m\n",
      "Training:  19%|█▉        | 147/782 [01:54<08:53,  1.19it/s]\u001b[32m [repeated 146x across cluster]\u001b[0m\n",
      "Training:  35%|███▍      | 272/782 [02:04<03:14,  2.62it/s]\u001b[32m [repeated 150x across cluster]\u001b[0m\n",
      "Training:  37%|███▋      | 286/782 [02:42<05:05,  1.63it/s]\u001b[32m [repeated 149x across cluster]\u001b[0m\n",
      "Training:  15%|█▍        | 117/782 [02:07<11:22,  1.03s/it]\u001b[32m [repeated 147x across cluster]\u001b[0m\n",
      "Training:  31%|███       | 243/782 [02:53<07:40,  1.17it/s]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  25%|██▍       | 194/782 [02:59<10:31,  1.07s/it]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  43%|████▎     | 333/782 [02:29<03:05,  2.42it/s]\u001b[32m [repeated 147x across cluster]\u001b[0m\n",
      "Training:  44%|████▍     | 346/782 [02:34<02:57,  2.46it/s]\u001b[32m [repeated 153x across cluster]\u001b[0m\n",
      "Training:  26%|██▌       | 204/782 [02:48<08:41,  1.11it/s]\u001b[32m [repeated 148x across cluster]\u001b[0m\n",
      "Training:  40%|███▉      | 309/782 [03:12<04:35,  1.72it/s]\u001b[32m [repeated 154x across cluster]\u001b[0m\n",
      "Training:  38%|███▊      | 294/782 [03:27<06:12,  1.31it/s]\u001b[32m [repeated 153x across cluster]\u001b[0m\n",
      "Training:  20%|██        | 158/782 [02:47<10:59,  1.06s/it]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  52%|█████▏    | 407/782 [03:00<02:30,  2.49it/s]\u001b[32m [repeated 153x across cluster]\u001b[0m\n",
      "Training:  44%|████▍     | 343/782 [03:33<04:10,  1.75it/s]\u001b[32m [repeated 149x across cluster]\u001b[0m\n",
      "Training:  55%|█████▌    | 431/782 [03:10<02:27,  2.38it/s]\u001b[32m [repeated 150x across cluster]\u001b[0m\n",
      "Training:  57%|█████▋    | 443/782 [03:15<02:37,  2.16it/s]\u001b[32m [repeated 148x across cluster]\u001b[0m\n",
      "Training:  29%|██▉       | 227/782 [03:36<09:13,  1.00it/s]\u001b[32m [repeated 152x across cluster]\u001b[0m\n",
      "Training:  48%|████▊     | 374/782 [03:53<04:34,  1.48it/s]\u001b[32m [repeated 155x across cluster]\u001b[0m\n",
      "Training:  43%|████▎     | 335/782 [04:04<05:43,  1.30it/s]\u001b[32m [repeated 150x across cluster]\u001b[0m\n",
      "Training:  25%|██▌       | 197/782 [03:28<09:45,  1.00s/it]\u001b[32m [repeated 150x across cluster]\u001b[0m\n",
      "Training:  33%|███▎      | 256/782 [04:04<09:11,  1.05s/it]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  66%|██████▌   | 517/782 [03:45<01:47,  2.47it/s]\u001b[32m [repeated 152x across cluster]\u001b[0m\n",
      "Training:  68%|██████▊   | 528/782 [03:50<01:55,  2.19it/s]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  69%|██████▉   | 540/782 [03:55<01:45,  2.30it/s]\u001b[32m [repeated 153x across cluster]\u001b[0m\n",
      "Training:  71%|███████   | 552/782 [04:00<01:37,  2.35it/s]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  35%|███▌      | 277/782 [04:21<07:51,  1.07it/s]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  43%|████▎     | 339/782 [04:24<05:19,  1.39it/s]\u001b[32m [repeated 148x across cluster]\u001b[0m\n",
      "Training:  91%|█████████▏| 714/782 [04:43<00:32,  2.11it/s]\n",
      "Training:  91%|█████████▏| 715/782 [04:44<00:32,  2.07it/s]\n",
      "Training:  92%|█████████▏| 716/782 [04:44<00:31,  2.07it/s]\n",
      "Training:  92%|█████████▏| 717/782 [04:45<00:31,  2.08it/s]\n",
      "Training:  92%|█████████▏| 718/782 [04:45<00:31,  2.04it/s]\n",
      "Training:  92%|█████████▏| 719/782 [04:46<00:30,  2.05it/s]\n",
      "Training:  92%|█████████▏| 720/782 [04:46<00:29,  2.13it/s]\n",
      "Training:  44%|████▍     | 346/782 [04:29<05:50,  1.24it/s]\u001b[32m [repeated 147x across cluster]\u001b[0m\n",
      "Training:  92%|█████████▏| 721/782 [04:47<00:27,  2.20it/s]\n",
      "Training:  92%|█████████▏| 722/782 [04:47<00:26,  2.24it/s]\n",
      "Training:  92%|█████████▏| 723/782 [04:48<00:26,  2.26it/s]\n",
      "Training:  93%|█████████▎| 724/782 [04:48<00:25,  2.25it/s]\n",
      "Training:  93%|█████████▎| 725/782 [04:48<00:24,  2.29it/s]\n",
      "Training:  93%|█████████▎| 726/782 [04:49<00:25,  2.23it/s]\n",
      "Training:  93%|█████████▎| 727/782 [04:49<00:24,  2.22it/s]\n",
      "Training:  93%|█████████▎| 728/782 [04:50<00:23,  2.27it/s]\n",
      "Training:  93%|█████████▎| 729/782 [04:50<00:23,  2.24it/s]\n",
      "Training:  93%|█████████▎| 730/782 [04:51<00:23,  2.23it/s]\n",
      "Training:  93%|█████████▎| 731/782 [04:51<00:24,  2.12it/s]\n",
      "Training:  77%|███████▋  | 600/782 [04:21<01:13,  2.46it/s]\u001b[32m [repeated 138x across cluster]\u001b[0m\n",
      "Training:  94%|█████████▎| 732/782 [04:52<00:27,  1.81it/s]\n",
      "Training:  94%|█████████▎| 733/782 [04:52<00:26,  1.87it/s]\n",
      "Training:  94%|█████████▍| 734/782 [04:53<00:23,  2.05it/s]\n",
      "Training:  94%|█████████▍| 735/782 [04:53<00:21,  2.22it/s]\n",
      "Training:  94%|█████████▍| 736/782 [04:54<00:19,  2.37it/s]\n",
      "Training:  94%|█████████▍| 737/782 [04:54<00:18,  2.40it/s]\n",
      "Training:  94%|█████████▍| 738/782 [04:54<00:17,  2.47it/s]\n",
      "Training:  95%|█████████▍| 739/782 [04:55<00:18,  2.37it/s]\n",
      "Training:  95%|█████████▍| 740/782 [04:55<00:17,  2.34it/s]\n",
      "Training:  95%|█████████▍| 741/782 [04:56<00:17,  2.38it/s]\n",
      "Training:  95%|█████████▍| 742/782 [04:56<00:16,  2.41it/s]\n",
      "Training:  95%|█████████▌| 743/782 [04:56<00:16,  2.36it/s]\n",
      "Training:  78%|███████▊  | 613/782 [04:26<01:03,  2.65it/s]\u001b[32m [repeated 139x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▌| 744/782 [04:57<00:15,  2.39it/s]\n",
      "Training:  95%|█████████▌| 745/782 [04:57<00:15,  2.37it/s]\n",
      "Training:  95%|█████████▌| 746/782 [04:58<00:15,  2.40it/s]\n",
      "Training:  96%|█████████▌| 747/782 [04:58<00:14,  2.38it/s]\n",
      "Training:  96%|█████████▌| 748/782 [04:59<00:14,  2.36it/s]\n",
      "Training:  96%|█████████▌| 749/782 [04:59<00:13,  2.38it/s]\n",
      "Training:  96%|█████████▌| 750/782 [04:59<00:13,  2.38it/s]\n",
      "Training:  96%|█████████▌| 751/782 [05:00<00:12,  2.41it/s]\n",
      "Training:  96%|█████████▌| 752/782 [05:00<00:11,  2.52it/s]\n",
      "Training:  96%|█████████▋| 753/782 [05:01<00:12,  2.36it/s]\n",
      "Training:  96%|█████████▋| 754/782 [05:01<00:12,  2.29it/s]\n",
      "Training:  97%|█████████▋| 755/782 [05:02<00:12,  2.21it/s]\n",
      "Training:  80%|███████▉  | 625/782 [04:31<01:11,  2.19it/s]\u001b[32m [repeated 137x across cluster]\u001b[0m\n",
      "Training:  97%|█████████▋| 756/782 [05:02<00:11,  2.19it/s]\n",
      "Training:  97%|█████████▋| 757/782 [05:02<00:10,  2.31it/s]\n",
      "Training:  97%|█████████▋| 758/782 [05:03<00:10,  2.30it/s]\n",
      "Training:  97%|█████████▋| 759/782 [05:03<00:10,  2.17it/s]\n",
      "Training:  97%|█████████▋| 760/782 [05:04<00:09,  2.29it/s]\n",
      "Training:  97%|█████████▋| 761/782 [05:04<00:08,  2.35it/s]\n",
      "Training:  97%|█████████▋| 762/782 [05:05<00:08,  2.31it/s]\n",
      "Training:  98%|█████████▊| 763/782 [05:05<00:08,  2.29it/s]\n",
      "Training:  98%|█████████▊| 764/782 [05:05<00:07,  2.27it/s]\n",
      "Training:  98%|█████████▊| 765/782 [05:06<00:07,  2.25it/s]\n",
      "Training:  98%|█████████▊| 766/782 [05:06<00:07,  2.22it/s]\n",
      "Training:  48%|████▊     | 372/782 [04:49<04:53,  1.40it/s]\u001b[32m [repeated 139x across cluster]\u001b[0m\n",
      "Training:  98%|█████████▊| 767/782 [05:07<00:06,  2.15it/s]\n",
      "Training:  98%|█████████▊| 768/782 [05:07<00:06,  2.26it/s]\n",
      "Training:  98%|█████████▊| 769/782 [05:08<00:05,  2.35it/s]\n",
      "Training:  98%|█████████▊| 770/782 [05:08<00:05,  2.36it/s]\n",
      "Training:  99%|█████████▊| 771/782 [05:08<00:04,  2.41it/s]\n",
      "Training:  99%|█████████▊| 772/782 [05:09<00:04,  2.47it/s]\n",
      "Training:  99%|█████████▉| 773/782 [05:09<00:03,  2.44it/s]\n",
      "Training:  99%|█████████▉| 774/782 [05:10<00:03,  2.52it/s]\n",
      "Training:  99%|█████████▉| 775/782 [05:10<00:02,  2.60it/s]\n",
      "Training:  99%|█████████▉| 776/782 [05:10<00:02,  2.64it/s]\n",
      "Training:  99%|█████████▉| 777/782 [05:11<00:01,  2.73it/s]\n",
      "Training:  99%|█████████▉| 778/782 [05:11<00:01,  2.67it/s]\n",
      "Training: 100%|█████████▉| 779/782 [05:11<00:01,  2.71it/s]\n",
      "Training:  83%|████████▎ | 648/782 [04:41<00:52,  2.57it/s]\u001b[32m [repeated 138x across cluster]\u001b[0m\n",
      "Training: 100%|█████████▉| 780/782 [05:12<00:00,  2.23it/s]\n",
      "Training: 100%|█████████▉| 781/782 [05:13<00:00,  2.24it/s]\n",
      "Training: 100%|██████████| 782/782 [05:13<00:00,  2.72it/s]\n",
      "Training: 100%|██████████| 782/782 [05:13<00:00,  2.50it/s]\n",
      "Training:  85%|████████▍ | 661/782 [04:46<00:48,  2.47it/s]\u001b[32m [repeated 143x across cluster]\u001b[0m\n",
      "Training:  74%|███████▍  | 577/782 [04:55<01:37,  2.10it/s]\u001b[32m [repeated 137x across cluster]\u001b[0m\n",
      "Training:  91%|█████████▏| 714/782 [05:29<00:30,  2.20it/s]\n",
      "Training:  91%|█████████▏| 715/782 [05:29<00:30,  2.23it/s]\n",
      "Training:  92%|█████████▏| 716/782 [05:29<00:29,  2.25it/s]\n",
      "Training:  92%|█████████▏| 717/782 [05:30<00:29,  2.21it/s]\n",
      "Training:  92%|█████████▏| 718/782 [05:31<00:31,  2.02it/s]\n",
      "Training:  92%|█████████▏| 719/782 [05:31<00:34,  1.82it/s]\n",
      "Training:  92%|█████████▏| 720/782 [05:32<00:35,  1.77it/s]\n",
      "Training:  58%|█████▊    | 455/782 [05:22<04:30,  1.21it/s]\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
      "Training:  92%|█████████▏| 721/782 [05:33<00:37,  1.62it/s]\n",
      "Training:  92%|█████████▏| 722/782 [05:33<00:39,  1.52it/s]\n",
      "Training:  92%|█████████▏| 723/782 [05:34<00:35,  1.65it/s]\n",
      "Training:  93%|█████████▎| 724/782 [05:35<00:36,  1.58it/s]\n",
      "Training:  93%|█████████▎| 725/782 [05:35<00:33,  1.72it/s]\n",
      "Training:  93%|█████████▎| 726/782 [05:35<00:30,  1.84it/s]\n",
      "Training:  93%|█████████▎| 727/782 [05:36<00:28,  1.94it/s]\n",
      "Training:  93%|█████████▎| 728/782 [05:36<00:26,  2.02it/s]\n",
      "Training:  93%|█████████▎| 729/782 [05:37<00:26,  2.03it/s]\n",
      "Training:  93%|█████████▎| 730/782 [05:37<00:24,  2.08it/s]\n",
      "Training:  89%|████████▉ | 697/782 [05:01<00:34,  2.46it/s]\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
      "Training:  93%|█████████▎| 731/782 [05:38<00:23,  2.13it/s]\n",
      "Training:  94%|█████████▎| 732/782 [05:38<00:22,  2.19it/s]\n",
      "Training:  94%|█████████▎| 733/782 [05:39<00:21,  2.29it/s]\n",
      "Training:  94%|█████████▍| 734/782 [05:39<00:21,  2.25it/s]\n",
      "Training:  94%|█████████▍| 735/782 [05:39<00:21,  2.15it/s]\n",
      "Training:  94%|█████████▍| 736/782 [05:40<00:21,  2.19it/s]\n",
      "Training:  94%|█████████▍| 737/782 [05:40<00:20,  2.21it/s]\n",
      "Training:  94%|█████████▍| 738/782 [05:41<00:19,  2.22it/s]\n",
      "Training:  95%|█████████▍| 739/782 [05:41<00:19,  2.18it/s]\n",
      "Training:  95%|█████████▍| 740/782 [05:42<00:18,  2.22it/s]\n",
      "Training:  95%|█████████▍| 741/782 [05:42<00:18,  2.18it/s]\n",
      "Training:  68%|██████▊   | 535/782 [05:34<02:30,  1.64it/s]\u001b[32m [repeated 125x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▍| 742/782 [05:43<00:18,  2.14it/s]\n",
      "Training:  95%|█████████▌| 743/782 [05:43<00:18,  2.15it/s]\n",
      "Training:  95%|█████████▌| 744/782 [05:44<00:17,  2.13it/s]\n",
      "Training:  95%|█████████▌| 745/782 [05:44<00:17,  2.15it/s]\n",
      "Training:  95%|█████████▌| 746/782 [05:45<00:16,  2.18it/s]\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860005)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860005)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  58%|█████▊    | 451/782 [05:33<03:56,  1.40it/s]\u001b[32m [repeated 125x across cluster]\u001b[0m\n",
      "Training:  92%|█████████▏| 723/782 [05:12<00:28,  2.10it/s]\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "Training:  55%|█████▍    | 427/782 [05:29<04:06,  1.44it/s]\u001b[32m [repeated 129x across cluster]\u001b[0m\n",
      "Training:  94%|█████████▍| 735/782 [05:18<00:19,  2.44it/s]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "Training:  63%|██████▎   | 492/782 [05:59<04:31,  1.07it/s]\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
      "Training:  96%|█████████▌| 747/782 [05:22<00:13,  2.58it/s]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "Training:  64%|██████▍   | 499/782 [06:04<03:33,  1.33it/s]\u001b[32m [repeated 129x across cluster]\u001b[0m\n",
      "Training:  97%|█████████▋| 759/782 [05:27<00:09,  2.41it/s]\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "Training:  70%|███████   | 549/782 [05:49<02:15,  1.72it/s]\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▊| 772/782 [05:33<00:04,  2.44it/s]\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "Training:  62%|██████▏   | 486/782 [05:58<03:16,  1.51it/s]\u001b[32m [repeated 126x across cluster]\u001b[0m\n",
      "Training: 100%|██████████| 782/782 [05:36<00:00,  2.32it/s]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "Training:  50%|█████     | 393/782 [06:17<07:07,  1.10s/it]\u001b[32m [repeated 131x across cluster]\u001b[0m\n",
      "Training:  57%|█████▋    | 444/782 [05:55<05:16,  1.07it/s]\u001b[32m [repeated 131x across cluster]\u001b[0m\n",
      "Training:  42%|████▏     | 332/782 [05:44<09:12,  1.23s/it]\u001b[32m [repeated 131x across cluster]\u001b[0m\n",
      "Training:  59%|█████▊    | 458/782 [06:05<03:45,  1.44it/s]\u001b[32m [repeated 133x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860003)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860003)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  91%|█████████▏| 714/782 [06:05<00:33,  2.03it/s]\n",
      "Training:  91%|█████████▏| 715/782 [06:06<00:38,  1.76it/s]\n",
      "Training:  86%|████████▌ | 670/782 [06:34<01:05,  1.72it/s]\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
      "Training:  92%|█████████▏| 716/782 [06:06<00:41,  1.59it/s]\n",
      "Training:  92%|█████████▏| 717/782 [06:07<00:41,  1.57it/s]\n",
      "Training:  92%|█████████▏| 718/782 [06:08<00:38,  1.68it/s]\n",
      "Training:  92%|█████████▏| 719/782 [06:08<00:34,  1.82it/s]\n",
      "Training:  92%|█████████▏| 720/782 [06:09<00:33,  1.88it/s]\n",
      "Training:  92%|█████████▏| 721/782 [06:09<00:31,  1.97it/s]\n",
      "Training:  92%|█████████▏| 722/782 [06:09<00:29,  2.00it/s]\n",
      "Training:  92%|█████████▏| 723/782 [06:10<00:29,  2.03it/s]\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860000)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860000)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  93%|█████████▎| 724/782 [06:10<00:28,  2.05it/s]\n",
      "Training:  65%|██████▍   | 506/782 [06:02<03:25,  1.35it/s]\u001b[32m [repeated 132x across cluster]\u001b[0m\n",
      "Training:  93%|█████████▎| 725/782 [06:11<00:27,  2.05it/s]\n",
      "Training:  93%|█████████▎| 726/782 [06:11<00:27,  2.07it/s]\n",
      "Training:  93%|█████████▎| 727/782 [06:12<00:26,  2.08it/s]\n",
      "Training:  93%|█████████▎| 728/782 [06:12<00:26,  2.08it/s]\n",
      "Training:  93%|█████████▎| 729/782 [06:13<00:24,  2.16it/s]\n",
      "Training:  93%|█████████▎| 730/782 [06:13<00:23,  2.17it/s]\n",
      "Training:  93%|█████████▎| 731/782 [06:14<00:23,  2.13it/s]\n",
      "Training:  94%|█████████▎| 732/782 [06:14<00:23,  2.09it/s]\n",
      "Training:  94%|█████████▎| 733/782 [06:15<00:23,  2.09it/s]\n",
      "Training:  94%|█████████▍| 734/782 [06:15<00:22,  2.16it/s]\n",
      "Training:  94%|█████████▍| 735/782 [06:16<00:22,  2.06it/s]\n",
      "Training:  19%|█▉        | 149/782 [01:03<04:03,  2.60it/s]\u001b[32m [repeated 138x across cluster]\u001b[0m\n",
      "Training:  94%|█████████▍| 736/782 [06:16<00:22,  2.05it/s]\n",
      "Training:  94%|█████████▍| 737/782 [06:17<00:21,  2.11it/s]\n",
      "Training:  94%|█████████▍| 738/782 [06:17<00:20,  2.10it/s]\n",
      "Training:  95%|█████████▍| 739/782 [06:18<00:20,  2.14it/s]\n",
      "Training:  95%|█████████▍| 740/782 [06:18<00:19,  2.20it/s]\n",
      "Training:  95%|█████████▍| 741/782 [06:18<00:18,  2.18it/s]\n",
      "Training:  95%|█████████▍| 742/782 [06:19<00:18,  2.14it/s]\n",
      "Training:  95%|█████████▌| 743/782 [06:19<00:18,  2.15it/s]\n",
      "Training:  95%|█████████▌| 744/782 [06:20<00:17,  2.17it/s]\n",
      "Training:  95%|█████████▌| 745/782 [06:20<00:17,  2.10it/s]\n",
      "Training:  72%|███████▏  | 565/782 [06:55<02:54,  1.25it/s]\u001b[32m [repeated 137x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▌| 746/782 [06:21<00:17,  2.05it/s]\n",
      "Training:  96%|█████████▌| 747/782 [06:21<00:17,  1.99it/s]\n",
      "Training:  96%|█████████▌| 748/782 [06:22<00:16,  2.01it/s]\n",
      "Training:  96%|█████████▌| 749/782 [06:22<00:16,  2.00it/s]\n",
      "Training:  96%|█████████▌| 750/782 [06:23<00:15,  2.09it/s]\n",
      "Training:  96%|█████████▌| 751/782 [06:23<00:15,  1.99it/s]\n",
      "Training:  96%|█████████▌| 752/782 [06:24<00:15,  1.95it/s]\n",
      "Training:  96%|█████████▋| 753/782 [06:24<00:14,  1.98it/s]\n",
      "Training:  96%|█████████▋| 754/782 [06:25<00:14,  1.92it/s]\n",
      "Training:  97%|█████████▋| 755/782 [06:26<00:15,  1.73it/s]\n",
      "Training:  66%|██████▌   | 517/782 [06:35<03:01,  1.46it/s]\u001b[32m [repeated 141x across cluster]\u001b[0m\n",
      "Training:  97%|█████████▋| 756/782 [06:26<00:15,  1.72it/s]\n",
      "Training:  97%|█████████▋| 757/782 [06:27<00:13,  1.80it/s]\n",
      "Training:  97%|█████████▋| 758/782 [06:27<00:13,  1.73it/s]\n",
      "Training:  97%|█████████▋| 759/782 [06:28<00:12,  1.80it/s]\n",
      "Training:  97%|█████████▋| 760/782 [06:28<00:11,  1.89it/s]\n",
      "Training:  97%|█████████▋| 761/782 [06:29<00:10,  1.96it/s]\n",
      "Training:  97%|█████████▋| 762/782 [06:29<00:10,  1.99it/s]\n",
      "Training:  98%|█████████▊| 763/782 [06:30<00:09,  2.09it/s]\n",
      "Training:  98%|█████████▊| 764/782 [06:30<00:08,  2.15it/s]\n",
      "Training:  98%|█████████▊| 765/782 [06:31<00:07,  2.17it/s]\n",
      "Training:   5%|▌         | 43/782 [00:20<05:38,  2.19it/s]\u001b[32m [repeated 135x across cluster]\u001b[0m\n",
      "Training:  98%|█████████▊| 766/782 [06:31<00:07,  2.16it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Training:  68%|██████▊   | 532/782 [06:45<02:47,  1.49it/s]\u001b[32m [repeated 136x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▉| 776/782 [06:36<00:03,  1.98it/s]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "Training:  69%|██████▉   | 539/782 [06:50<03:04,  1.32it/s]\u001b[32m [repeated 134x across cluster]\u001b[0m\n",
      "Training:  93%|█████████▎| 731/782 [07:10<00:29,  1.71it/s]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "Training:  10%|▉         | 76/782 [00:35<05:04,  2.32it/s]\u001b[32m [repeated 132x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▍| 740/782 [07:15<00:23,  1.77it/s]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "Training:  67%|██████▋   | 524/782 [06:56<03:42,  1.16it/s]\u001b[32m [repeated 132x across cluster]\u001b[0m\n",
      "Training:  96%|█████████▌| 749/782 [07:20<00:18,  1.77it/s]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "Training:  12%|█▏        | 97/782 [00:45<05:24,  2.11it/s]\u001b[32m [repeated 132x across cluster]\u001b[0m\n",
      "Training:  97%|█████████▋| 758/782 [07:25<00:13,  1.84it/s]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "Training:  51%|█████     | 398/782 [06:50<06:05,  1.05it/s]\u001b[32m [repeated 129x across cluster]\u001b[0m\n",
      "Training:  98%|█████████▊| 767/782 [07:30<00:08,  1.81it/s]\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "Training:  51%|█████▏    | 402/782 [06:55<08:07,  1.28s/it]\u001b[32m [repeated 122x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▉| 776/782 [07:35<00:03,  1.71it/s]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "Training:  62%|██████▏   | 487/782 [07:23<04:28,  1.10it/s]\u001b[32m [repeated 125x across cluster]\u001b[0m\n",
      "Training:  94%|█████████▎| 732/782 [07:36<00:29,  1.72it/s]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860004)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860004)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  18%|█▊        | 140/782 [01:06<05:02,  2.12it/s]\u001b[32m [repeated 130x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▍| 740/782 [07:40<00:24,  1.72it/s]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "Training:  81%|████████  | 632/782 [07:51<01:50,  1.36it/s]\u001b[32m [repeated 124x across cluster]\u001b[0m\n",
      "Training:  92%|█████████▏| 721/782 [07:36<00:34,  1.77it/s]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "Training:  21%|██        | 161/782 [01:16<04:53,  2.12it/s]\u001b[32m [repeated 127x across cluster]\u001b[0m\n",
      "Training:  97%|█████████▋| 756/782 [07:51<00:19,  1.34it/s]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "Training:  55%|█████▍    | 427/782 [07:20<05:48,  1.02it/s]\u001b[32m [repeated 123x across cluster]\u001b[0m\n",
      "Training:  94%|█████████▍| 737/782 [07:46<00:26,  1.72it/s]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "Training:  81%|████████  | 630/782 [07:28<01:39,  1.53it/s]\u001b[32m [repeated 123x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▊| 772/782 [08:01<00:06,  1.64it/s]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "Training:  24%|██▍       | 191/782 [01:37<04:39,  2.12it/s]\u001b[32m [repeated 127x across cluster]\u001b[0m\n",
      "Training:  96%|█████████▋| 754/782 [07:56<00:16,  1.67it/s]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "Training:   7%|▋         | 56/782 [00:33<06:05,  1.99it/s]\u001b[32m [repeated 125x across cluster]\u001b[0m\n",
      "Training:  97%|█████████▋| 762/782 [08:01<00:12,  1.64it/s]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860007)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860007)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  87%|████████▋ | 684/782 [08:26<01:21,  1.20it/s]\u001b[32m [repeated 134x across cluster]\u001b[0m\n",
      "Training:  98%|█████████▊| 770/782 [08:06<00:07,  1.60it/s]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "Training:  30%|██▉       | 231/782 [01:46<03:39,  2.51it/s]\u001b[32m [repeated 131x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▉| 777/782 [08:11<00:03,  1.34it/s]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "Training:  11%|█         | 83/782 [00:48<05:45,  2.03it/s]\u001b[32m [repeated 138x across cluster]\u001b[0m\n",
      "Training: 100%|██████████| 782/782 [08:14<00:00,  1.58it/s]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "Training:  54%|█████▍    | 424/782 [02:54<02:28,  2.41it/s]\u001b[32m [repeated 131x across cluster]\u001b[0m\n",
      "Training:  92%|█████████▏| 719/782 [08:29<00:45,  1.37it/s]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "Training:  13%|█▎        | 104/782 [00:58<05:26,  2.08it/s]\u001b[32m [repeated 127x across cluster]\u001b[0m\n",
      "Training:  93%|█████████▎| 726/782 [08:34<00:38,  1.45it/s]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "Training:  35%|███▌      | 277/782 [02:06<03:37,  2.32it/s]\u001b[32m [repeated 126x across cluster]\u001b[0m\n",
      "Training:  94%|█████████▎| 732/782 [08:39<00:36,  1.38it/s]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860002)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860002)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  73%|███████▎  | 567/782 [08:34<03:00,  1.19it/s]\u001b[32m [repeated 120x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▍| 739/782 [08:44<00:34,  1.24it/s]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "Training:  38%|███▊      | 299/782 [02:16<03:42,  2.17it/s]\u001b[32m [repeated 109x across cluster]\u001b[0m\n",
      "Training:  93%|█████████▎| 725/782 [08:46<00:39,  1.45it/s]\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "Training:  84%|████████▎ | 654/782 [08:37<01:34,  1.35it/s]\u001b[32m [repeated 106x across cluster]\u001b[0m\n",
      "Training:  93%|█████████▎| 726/782 [09:02<00:43,  1.29it/s]\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "Training:  40%|███▉      | 311/782 [02:32<03:50,  2.05it/s]\u001b[32m [repeated 106x across cluster]\u001b[0m\n",
      "Training:  94%|█████████▍| 737/782 [09:12<00:39,  1.13it/s]\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1859998)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1859998)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  76%|███████▋  | 597/782 [09:02<02:45,  1.12it/s]\u001b[32m [repeated 102x across cluster]\u001b[0m\n",
      "Training:  98%|█████████▊| 768/782 [09:05<00:09,  1.45it/s]\u001b[32m [repeated 41x across cluster]\u001b[0m\n",
      "Training:  76%|███████▌  | 596/782 [08:59<02:34,  1.21it/s]\u001b[32m [repeated 105x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▉| 774/782 [09:10<00:06,  1.32it/s]\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "Training:  45%|████▌     | 355/782 [02:42<03:19,  2.15it/s]\u001b[32m [repeated 98x across cluster]\u001b[0m\n",
      "Training: 100%|██████████| 782/782 [09:15<00:00,  1.41it/s]\n",
      "Training:  93%|█████████▎| 725/782 [09:02<00:38,  1.48it/s]\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "Training:  25%|██▍       | 193/782 [01:44<04:54,  2.00it/s]\u001b[32m [repeated 104x across cluster]\u001b[0m\n",
      "Training:  97%|█████████▋| 756/782 [09:28<00:21,  1.19it/s]\u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "Training:   8%|▊         | 66/782 [00:41<07:03,  1.69it/s]\u001b[32m [repeated 100x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▉| 774/782 [09:21<00:05,  1.43it/s]\u001b[32m [repeated 41x across cluster]\u001b[0m\n",
      "Training:  71%|███████   | 556/782 [03:55<01:47,  2.10it/s]\u001b[32m [repeated 100x across cluster]\u001b[0m\n",
      "Training: 100%|██████████| 782/782 [09:26<00:00,  1.38it/s]\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "Training:  90%|█████████ | 705/782 [09:17<00:59,  1.30it/s]\u001b[32m [repeated 105x across cluster]\u001b[0m\n",
      "Training:  98%|█████████▊| 769/782 [09:04<00:08,  1.46it/s]\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "Training:  53%|█████▎    | 414/782 [03:07<02:58,  2.06it/s]\u001b[32m [repeated 99x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▉| 776/782 [09:09<00:04,  1.47it/s]\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "Training:  54%|█████▍    | 424/782 [03:12<03:12,  1.86it/s]\u001b[32m [repeated 97x across cluster]\u001b[0m\n",
      "Training:  92%|█████████▏| 718/782 [09:27<00:48,  1.33it/s]\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "Training:  10%|▉         | 77/782 [00:47<07:12,  1.63it/s]\u001b[32m [repeated 96x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▉| 776/782 [09:37<00:03,  1.53it/s]\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "Training:  53%|█████▎    | 415/782 [03:28<02:50,  2.15it/s]\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "Training:  93%|█████████▎| 730/782 [09:37<00:43,  1.20it/s]\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "Training:  59%|█████▊    | 458/782 [03:27<02:49,  1.91it/s]\u001b[32m [repeated 98x across cluster]\u001b[0m\n",
      "Training:  94%|█████████▍| 737/782 [09:42<00:32,  1.37it/s]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "Training:  82%|████████▏ | 644/782 [04:30<00:52,  2.62it/s]\u001b[32m [repeated 99x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▌| 744/782 [09:47<00:26,  1.43it/s]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860016)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860016)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  82%|████████▏ | 644/782 [10:19<02:05,  1.10it/s]\u001b[32m [repeated 98x across cluster]\u001b[0m\n",
      "Training:  96%|█████████▌| 751/782 [09:52<00:22,  1.39it/s]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860013)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860013)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  39%|███▉      | 304/782 [02:39<03:38,  2.19it/s]\u001b[32m [repeated 102x across cluster]\u001b[0m\n",
      "Training:  97%|█████████▋| 758/782 [09:57<00:16,  1.42it/s]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860017)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860017)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  87%|████████▋ | 677/782 [10:18<01:42,  1.03it/s]\u001b[32m [repeated 113x across cluster]\u001b[0m\n",
      "Training:  98%|█████████▊| 765/782 [10:02<00:12,  1.36it/s]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860001)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860001)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  84%|████████▍ | 660/782 [10:35<01:59,  1.02it/s]\u001b[32m [repeated 120x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▊| 772/782 [10:08<00:07,  1.33it/s]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860015)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860015)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  68%|██████▊   | 529/782 [03:58<01:38,  2.58it/s]\u001b[32m [repeated 126x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▉| 778/782 [10:12<00:03,  1.24it/s]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860009)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860009)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:   2%|▏         | 14/782 [00:12<11:18,  1.13it/s]\u001b[32m [repeated 127x across cluster]\u001b[0m\n",
      "Training:  92%|█████████▏| 720/782 [05:01<00:24,  2.54it/s]\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860012)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1860012)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  45%|████▍     | 350/782 [03:05<04:01,  1.79it/s]\u001b[32m [repeated 125x across cluster]\u001b[0m\n",
      "Training:  94%|█████████▎| 732/782 [05:06<00:18,  2.64it/s]\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "Training:  72%|███████▏  | 566/782 [04:13<01:26,  2.50it/s]\u001b[32m [repeated 132x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▌| 746/782 [05:11<00:13,  2.63it/s]\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "Training:  85%|████████▌ | 666/782 [10:54<01:53,  1.02it/s]\u001b[32m [repeated 131x across cluster]\u001b[0m\n",
      "Training:  97%|█████████▋| 758/782 [05:16<00:09,  2.56it/s]\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "Training:   2%|▏         | 19/782 [00:15<09:22,  1.36it/s]\u001b[32m [repeated 124x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▊| 772/782 [05:21<00:03,  2.63it/s]\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "Training:   9%|▉         | 73/782 [00:52<08:42,  1.36it/s]\u001b[32m [repeated 120x across cluster]\u001b[0m\n",
      "Training:  92%|█████████▏| 719/782 [10:59<00:58,  1.08it/s]\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "Training:  10%|█         | 80/782 [00:57<08:03,  1.45it/s]\u001b[32m [repeated 123x across cluster]\u001b[0m\n",
      "Training:  93%|█████████▎| 725/782 [11:04<00:48,  1.17it/s]\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "Training:  30%|███       | 237/782 [02:28<05:11,  1.75it/s]\u001b[32m [repeated 120x across cluster]\u001b[0m\n",
      "Training:  94%|█████████▍| 736/782 [11:01<00:39,  1.16it/s]\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "Training:  82%|████████▏ | 641/782 [04:43<00:57,  2.47it/s]\u001b[32m [repeated 119x across cluster]\u001b[0m\n",
      "Training:  94%|█████████▍| 736/782 [11:14<00:40,  1.13it/s]\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "Training:  83%|████████▎ | 652/782 [04:48<01:01,  2.12it/s]\u001b[32m [repeated 119x across cluster]\u001b[0m\n",
      "Training:  91%|█████████▏| 715/782 [11:30<01:14,  1.11s/it]\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1859999)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1859999)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  10%|▉         | 78/782 [01:02<08:52,  1.32it/s]\u001b[32m [repeated 123x across cluster]\u001b[0m\n",
      "Training:  96%|█████████▌| 747/782 [11:24<00:32,  1.08it/s]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  78%|███████▊  | 611/782 [05:04<01:22,  2.08it/s]\u001b[32m [repeated 136x across cluster]\u001b[0m\n",
      "Training:  93%|█████████▎| 724/782 [11:40<01:03,  1.09s/it]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "Training:  11%|█         | 84/782 [01:04<07:52,  1.48it/s]\u001b[32m [repeated 135x across cluster]\u001b[0m\n",
      "Training:  97%|█████████▋| 758/782 [11:34<00:22,  1.08it/s]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "Training:  60%|█████▉    | 469/782 [04:05<02:25,  2.16it/s]\u001b[32m [repeated 125x across cluster]\u001b[0m\n",
      "Training:  94%|█████████▎| 733/782 [11:50<00:51,  1.05s/it]\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m [2025-10-19 16:29:08,176 E 1857549 1857549] (raylet) node_manager.cc:2929: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 96bc6d0858006189c483e3db21548cc8885f0919fd9d426ed3d5929e, IP: 10.82.72.122) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.82.72.122`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "Training:  61%|██████▏   | 479/782 [04:10<02:22,  2.12it/s]\u001b[32m [repeated 124x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▉| 775/782 [11:36<00:05,  1.21it/s]\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "Training:  13%|█▎        | 100/782 [01:11<07:25,  1.53it/s]\u001b[32m [repeated 115x across cluster]\u001b[0m\n",
      "Training:  93%|█████████▎| 726/782 [05:19<00:21,  2.55it/s]\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 1/782 [00:00<04:30,  2.89it/s]\n",
      "Training:   0%|          | 2/782 [00:00<03:13,  4.02it/s]\n",
      "Training:   0%|          | 3/782 [00:00<02:49,  4.60it/s]\n",
      "Training:   1%|          | 4/782 [00:00<02:31,  5.15it/s]\n",
      "Training:   1%|          | 5/782 [00:01<02:18,  5.60it/s]\n",
      "Training:   1%|          | 6/782 [00:01<02:12,  5.85it/s]\n",
      "Training:   1%|          | 7/782 [00:01<02:11,  5.89it/s]\n",
      "Training:   1%|          | 8/782 [00:01<02:08,  6.01it/s]\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "Training:   1%|          | 5/782 [00:01<03:33,  3.63it/s]\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "Training:   5%|▌         | 43/782 [00:07<02:41,  4.58it/s]\u001b[32m [repeated 133x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Training:   4%|▍         | 35/782 [00:11<04:44,  2.62it/s]\u001b[32m [repeated 142x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "Training:  11%|█         | 84/782 [00:20<04:02,  2.88it/s]\u001b[32m [repeated 142x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Training:  12%|█▏        | 90/782 [00:24<05:02,  2.29it/s]\u001b[32m [repeated 145x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Training:   3%|▎         | 24/782 [00:10<06:57,  1.81it/s]\u001b[32m [repeated 135x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Training:   4%|▍         | 33/782 [00:16<06:47,  1.84it/s]\u001b[32m [repeated 148x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  14%|█▍        | 111/782 [00:33<04:41,  2.39it/s]\u001b[32m [repeated 150x across cluster]\u001b[0m\n",
      "Training:  16%|█▌        | 123/782 [00:39<04:39,  2.36it/s]\u001b[32m [repeated 150x across cluster]\u001b[0m\n",
      "Training:   7%|▋         | 56/782 [00:33<08:01,  1.51it/s]\u001b[32m [repeated 153x across cluster]\u001b[0m\n",
      "Training:   8%|▊         | 61/782 [00:42<09:36,  1.25it/s]\u001b[32m [repeated 153x across cluster]\u001b[0m\n",
      "Training:  20%|██        | 157/782 [00:59<05:33,  1.88it/s]\u001b[32m [repeated 152x across cluster]\u001b[0m\n",
      "Training:  22%|██▏       | 174/782 [00:59<03:56,  2.57it/s]\u001b[32m [repeated 149x across cluster]\u001b[0m\n",
      "Training:  12%|█▏        | 93/782 [01:01<08:52,  1.29it/s]\u001b[32m [repeated 149x across cluster]\u001b[0m\n",
      "Training:  24%|██▎       | 184/782 [01:16<05:47,  1.72it/s]\u001b[32m [repeated 153x across cluster]\u001b[0m\n",
      "Training:  27%|██▋       | 211/782 [01:14<03:51,  2.47it/s]\u001b[32m [repeated 154x across cluster]\u001b[0m\n",
      "Training:  29%|██▊       | 224/782 [01:19<03:38,  2.56it/s]\u001b[32m [repeated 148x across cluster]\u001b[0m\n",
      "Training:  10%|▉         | 75/782 [00:54<08:10,  1.44it/s]\u001b[32m [repeated 155x across cluster]\u001b[0m\n",
      "Training:  20%|█▉        | 154/782 [01:32<07:18,  1.43it/s]\u001b[32m [repeated 154x across cluster]\u001b[0m\n",
      "Training:  21%|██        | 161/782 [01:37<07:28,  1.38it/s]\u001b[32m [repeated 154x across cluster]\u001b[0m\n",
      "Training:  35%|███▌      | 274/782 [01:39<03:23,  2.50it/s]\u001b[32m [repeated 149x across cluster]\u001b[0m\n",
      "Training:  22%|██▏       | 174/782 [01:47<07:42,  1.31it/s]\u001b[32m [repeated 152x across cluster]\u001b[0m\n",
      "Training:  33%|███▎      | 259/782 [01:55<04:40,  1.87it/s]\u001b[32m [repeated 152x across cluster]\u001b[0m\n",
      "Training:  26%|██▌       | 202/782 [01:56<06:37,  1.46it/s]\u001b[32m [repeated 153x across cluster]\u001b[0m\n",
      "Training:  25%|██▍       | 194/782 [02:02<08:00,  1.22it/s]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  23%|██▎       | 177/782 [01:54<06:56,  1.45it/s]\u001b[32m [repeated 153x across cluster]\u001b[0m\n",
      "Training:  17%|█▋        | 132/782 [01:43<08:18,  1.30it/s]\u001b[32m [repeated 152x across cluster]\u001b[0m\n",
      "Training:  39%|███▉      | 304/782 [02:22<04:10,  1.91it/s]\u001b[32m [repeated 150x across cluster]\u001b[0m\n",
      "Training:  28%|██▊       | 221/782 [02:23<06:52,  1.36it/s]\u001b[32m [repeated 153x across cluster]\u001b[0m\n",
      "Training:  26%|██▋       | 206/782 [02:14<06:24,  1.50it/s]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  51%|█████     | 400/782 [02:30<02:21,  2.70it/s]\u001b[32m [repeated 152x across cluster]\u001b[0m\n",
      "Training:  53%|█████▎    | 414/782 [02:35<02:14,  2.74it/s]\u001b[32m [repeated 150x across cluster]\u001b[0m\n",
      "Training:  23%|██▎       | 183/782 [02:11<06:50,  1.46it/s]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  27%|██▋       | 208/782 [02:30<06:51,  1.39it/s]\u001b[32m [repeated 143x across cluster]\u001b[0m\n",
      "Training:  34%|███▎      | 263/782 [02:38<05:41,  1.52it/s]\u001b[32m [repeated 152x across cluster]\u001b[0m\n",
      "Training:  59%|█████▉    | 461/782 [02:55<02:23,  2.24it/s]\u001b[32m [repeated 148x across cluster]\u001b[0m\n",
      "Training:  29%|██▊       | 224/782 [02:54<08:44,  1.06it/s]\u001b[32m [repeated 149x across cluster]\u001b[0m\n",
      "Training:  56%|█████▌    | 435/782 [03:10<02:36,  2.21it/s]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  47%|████▋     | 367/782 [02:49<03:13,  2.14it/s]\u001b[32m [repeated 147x across cluster]\u001b[0m\n",
      "Training:  32%|███▏      | 250/782 [03:01<06:42,  1.32it/s]\u001b[32m [repeated 149x across cluster]\u001b[0m\n",
      "Training:  29%|██▉       | 226/782 [02:54<07:19,  1.27it/s]\u001b[32m [repeated 150x across cluster]\u001b[0m\n",
      "Training:  33%|███▎      | 255/782 [03:19<06:55,  1.27it/s]\u001b[32m [repeated 153x across cluster]\u001b[0m\n",
      "Training:  34%|███▎      | 262/782 [03:24<06:27,  1.34it/s]\u001b[32m [repeated 150x across cluster]\u001b[0m\n",
      "Training:  57%|█████▋    | 449/782 [03:43<02:50,  1.95it/s]\u001b[32m [repeated 153x across cluster]\u001b[0m\n",
      "Training:  32%|███▏      | 252/782 [03:14<07:11,  1.23it/s]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  75%|███████▍  | 585/782 [03:46<01:13,  2.67it/s]\u001b[32m [repeated 148x across cluster]\u001b[0m\n",
      "Training:  61%|██████    | 475/782 [03:57<03:18,  1.55it/s]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  43%|████▎     | 338/782 [03:45<04:42,  1.57it/s]\u001b[32m [repeated 150x across cluster]\u001b[0m\n",
      "Training:  38%|███▊      | 300/782 [03:54<05:53,  1.36it/s]\u001b[32m [repeated 148x across cluster]\u001b[0m\n",
      "Training:  37%|███▋      | 286/782 [03:39<06:05,  1.36it/s]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  32%|███▏      | 253/782 [04:06<08:26,  1.04it/s]\u001b[32m [repeated 155x across cluster]\u001b[0m\n",
      "Training:  85%|████████▍ | 662/782 [04:16<00:46,  2.56it/s]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  41%|████▏     | 323/782 [03:52<05:22,  1.42it/s]\u001b[32m [repeated 154x across cluster]\u001b[0m\n",
      "Training:  50%|█████     | 392/782 [04:29<04:34,  1.42it/s]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  41%|████      | 320/782 [04:05<06:01,  1.28it/s]\u001b[32m [repeated 154x across cluster]\u001b[0m\n",
      "Training:  91%|█████████▏| 714/782 [04:36<00:26,  2.56it/s]\n",
      "Training:  91%|█████████▏| 715/782 [04:37<00:26,  2.54it/s]\n",
      "Training:  42%|████▏     | 327/782 [04:10<05:30,  1.38it/s]\u001b[32m [repeated 149x across cluster]\u001b[0m\n",
      "Training:  92%|█████████▏| 716/782 [04:37<00:26,  2.45it/s]\n",
      "Training:  92%|█████████▏| 717/782 [04:37<00:27,  2.39it/s]\n",
      "Training:  92%|█████████▏| 718/782 [04:38<00:26,  2.40it/s]\n",
      "Training:  92%|█████████▏| 719/782 [04:38<00:26,  2.42it/s]\n",
      "Training:  92%|█████████▏| 720/782 [04:39<00:24,  2.52it/s]\n",
      "Training:  92%|█████████▏| 721/782 [04:39<00:23,  2.61it/s]\n",
      "Training:  92%|█████████▏| 722/782 [04:39<00:22,  2.62it/s]\n",
      "Training:  92%|█████████▏| 723/782 [04:40<00:23,  2.49it/s]\n",
      "Training:  93%|█████████▎| 724/782 [04:40<00:24,  2.38it/s]\n",
      "Training:  93%|█████████▎| 725/782 [04:41<00:22,  2.49it/s]\n",
      "Training:  93%|█████████▎| 726/782 [04:41<00:22,  2.46it/s]\n",
      "Training:  93%|█████████▎| 727/782 [04:41<00:22,  2.44it/s]\n",
      "Training:  56%|█████▌    | 436/782 [04:29<03:24,  1.69it/s]\u001b[32m [repeated 139x across cluster]\u001b[0m\n",
      "Training:  93%|█████████▎| 728/782 [04:42<00:22,  2.45it/s]\n",
      "Training:  93%|█████████▎| 729/782 [04:42<00:21,  2.47it/s]\n",
      "Training:  93%|█████████▎| 730/782 [04:43<00:21,  2.46it/s]\n",
      "Training:  93%|█████████▎| 731/782 [04:43<00:20,  2.45it/s]\n",
      "Training:  94%|█████████▎| 732/782 [04:44<00:20,  2.43it/s]\n",
      "Training:  94%|█████████▎| 733/782 [04:44<00:20,  2.43it/s]\n",
      "Training:  94%|█████████▍| 734/782 [04:44<00:18,  2.54it/s]\n",
      "Training:  94%|█████████▍| 735/782 [04:45<00:18,  2.57it/s]\n",
      "Training:  94%|█████████▍| 736/782 [04:45<00:18,  2.53it/s]\n",
      "Training:  94%|█████████▍| 737/782 [04:45<00:17,  2.62it/s]\n",
      "Training:  94%|█████████▍| 738/782 [04:46<00:17,  2.46it/s]\n",
      "Training:  95%|█████████▍| 739/782 [04:46<00:18,  2.37it/s]\n",
      "Training:  95%|█████████▍| 740/782 [04:47<00:17,  2.36it/s]\n",
      "Training:  51%|█████     | 395/782 [04:44<04:43,  1.36it/s]\u001b[32m [repeated 135x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▍| 741/782 [04:47<00:17,  2.37it/s]\n",
      "Training:  95%|█████████▍| 742/782 [04:48<00:15,  2.51it/s]\n",
      "Training:  95%|█████████▌| 743/782 [04:48<00:17,  2.22it/s]\n",
      "Training:  95%|█████████▌| 744/782 [04:49<00:18,  2.06it/s]\n",
      "Training:  95%|█████████▌| 745/782 [04:49<00:18,  1.96it/s]\n",
      "Training:  95%|█████████▌| 746/782 [04:50<00:16,  2.15it/s]\n",
      "Training:  96%|█████████▌| 747/782 [04:50<00:15,  2.20it/s]\n",
      "Training:  96%|█████████▌| 748/782 [04:50<00:14,  2.33it/s]\n",
      "Training:  96%|█████████▌| 749/782 [04:51<00:14,  2.30it/s]\n",
      "Training:  96%|█████████▌| 750/782 [04:51<00:13,  2.36it/s]\n",
      "Training:  96%|█████████▌| 751/782 [04:52<00:12,  2.40it/s]\n",
      "Training:  46%|████▌     | 361/782 [04:22<06:17,  1.11it/s]\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
      "Training:  96%|█████████▌| 752/782 [04:52<00:12,  2.49it/s]\n",
      "Training:  96%|█████████▋| 753/782 [04:52<00:11,  2.48it/s]\n",
      "Training:  96%|█████████▋| 754/782 [04:53<00:11,  2.49it/s]\n",
      "Training:  97%|█████████▋| 755/782 [04:53<00:10,  2.54it/s]\n",
      "Training:  97%|█████████▋| 756/782 [04:54<00:10,  2.45it/s]\n",
      "Training:  97%|█████████▋| 757/782 [04:54<00:10,  2.46it/s]\n",
      "Training:  97%|█████████▋| 758/782 [04:54<00:09,  2.50it/s]\n",
      "Training:  97%|█████████▋| 759/782 [04:55<00:09,  2.51it/s]\n",
      "Training:  97%|█████████▋| 760/782 [04:55<00:08,  2.48it/s]\n",
      "Training:  97%|█████████▋| 761/782 [04:56<00:08,  2.43it/s]\n",
      "Training:  97%|█████████▋| 762/782 [04:56<00:08,  2.46it/s]\n",
      "Training:  98%|█████████▊| 763/782 [04:56<00:07,  2.42it/s]\n",
      "Training:  98%|█████████▊| 764/782 [04:57<00:07,  2.45it/s]\n",
      "Training:  47%|████▋     | 369/782 [04:50<05:31,  1.24it/s]\u001b[32m [repeated 140x across cluster]\u001b[0m\n",
      "Training:  98%|█████████▊| 765/782 [04:57<00:06,  2.52it/s]\n",
      "Training:  98%|█████████▊| 766/782 [04:58<00:06,  2.48it/s]\n",
      "Training:  98%|█████████▊| 767/782 [04:58<00:05,  2.50it/s]\n",
      "Training:  98%|█████████▊| 768/782 [04:58<00:05,  2.50it/s]\n",
      "Training:  98%|█████████▊| 769/782 [04:59<00:05,  2.54it/s]\n",
      "Training:  98%|█████████▊| 770/782 [04:59<00:04,  2.59it/s]\n",
      "Training:  99%|█████████▊| 771/782 [05:00<00:04,  2.53it/s]\n",
      "Training:  99%|█████████▊| 772/782 [05:00<00:04,  2.38it/s]\n",
      "Training:  99%|█████████▉| 773/782 [05:00<00:03,  2.45it/s]\n",
      "Training:  99%|█████████▉| 774/782 [05:01<00:03,  2.53it/s]\n",
      "Training:  99%|█████████▉| 775/782 [05:01<00:02,  2.59it/s]\n",
      "Training:  99%|█████████▉| 776/782 [05:02<00:02,  2.20it/s]\n",
      "Training:  48%|████▊     | 375/782 [04:55<05:36,  1.21it/s]\u001b[32m [repeated 141x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▉| 777/782 [05:02<00:02,  2.21it/s]\n",
      "Training:  99%|█████████▉| 778/782 [05:03<00:01,  2.37it/s]\n",
      "Training: 100%|█████████▉| 779/782 [05:03<00:01,  2.40it/s]\n",
      "Training: 100%|█████████▉| 780/782 [05:03<00:00,  2.51it/s]\n",
      "Training: 100%|█████████▉| 781/782 [05:04<00:00,  2.51it/s]\n",
      "Training: 100%|██████████| 782/782 [05:04<00:00,  2.57it/s]\n",
      "Training:  49%|████▊     | 381/782 [05:00<05:42,  1.17it/s]\u001b[32m [repeated 136x across cluster]\u001b[0m\n",
      "Training:  52%|█████▏    | 408/782 [04:57<04:04,  1.53it/s]\u001b[32m [repeated 141x across cluster]\u001b[0m\n",
      "Training:  56%|█████▌    | 435/782 [05:14<04:15,  1.36it/s]\u001b[32m [repeated 139x across cluster]\u001b[0m\n",
      "Training:  91%|█████████▏| 714/782 [05:24<00:31,  2.13it/s]\n",
      "Training:  91%|█████████▏| 715/782 [05:24<00:30,  2.20it/s]\n",
      "Training:  92%|█████████▏| 716/782 [05:25<00:33,  1.98it/s]\n",
      "Training:  92%|█████████▏| 717/782 [05:25<00:37,  1.76it/s]\n",
      "Training:  92%|█████████▏| 718/782 [05:26<00:35,  1.80it/s]\n",
      "Training:  54%|█████▍    | 423/782 [05:07<04:01,  1.49it/s]\u001b[32m [repeated 132x across cluster]\u001b[0m\n",
      "Training:  92%|█████████▏| 719/782 [05:26<00:32,  1.94it/s]\n",
      "Training:  92%|█████████▏| 720/782 [05:27<00:30,  2.05it/s]\n",
      "Training:  92%|█████████▏| 721/782 [05:27<00:28,  2.13it/s]\n",
      "Training:  92%|█████████▏| 722/782 [05:28<00:28,  2.11it/s]\n",
      "Training:  92%|█████████▏| 723/782 [05:28<00:27,  2.13it/s]\n",
      "Training:  93%|█████████▎| 724/782 [05:29<00:27,  2.10it/s]\n",
      "Training:  93%|█████████▎| 725/782 [05:29<00:27,  2.11it/s]\n",
      "Training:  93%|█████████▎| 726/782 [05:30<00:26,  2.13it/s]\n",
      "Training:  93%|█████████▎| 727/782 [05:30<00:25,  2.16it/s]\n",
      "Training:  93%|█████████▎| 728/782 [05:30<00:24,  2.17it/s]\n",
      "Training:  93%|█████████▎| 729/782 [05:31<00:30,  1.73it/s]\n",
      "Training:  82%|████████▏ | 642/782 [05:33<01:17,  1.81it/s]\u001b[32m [repeated 131x across cluster]\u001b[0m\n",
      "Training:  93%|█████████▎| 730/782 [05:32<00:27,  1.89it/s]\n",
      "Training:  93%|█████████▎| 731/782 [05:32<00:26,  1.93it/s]\n",
      "Training:  94%|█████████▎| 732/782 [05:33<00:24,  2.01it/s]\n",
      "Training:  94%|█████████▎| 733/782 [05:33<00:24,  1.96it/s]\n",
      "Training:  94%|█████████▍| 734/782 [05:34<00:24,  1.99it/s]\n",
      "Training:  94%|█████████▍| 735/782 [05:34<00:23,  2.04it/s]\n",
      "Training:  94%|█████████▍| 736/782 [05:35<00:21,  2.11it/s]\n",
      "Training:  94%|█████████▍| 737/782 [05:35<00:20,  2.15it/s]\n",
      "Training:  94%|█████████▍| 738/782 [05:35<00:20,  2.14it/s]\n",
      "Training:  95%|█████████▍| 739/782 [05:36<00:19,  2.15it/s]\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864770)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864770)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  95%|█████████▍| 740/782 [05:36<00:19,  2.18it/s]\n",
      "Training:  62%|██████▏   | 483/782 [05:35<04:02,  1.23it/s]\u001b[32m [repeated 127x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▍| 741/782 [05:37<00:18,  2.19it/s]\n",
      "Training:  95%|█████████▍| 742/782 [05:37<00:17,  2.24it/s]\n",
      "Training:  95%|█████████▌| 743/782 [05:38<00:17,  2.19it/s]\n",
      "Training:  95%|█████████▌| 744/782 [05:38<00:17,  2.12it/s]\n",
      "Training:  95%|█████████▌| 745/782 [05:39<00:17,  2.12it/s]\n",
      "Training:  95%|█████████▌| 746/782 [05:39<00:16,  2.14it/s]\n",
      "Training:  96%|█████████▌| 747/782 [05:40<00:16,  2.15it/s]\n",
      "Training:  96%|█████████▌| 748/782 [05:40<00:16,  2.08it/s]\n",
      "Training:  96%|█████████▌| 749/782 [05:41<00:17,  1.89it/s]\n",
      "Training:  96%|█████████▌| 750/782 [05:41<00:17,  1.83it/s]\n",
      "Training:   1%|▏         | 11/782 [00:05<05:29,  2.34it/s]\u001b[32m [repeated 139x across cluster]\u001b[0m\n",
      "Training:  96%|█████████▌| 751/782 [05:42<00:17,  1.77it/s]\n",
      "Training:  96%|█████████▌| 752/782 [05:43<00:17,  1.69it/s]\n",
      "Training:  96%|█████████▋| 753/782 [05:43<00:17,  1.68it/s]\n",
      "Training:  96%|█████████▋| 754/782 [05:44<00:16,  1.71it/s]\n",
      "Training:  97%|█████████▋| 755/782 [05:44<00:15,  1.78it/s]\n",
      "Training:  97%|█████████▋| 756/782 [05:45<00:13,  1.91it/s]\n",
      "Training:  97%|█████████▋| 757/782 [05:45<00:12,  2.01it/s]\n",
      "Training:  97%|█████████▋| 758/782 [05:46<00:11,  2.02it/s]\n",
      "Training:  97%|█████████▋| 759/782 [05:46<00:11,  1.96it/s]\n",
      "Training:   3%|▎         | 23/782 [00:10<04:53,  2.59it/s]\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
      "Training:  97%|█████████▋| 760/782 [05:47<00:11,  1.91it/s]\n",
      "Training:  97%|█████████▋| 761/782 [05:47<00:11,  1.83it/s]\n",
      "Training:  97%|█████████▋| 762/782 [05:48<00:12,  1.63it/s]\n",
      "Training:  98%|█████████▊| 763/782 [05:49<00:12,  1.55it/s]\n",
      "Training:  98%|█████████▊| 764/782 [05:49<00:10,  1.64it/s]\n",
      "Training:  98%|█████████▊| 765/782 [05:50<00:10,  1.64it/s]\n",
      "Training:  98%|█████████▊| 766/782 [05:50<00:08,  1.79it/s]\n",
      "Training:  98%|█████████▊| 767/782 [05:51<00:07,  1.92it/s]\n",
      "Training:  98%|█████████▊| 768/782 [05:51<00:07,  2.00it/s]\n",
      "Training:  65%|██████▌   | 510/782 [05:37<02:56,  1.54it/s]\u001b[32m [repeated 136x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▉| 773/782 [05:54<00:04,  1.90it/s]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "Training:  55%|█████▌    | 434/782 [05:46<04:58,  1.17it/s]\u001b[32m [repeated 130x across cluster]\u001b[0m\n",
      "Training:  93%|█████████▎| 728/782 [05:33<00:31,  1.74it/s]\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "Training:   8%|▊         | 61/782 [00:25<05:04,  2.36it/s]\u001b[32m [repeated 133x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▍| 739/782 [05:38<00:19,  2.23it/s]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "Training:  72%|███████▏  | 566/782 [05:50<02:18,  1.56it/s]\u001b[32m [repeated 129x across cluster]\u001b[0m\n",
      "Training:  96%|█████████▌| 750/782 [05:43<00:14,  2.28it/s]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "Training:  69%|██████▉   | 539/782 [05:57<02:51,  1.42it/s]\u001b[32m [repeated 118x across cluster]\u001b[0m\n",
      "Training:  97%|█████████▋| 762/782 [05:48<00:08,  2.29it/s]\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "Training:  88%|████████▊ | 692/782 [06:11<00:49,  1.82it/s]\u001b[32m [repeated 113x across cluster]\u001b[0m\n",
      "Training:  94%|█████████▍| 736/782 [06:22<00:28,  1.60it/s]\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "Training:  64%|██████▎   | 498/782 [06:03<03:05,  1.53it/s]\u001b[32m [repeated 111x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▌| 745/782 [06:27<00:20,  1.85it/s]\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "Training:  60%|██████    | 471/782 [06:16<03:55,  1.32it/s]\u001b[32m [repeated 110x across cluster]\u001b[0m\n",
      "Training:  91%|█████████▏| 715/782 [06:23<00:34,  1.96it/s]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864844)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864844)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  50%|█████     | 391/782 [06:04<05:47,  1.13it/s]\u001b[32m [repeated 109x across cluster]\u001b[0m\n",
      "Training:  97%|█████████▋| 755/782 [06:36<00:16,  1.67it/s]\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "Training:  73%|███████▎  | 567/782 [06:36<02:26,  1.47it/s]\u001b[32m [repeated 111x across cluster]\u001b[0m\n",
      "Training:  98%|█████████▊| 770/782 [06:42<00:06,  1.83it/s]\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "Training:  79%|███████▉  | 620/782 [06:25<01:48,  1.50it/s]\u001b[32m [repeated 111x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▍| 742/782 [06:39<00:21,  1.86it/s]\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "Training:  76%|███████▌  | 593/782 [06:32<01:58,  1.59it/s]\u001b[32m [repeated 115x across cluster]\u001b[0m\n",
      "Training:  96%|█████████▌| 751/782 [06:44<00:17,  1.82it/s]\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "Training:  64%|██████▍   | 500/782 [06:42<04:10,  1.13it/s]\u001b[32m [repeated 108x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864873)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864873)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  97%|█████████▋| 760/782 [06:48<00:11,  1.91it/s]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "Training:  78%|███████▊  | 608/782 [06:43<01:57,  1.48it/s]\u001b[32m [repeated 119x across cluster]\u001b[0m\n",
      "Training:  98%|█████████▊| 769/782 [06:53<00:07,  1.83it/s]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "Training:  71%|███████   | 555/782 [06:43<03:03,  1.24it/s]\u001b[32m [repeated 123x across cluster]\u001b[0m\n",
      "Training: 100%|█████████▉| 779/782 [06:59<00:01,  1.95it/s]\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "Training:  78%|███████▊  | 608/782 [07:06<02:08,  1.35it/s]\u001b[32m [repeated 124x across cluster]\u001b[0m\n",
      "Training: 100%|██████████| 782/782 [07:00<00:00,  1.86it/s]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "Training:  73%|███████▎  | 570/782 [06:54<02:27,  1.44it/s]\u001b[32m [repeated 120x across cluster]\u001b[0m\n",
      "Training:  68%|██████▊   | 529/782 [07:07<03:44,  1.13it/s]\u001b[32m [repeated 123x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864856)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864856)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  53%|█████▎    | 416/782 [06:59<06:45,  1.11s/it]\u001b[32m [repeated 127x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864890)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864890)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  71%|███████   | 552/782 [06:57<02:47,  1.38it/s]\u001b[32m [repeated 136x across cluster]\u001b[0m\n",
      "Training:  71%|███████▏  | 559/782 [07:02<02:40,  1.39it/s]\u001b[32m [repeated 140x across cluster]\u001b[0m\n",
      "Training:  71%|███████   | 556/782 [07:27<02:47,  1.35it/s]\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
      "Training:  91%|█████████▏| 714/782 [07:37<00:42,  1.61it/s]\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864832)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864832)\u001b[0m   _log_deprecation_warning(\n",
      "Training:  91%|█████████▏| 715/782 [07:38<00:42,  1.59it/s]\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  92%|█████████▏| 716/782 [07:38<00:40,  1.62it/s]\n",
      "Training:  92%|█████████▏| 717/782 [07:39<00:41,  1.57it/s]\n",
      "Training:  92%|█████████▏| 718/782 [07:40<00:39,  1.60it/s]\n",
      "Training:  72%|███████▏  | 563/782 [07:32<02:43,  1.34it/s]\u001b[32m [repeated 135x across cluster]\u001b[0m\n",
      "Training:  92%|█████████▏| 718/782 [07:28<00:34,  1.84it/s]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "Training:  74%|███████▍  | 579/782 [07:17<02:24,  1.41it/s]\u001b[32m [repeated 136x across cluster]\u001b[0m\n",
      "Training:  93%|█████████▎| 726/782 [07:33<00:36,  1.55it/s]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "Training:  42%|████▏     | 331/782 [02:17<03:11,  2.36it/s]\u001b[32m [repeated 140x across cluster]\u001b[0m\n",
      "Training:  94%|█████████▍| 736/782 [07:52<00:28,  1.60it/s]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "Training:  22%|██▏       | 171/782 [01:27<04:33,  2.24it/s]\u001b[32m [repeated 136x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▌| 745/782 [07:43<00:19,  1.91it/s]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "Training:  90%|█████████ | 705/782 [07:48<00:54,  1.42it/s]\u001b[32m [repeated 136x across cluster]\u001b[0m\n",
      "Training:  96%|█████████▋| 753/782 [07:48<00:16,  1.73it/s]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "Training:  47%|████▋     | 370/782 [02:32<02:59,  2.30it/s]\u001b[32m [repeated 137x across cluster]\u001b[0m\n",
      "Training:  97%|█████████▋| 758/782 [08:07<00:16,  1.45it/s]\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "Training:  78%|███████▊  | 613/782 [07:42<01:52,  1.50it/s]\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
      "Training:  98%|█████████▊| 765/782 [08:12<00:11,  1.50it/s]\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "Training:  50%|█████     | 393/782 [02:42<02:54,  2.23it/s]\u001b[32m [repeated 129x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▉| 778/782 [08:03<00:02,  1.61it/s]\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "Training:  80%|████████  | 627/782 [07:52<01:50,  1.41it/s]\u001b[32m [repeated 126x across cluster]\u001b[0m\n",
      "Training: 100%|█████████▉| 780/782 [08:22<00:01,  1.38it/s]\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "Training:  81%|████████  | 634/782 [07:57<01:51,  1.33it/s]\u001b[32m [repeated 120x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▌| 746/782 [08:15<00:23,  1.55it/s]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "Training:  88%|████████▊ | 692/782 [08:26<01:03,  1.42it/s]\u001b[32m [repeated 121x across cluster]\u001b[0m\n",
      "Training:  93%|█████████▎| 730/782 [08:34<00:37,  1.39it/s]\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "Training:  16%|█▋        | 129/782 [01:16<05:25,  2.00it/s]\u001b[32m [repeated 122x across cluster]\u001b[0m\n",
      "Training:  97%|█████████▋| 762/782 [08:25<00:11,  1.67it/s]\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "Training:  57%|█████▋    | 448/782 [03:07<02:52,  1.93it/s]\u001b[32m [repeated 118x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▌| 744/782 [08:44<00:26,  1.46it/s]\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "Training:  31%|███       | 243/782 [01:56<04:06,  2.19it/s]\u001b[32m [repeated 117x across cluster]\u001b[0m\n",
      "Training:  91%|█████████▏| 714/782 [08:43<01:05,  1.04it/s]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "Training:  60%|█████▉    | 468/782 [03:17<02:08,  2.44it/s]\u001b[32m [repeated 107x across cluster]\u001b[0m\n",
      "Training:  97%|█████████▋| 758/782 [08:54<00:16,  1.47it/s]\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "Training:  61%|██████▏   | 480/782 [03:22<02:31,  2.00it/s]\u001b[32m [repeated 106x across cluster]\u001b[0m\n",
      "Training:  98%|█████████▊| 765/782 [08:59<00:12,  1.39it/s]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "Training:  63%|██████▎   | 492/782 [03:27<01:53,  2.55it/s]\u001b[32m [repeated 106x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864867)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864867)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  99%|█████████▊| 772/782 [09:04<00:06,  1.46it/s]\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "Training:  91%|█████████ | 711/782 [08:35<00:54,  1.29it/s]\u001b[32m [repeated 116x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864850)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864850)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training: 100%|█████████▉| 779/782 [09:09<00:02,  1.30it/s]\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "Training:  77%|███████▋  | 604/782 [09:01<02:27,  1.21it/s]\u001b[32m [repeated 119x across cluster]\u001b[0m\n",
      "Training:  96%|█████████▌| 749/782 [08:57<00:22,  1.46it/s]\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
      "Training:  87%|████████▋ | 683/782 [09:08<01:18,  1.26it/s]\u001b[32m [repeated 112x across cluster]\u001b[0m\n",
      "Training:  97%|█████████▋| 756/782 [09:01<00:18,  1.41it/s]\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "Training:  70%|██████▉   | 544/782 [03:48<01:33,  2.56it/s]\u001b[32m [repeated 115x across cluster]\u001b[0m\n",
      "Training:  98%|█████████▊| 763/782 [09:06<00:13,  1.40it/s]\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "Training:  89%|████████▉ | 695/782 [09:18<01:15,  1.15it/s]\u001b[32m [repeated 116x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▍| 742/782 [08:57<00:27,  1.45it/s]\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "Training:   6%|▌         | 44/782 [00:29<07:01,  1.75it/s]\u001b[32m [repeated 109x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864793)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864793)\u001b[0m   _log_deprecation_warning(\n",
      "Training:  96%|█████████▌| 749/782 [09:02<00:22,  1.44it/s]\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  75%|███████▍  | 583/782 [04:03<01:19,  2.50it/s]\u001b[32m [repeated 114x across cluster]\u001b[0m\n",
      "Training:  93%|█████████▎| 727/782 [09:10<00:43,  1.27it/s]\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "Training:  50%|████▉     | 389/782 [03:13<03:20,  1.96it/s]\u001b[32m [repeated 114x across cluster]\u001b[0m\n",
      "Training:  94%|█████████▍| 734/782 [09:15<00:34,  1.40it/s]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "Training:  77%|███████▋  | 605/782 [04:13<01:26,  2.04it/s]\u001b[32m [repeated 106x across cluster]\u001b[0m\n",
      "Training:  98%|█████████▊| 769/782 [09:17<00:09,  1.31it/s]\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864831)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864831)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  79%|███████▉  | 616/782 [04:18<01:15,  2.20it/s]\u001b[32m [repeated 109x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▉| 776/782 [09:22<00:04,  1.39it/s]\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "Training:  34%|███▍      | 269/782 [02:35<04:52,  1.75it/s]\u001b[32m [repeated 119x across cluster]\u001b[0m\n",
      "Training:  97%|█████████▋| 756/782 [09:30<00:18,  1.43it/s]\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "Training:  82%|████████▏ | 639/782 [04:28<00:55,  2.57it/s]\u001b[32m [repeated 116x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▍| 740/782 [09:55<00:33,  1.24it/s]\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "Training:  75%|███████▍  | 585/782 [09:46<03:11,  1.03it/s]\u001b[32m [repeated 118x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▌| 746/782 [10:00<00:29,  1.21it/s]\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "Training:   7%|▋         | 57/782 [00:39<07:32,  1.60it/s]\u001b[32m [repeated 118x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▉| 777/782 [09:45<00:03,  1.39it/s]\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "Training:  14%|█▍        | 113/782 [01:14<07:37,  1.46it/s]\u001b[32m [repeated 116x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864830)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864830)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  97%|█████████▋| 758/782 [10:10<00:18,  1.26it/s]\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "Training:   1%|          | 4/782 [00:03<10:13,  1.27it/s]\u001b[32m [repeated 122x across cluster]\u001b[0m\n",
      "Training:  98%|█████████▊| 764/782 [10:15<00:14,  1.25it/s]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "Training:  77%|███████▋  | 606/782 [10:06<02:47,  1.05it/s]\u001b[32m [repeated 127x across cluster]\u001b[0m\n",
      "Training:  99%|█████████▊| 771/782 [10:20<00:08,  1.28it/s]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864819)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864819)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  41%|████      | 320/782 [03:12<05:14,  1.47it/s]\u001b[32m [repeated 124x across cluster]\u001b[0m\n",
      "Training:  92%|█████████▏| 719/782 [05:00<00:26,  2.38it/s]\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "Training:  82%|████████▏ | 639/782 [10:19<02:15,  1.06it/s]\u001b[32m [repeated 116x across cluster]\u001b[0m\n",
      "Training:  93%|█████████▎| 730/782 [05:05<00:22,  2.32it/s]\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "Training:  86%|████████▌ | 670/782 [10:17<01:44,  1.07it/s]\u001b[32m [repeated 118x across cluster]\u001b[0m\n",
      "Training:  95%|█████████▌| 743/782 [05:10<00:14,  2.63it/s]\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864818)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864818)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  91%|█████████ | 711/782 [10:37<01:00,  1.18it/s]\u001b[32m [repeated 117x across cluster]\u001b[0m\n",
      "Training:  96%|█████████▋| 754/782 [05:15<00:13,  2.08it/s]\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "Training:  84%|████████▍ | 659/782 [10:46<02:26,  1.19s/it]\u001b[32m [repeated 125x across cluster]\u001b[0m\n",
      "Training:  98%|█████████▊| 767/782 [05:20<00:05,  2.58it/s]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m [2025-10-19 16:44:11,793 E 1857549 1857549] (raylet) node_manager.cc:2929: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 96bc6d0858006189c483e3db21548cc8885f0919fd9d426ed3d5929e, IP: 10.82.72.122) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.82.72.122`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "Training:  48%|████▊     | 376/782 [03:36<03:50,  1.76it/s]\u001b[32m [repeated 115x across cluster]\u001b[0m\n",
      "Training: 100%|█████████▉| 780/782 [05:25<00:00,  2.68it/s]\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "Training:  12%|█▏        | 96/782 [01:11<07:29,  1.53it/s]\u001b[32m [repeated 121x across cluster]\u001b[0m\n",
      "Training:  93%|█████████▎| 730/782 [10:54<00:46,  1.12it/s]\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864785)\u001b[0m /mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/.venv/lib/python3.12/site-packages/ray/train/_internal/session.py:772: RayDeprecationWarning: `ray.train.report` should be switched to `ray.tune.report` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(train_and_evaluate_ray pid=1864785)\u001b[0m   _log_deprecation_warning(\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 1/782 [00:00<04:03,  3.21it/s]\n",
      "Training:   0%|          | 2/782 [00:00<02:57,  4.41it/s]\n",
      "Training:   0%|          | 3/782 [00:00<02:37,  4.94it/s]\n",
      "Training:   1%|          | 4/782 [00:00<02:29,  5.21it/s]\n",
      "Training:   1%|          | 5/782 [00:00<02:20,  5.51it/s]\n",
      "Training:   1%|          | 6/782 [00:01<02:14,  5.78it/s]\n",
      "Training:   1%|          | 7/782 [00:01<02:15,  5.73it/s]\n",
      "Training:   1%|          | 8/782 [00:01<02:14,  5.77it/s]\n",
      "Training:   1%|          | 9/782 [00:01<02:10,  5.93it/s]\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "Training:   2%|▏         | 17/782 [00:02<02:01,  6.27it/s]\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "Training:   0%|          | 1/782 [00:00<06:02,  2.15it/s]\u001b[32m [repeated 128x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Training:   8%|▊         | 64/782 [00:12<03:00,  3.98it/s]\u001b[32m [repeated 137x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "Training:   2%|▏         | 16/782 [00:06<06:15,  2.04it/s]\u001b[32m [repeated 140x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Training:   2%|▏         | 12/782 [00:06<06:50,  1.88it/s]\u001b[32m [repeated 142x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Training:  13%|█▎        | 103/782 [00:28<05:33,  2.04it/s]\u001b[32m [repeated 134x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Training:  14%|█▍        | 113/782 [00:33<05:52,  1.90it/s]\u001b[32m [repeated 144x across cluster]\u001b[0m\n",
      "Training:   0%|          | 0/782 [00:00<?, ?it/s]\n",
      "Training:  14%|█▍        | 113/782 [00:40<06:16,  1.78it/s]\u001b[32m [repeated 145x across cluster]\u001b[0m\n",
      "Training:  16%|█▌        | 122/782 [00:45<06:01,  1.82it/s]\u001b[32m [repeated 152x across cluster]\u001b[0m\n",
      "Training:  16%|█▌        | 127/782 [00:49<06:28,  1.69it/s]\u001b[32m [repeated 152x across cluster]\u001b[0m\n",
      "Training:   5%|▍         | 36/782 [00:27<08:55,  1.39it/s]\u001b[32m [repeated 150x across cluster]\u001b[0m\n",
      "Training:  21%|██        | 163/782 [00:58<05:10,  1.99it/s]\u001b[32m [repeated 147x across cluster]\u001b[0m\n",
      "Training:   6%|▌         | 45/782 [00:42<13:54,  1.13s/it]\u001b[32m [repeated 146x across cluster]\u001b[0m\n",
      "Training:  20%|██        | 158/782 [01:09<06:22,  1.63it/s]\u001b[32m [repeated 152x across cluster]\u001b[0m\n",
      "Training:   8%|▊         | 63/782 [00:48<09:03,  1.32it/s]\u001b[32m [repeated 148x across cluster]\u001b[0m\n",
      "Training:  13%|█▎        | 104/782 [01:07<07:41,  1.47it/s]\u001b[32m [repeated 150x across cluster]\u001b[0m\n",
      "Training:  23%|██▎       | 182/782 [01:24<06:05,  1.64it/s]\u001b[32m [repeated 149x across cluster]\u001b[0m\n",
      "Training:  10%|█         | 82/782 [01:03<09:07,  1.28it/s]\u001b[32m [repeated 152x across cluster]\u001b[0m\n",
      "Training:  29%|██▉       | 230/782 [01:33<04:52,  1.89it/s]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  28%|██▊       | 219/782 [01:41<05:13,  1.80it/s]\u001b[32m [repeated 151x across cluster]\u001b[0m\n",
      "Training:  16%|█▌        | 126/782 [01:25<06:39,  1.64it/s]\u001b[32m [repeated 152x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "\n",
    "\n",
    "def train_and_evaluate_ray(config: dict):\n",
    "    model = SimpleCNN(\n",
    "        input_size=config[\"input_size\"],\n",
    "        hidden_size=config[\"hidden_size\"],\n",
    "        output_size=config[\"output_size\"],\n",
    "        dropout=config[\"dropout\"],\n",
    "        num_conv_layers=config[\"num_conv_layers\"],\n",
    "        filters=config[\"filters\"],\n",
    "        kernel_size=config[\"kernel_size\"],\n",
    "        stride=config[\"stride\"],\n",
    "        padding=config[\"padding\"],\n",
    "        num_fully_connected_layers=config[\"num_fully_connected_layers\"]\n",
    "    )\n",
    "    train_loader, test_loader = get_data_loaders(config[\"batch_size\"], config[\"data_dir\"])\n",
    "    device = config[\"device\"]\n",
    "    model.to(device)\n",
    "    optimizer = config[\"optimizer\"](model.parameters(), lr=config[\"learning_rate\"])\n",
    "    loss_fn = config[\"loss_fn\"]\n",
    "    num_epochs = config[\"epochs\"]\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "        val_loss, val_accuracy = evaluate(model, test_loader, loss_fn, device)\n",
    "\n",
    "        model.train_losses.append(train_loss)\n",
    "        model.val_losses.append(val_loss)\n",
    "        model.train_accuracies.append(train_accuracy)\n",
    "        model.val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        ray.train.report({\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"val_accuracy\": val_accuracy\n",
    "        })\n",
    "        # logger.info(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {val_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Test Acc: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    return model.train_losses[-1], model.val_losses[-1], model.val_accuracies[-1]\n",
    "\n",
    "config_structure = {\n",
    "    \n",
    "    # Fixed parameters\n",
    "    \"epochs\": 3,\n",
    "    \"data_dir\": Path(DATADIR).resolve(),\n",
    "    \"tune_dir\": Path(TUNEDIR).resolve(),\n",
    "    \"batch_size\": 64,\n",
    "    \"input_size\": 3,\n",
    "    \"output_size\": 20,\n",
    "    \"hidden_size\": 350,\n",
    "    \"dropout\": 0,\n",
    "    \"num_fully_connected_layers\": tune.grid_search([2,4]),\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"loss_fn\": torch.nn.CrossEntropyLoss(), # suitable for multi-class classification\n",
    "    \"optimizer\": torch.optim.Adam,\n",
    "    # \"scheduler\": torch.optim.lr_scheduler.LRScheduler,\n",
    "    \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"metrics\": \"accuracy\",\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \n",
    "    # convolutional layer parameters\n",
    "    \"num_conv_layers\": tune.grid_search([2,3,4]),\n",
    "    \"filters\": tune.grid_search([64,128,152]),\n",
    "    \"kernel_size\": tune.grid_search([2,3]),\n",
    "    \"stride\": 1,\n",
    "    \"padding\": 0,\n",
    "}\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_and_evaluate_ray,\n",
    "    config=config_structure,\n",
    "    name=\"cnn_hyperparameter_gridsearch\",\n",
    "    metric=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    storage_path=str(config_structure[\"tune_dir\"]),  # ensure path is string\n",
    "    stop={\"training_iteration\": config_structure[\"epochs\"]},\n",
    "    verbose=1,\n",
    "    resume=True,\n",
    "    raise_on_failed_trial=False  # This prevents TuneError from being raised\n",
    ")\n",
    "\n",
    "tune_df = analysis.results_df.sort_values(\"val_loss\")\n",
    "tune_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c7b67d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_heatmap(df, x, y, z):\n",
    "    # Pivot the dataframe to create a matrix for heatmap\n",
    "    heatmap_data = df.pivot_table(index=y, columns=x, values=z)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = plt.gca()\n",
    "    im = ax.imshow(heatmap_data, cmap='viridis', aspect='auto', origin='lower')\n",
    "\n",
    "    # Show all ticks and label them\n",
    "    ax.set_xticks(np.arange(len(heatmap_data.columns)))\n",
    "    ax.set_yticks(np.arange(len(heatmap_data.index)))\n",
    "    ax.set_xticklabels(heatmap_data.columns)\n",
    "    ax.set_yticklabels(heatmap_data.index)\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    plt.title(f\"Heatmap of {z} by {x} and {y}\")\n",
    "\n",
    "    # Annotate each cell with the accuracy value\n",
    "    for i in range(len(heatmap_data.index)):\n",
    "        for j in range(len(heatmap_data.columns)):\n",
    "            value = heatmap_data.iloc[i, j]\n",
    "            if not np.isnan(value):\n",
    "                ax.text(j, i, f\"{value:.2f}\", ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "    plt.colorbar(im, label=z)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac19c7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_heatmap(\n",
    "    tune_df,\n",
    "    x=\"config/kernel_size\",\n",
    "    y=\"config/filters\",\n",
    "    z=\"val_accuracy\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fb1357c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_heatmap(\n",
    "    tune_df,\n",
    "    x=\"config/num_conv_layers\",\n",
    "    y=\"config/num_fully_connected_layers\",\n",
    "    z=\"val_accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff47c1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_heatmap(\n",
    "    tune_df,\n",
    "    x=\"config/filters\",\n",
    "    y=\"config/num_conv_layers\",\n",
    "    z=\"val_accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cb41c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "trial_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "train_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "timestamp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "checkpoint_dir_name",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "done",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "training_iteration",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "time_this_iter_s",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "time_total_s",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hostname",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "node_ip",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "time_since_restore",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "iterations_since_restore",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "experiment_tag",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "config/epochs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/data_dir",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "config/tune_dir",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "config/batch_size",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/input_size",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/output_size",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/hidden_size",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/dropout",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/num_fully_connected_layers",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/learning_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/loss_fn",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "config/optimizer",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "config/scheduler",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "config/metrics",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "config/device",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "config/num_conv_layers",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/filters",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/kernel_size",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/stride",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/padding",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "004fcb7e-7b1e-427c-aa2f-e76258ea27bc",
       "rows": [
        [
         "60557_00005",
         "0.8653694896213234",
         "0.8583464580736343",
         "69.486",
         "69.92",
         "1760820842.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-54-02",
         "403.64898109436035",
         "1871.344081401825",
         "1670766.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1871.344081401825",
         "3.0",
         "5_filters=152,kernel_size=3,num_conv_layers=2,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "2.0",
         "152.0",
         "3.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00001",
         "0.892391116189225",
         "0.9061449219466774",
         "68.366",
         "68.94",
         "1760820435.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-47-15",
         "446.46467995643616",
         "1464.6482491493225",
         "1670782.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1464.6482491493225",
         "3.0",
         "1_filters=128,kernel_size=2,num_conv_layers=2,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "2.0",
         "128.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00023",
         "0.929347400165275",
         "0.9219477134905044",
         "67.404",
         "68.42",
         "1760820770.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-52-50",
         "349.03416204452515",
         "1798.7627747058868",
         "1670781.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1798.7627747058868",
         "3.0",
         "23_filters=152,kernel_size=3,num_conv_layers=2,num_fully_connected_layers=4",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "4.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "2.0",
         "152.0",
         "3.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00002",
         "0.8748945136509283",
         "0.9016384114125732",
         "69.04",
         "68.35",
         "1760820717.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-51-57",
         "444.56968212127686",
         "1747.172739982605",
         "1670688.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1747.172739982605",
         "3.0",
         "2_filters=152,kernel_size=2,num_conv_layers=2,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "2.0",
         "152.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00004",
         "0.881965663388867",
         "0.9056603187208723",
         "69.082",
         "68.3",
         "1760820509.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-48-29",
         "448.4934995174408",
         "1538.6261432170868",
         "1670752.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1538.6261432170868",
         "3.0",
         "4_filters=128,kernel_size=3,num_conv_layers=2,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "2.0",
         "128.0",
         "3.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00022",
         "0.924181490450564",
         "0.9181767705899135",
         "67.724",
         "67.77",
         "1760820541.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-49-01",
         "425.71722197532654",
         "1571.2217280864716",
         "1670751.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1571.2217280864716",
         "3.0",
         "22_filters=128,kernel_size=3,num_conv_layers=2,num_fully_connected_layers=4",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "4.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "2.0",
         "128.0",
         "3.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00000",
         "0.9270617668433567",
         "0.9301760466235458",
         "67.22",
         "67.49",
         "1760815973.0",
         null,
         "True",
         "3.0",
         "2025-10-18_21-32-53",
         "241.713299036026",
         "738.7214345932007",
         "1651381.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "738.7214345932007",
         "3.0",
         "0_filters=64,kernel_size=2,num_conv_layers=2,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "2.0",
         "64.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00003",
         "0.9845573841915716",
         "0.9660203244276108",
         "65.202",
         "66.37",
         "1760816011.0",
         null,
         "True",
         "3.0",
         "2025-10-18_21-33-31",
         "244.65620136260986",
         "772.8480396270752",
         "1651385.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "772.8480396270752",
         "3.0",
         "3_filters=64,kernel_size=3,num_conv_layers=2,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "2.0",
         "64.0",
         "3.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00021",
         "0.9860689426627001",
         "0.9779745769348873",
         "64.85",
         "66.36",
         "1760816035.0",
         null,
         "True",
         "3.0",
         "2025-10-18_21-33-55",
         "239.2808587551117",
         "796.0776374340057",
         "1651395.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "796.0776374340057",
         "3.0",
         "21_filters=64,kernel_size=3,num_conv_layers=2,num_fully_connected_layers=4",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "4.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "2.0",
         "64.0",
         "3.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00026",
         "1.0131747646404958",
         "0.9586977491712874",
         "63.928",
         "66.31",
         "1760820698.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-51-38",
         "375.15924048423767",
         "1728.0598220825195",
         "1670698.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1728.0598220825195",
         "3.0",
         "26_filters=152,kernel_size=2,num_conv_layers=3,num_fully_connected_layers=4",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "4.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "3.0",
         "152.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00011",
         "0.993530817272718",
         "0.9647225654049284",
         "64.558",
         "65.88",
         "1760820813.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-53-33",
         "329.1631643772125",
         "1841.880034685135",
         "1670753.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1841.880034685135",
         "3.0",
         "11_filters=152,kernel_size=3,num_conv_layers=3,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "3.0",
         "152.0",
         "3.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00020",
         "0.9279268543281214",
         "0.9701146392305945",
         "67.178",
         "65.51",
         "1760820721.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-52-01",
         "405.13041400909424",
         "1750.017335653305",
         "1670845.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1750.017335653305",
         "3.0",
         "20_filters=152,kernel_size=2,num_conv_layers=2,num_fully_connected_layers=4",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "4.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "2.0",
         "152.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00025",
         "1.0458392859877224",
         "0.977771176274415",
         "62.334",
         "65.29",
         "1760820306.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-45-06",
         "421.84322595596313",
         "1335.2397360801697",
         "1670770.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1335.2397360801697",
         "3.0",
         "25_filters=128,kernel_size=2,num_conv_layers=3,num_fully_connected_layers=4",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "4.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "3.0",
         "128.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00018",
         "0.9629514914796785",
         "1.0204271207189863",
         "65.514",
         "64.36",
         "1760817875.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-04-35",
         "232.31157398223877",
         "703.9183914661407",
         "1664110.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "703.9183914661407",
         "3.0",
         "18_filters=64,kernel_size=2,num_conv_layers=2,num_fully_connected_layers=4",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "4.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "2.0",
         "64.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00019",
         "0.8854211383615919",
         "1.0296334548360984",
         "68.87",
         "64.15",
         "1760820393.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-46-33",
         "457.38462924957275",
         "1423.2720458507538",
         "1670745.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1423.2720458507538",
         "3.0",
         "19_filters=128,kernel_size=2,num_conv_layers=2,num_fully_connected_layers=4",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "4.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "2.0",
         "128.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00028",
         "1.089847482150168",
         "1.0360557190172233",
         "61.066",
         "63.51",
         "1760820446.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-47-26",
         "455.4011459350586",
         "1475.0167236328125",
         "1670769.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1475.0167236328125",
         "3.0",
         "28_filters=128,kernel_size=3,num_conv_layers=3,num_fully_connected_layers=4",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "4.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "3.0",
         "128.0",
         "3.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00010",
         "1.0355651123292",
         "1.030021024357741",
         "63.292",
         "63.4",
         "1760820452.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-47-32",
         "460.9634177684784",
         "1481.4507954120636",
         "1670719.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1481.4507954120636",
         "3.0",
         "10_filters=128,kernel_size=3,num_conv_layers=3,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "3.0",
         "128.0",
         "3.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00007",
         "1.0243697069642488",
         "1.0334461133950834",
         "63.736",
         "63.39",
         "1760820283.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-44-43",
         "428.0590751171112",
         "1311.749225616455",
         "1670768.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1311.749225616455",
         "3.0",
         "7_filters=128,kernel_size=2,num_conv_layers=3,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "3.0",
         "128.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00006",
         "1.1138687838069008",
         "1.0356044587056348",
         "60.232",
         "63.36",
         "1760815967.0",
         null,
         "True",
         "3.0",
         "2025-10-18_21-32-47",
         "220.57606029510498",
         "727.5321011543274",
         "1651388.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "727.5321011543274",
         "3.0",
         "6_filters=64,kernel_size=2,num_conv_layers=3,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "3.0",
         "64.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00029",
         "1.069091072091666",
         "1.031483681338608",
         "61.854",
         "63.27",
         "1760820789.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-53-09",
         "374.0204916000366",
         "1818.8304524421692",
         "1670679.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1818.8304524421692",
         "3.0",
         "29_filters=152,kernel_size=3,num_conv_layers=3,num_fully_connected_layers=4",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "4.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "3.0",
         "152.0",
         "3.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00008",
         "1.0014296809730627",
         "1.0937521434893274",
         "64.448",
         "62.59",
         "1760820718.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-51-58",
         "366.35334157943726",
         "1748.162204504013",
         "1670680.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1748.162204504013",
         "3.0",
         "8_filters=152,kernel_size=2,num_conv_layers=3,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "3.0",
         "152.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00024",
         "1.149840189672797",
         "1.1046724767441962",
         "58.796",
         "60.98",
         "1760816003.0",
         null,
         "True",
         "3.0",
         "2025-10-18_21-33-23",
         "237.64164543151855",
         "765.1250219345093",
         "1651383.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "765.1250219345093",
         "3.0",
         "24_filters=64,kernel_size=2,num_conv_layers=3,num_fully_connected_layers=4",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "4.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "3.0",
         "64.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00027",
         "1.1684945718864042",
         "1.1053882833499058",
         "58.074",
         "60.81",
         "1760820704.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-51-44",
         "114.76696538925171",
         "412.9579327106476",
         "1674522.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "412.9579327106476",
         "3.0",
         "27_filters=64,kernel_size=3,num_conv_layers=3,num_fully_connected_layers=4",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "4.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "3.0",
         "64.0",
         "3.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00013",
         "1.186760294086793",
         "1.1058590875309744",
         "56.75",
         "60.42",
         "1760820262.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-44-22",
         "424.9472179412842",
         "1291.9556205272675",
         "1670754.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1291.9556205272675",
         "3.0",
         "13_filters=128,kernel_size=2,num_conv_layers=4,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "4.0",
         "128.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00014",
         "1.1781268102281235",
         "1.1282653857947915",
         "57.392",
         "58.92",
         "1760820721.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-52-01",
         "418.0337541103363",
         "1751.3661487102509",
         "1670767.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1751.3661487102509",
         "3.0",
         "14_filters=152,kernel_size=2,num_conv_layers=4,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "4.0",
         "152.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00009",
         "1.0975186958184937",
         "1.1692955767273143",
         "60.686",
         "58.66",
         "1760817829.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-03-49",
         "212.3008782863617",
         "657.9684517383575",
         "1664155.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "657.9684517383575",
         "3.0",
         "9_filters=64,kernel_size=3,num_conv_layers=3,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "3.0",
         "64.0",
         "3.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00032",
         "1.2000486509269461",
         "1.1545055979376386",
         "56.698",
         "57.98",
         "1760820693.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-51-33",
         "425.66643261909485",
         "1723.360808134079",
         "1670689.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1723.360808134079",
         "3.0",
         "32_filters=152,kernel_size=2,num_conv_layers=4,num_fully_connected_layers=4",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "4.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "4.0",
         "152.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00031",
         "1.2342170875548097",
         "1.1964043686344366",
         "54.99",
         "57.1",
         "1760820404.0",
         null,
         "True",
         "3.0",
         "2025-10-18_22-46-44",
         "441.8502342700958",
         "1433.4690997600555",
         "1670760.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "1433.4690997600555",
         "3.0",
         "31_filters=128,kernel_size=2,num_conv_layers=4,num_fully_connected_layers=4",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "4.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "4.0",
         "128.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00030",
         "1.3318179454035162",
         "1.2646723757883547",
         "50.834",
         "53.93",
         "1760815989.0",
         null,
         "True",
         "3.0",
         "2025-10-18_21-33-09",
         "225.98777675628662",
         "709.5093042850494",
         "1652868.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "709.5093042850494",
         "3.0",
         "30_filters=64,kernel_size=2,num_conv_layers=4,num_fully_connected_layers=4",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "4.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "4.0",
         "64.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00012",
         "1.2774122393954441",
         "1.2867247139572338",
         "53.188",
         "53.83",
         "1760815902.0",
         null,
         "True",
         "3.0",
         "2025-10-18_21-31-42",
         "221.8172583580017",
         "667.3080620765686",
         "1651382.0",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "667.3080620765686",
         "3.0",
         "12_filters=64,kernel_size=2,num_conv_layers=4,num_fully_connected_layers=2",
         "3.0",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64.0",
         "3.0",
         "20.0",
         "350.0",
         "0.0",
         "2.0",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "4.0",
         "64.0",
         "2.0",
         "1.0",
         "0.0"
        ],
        [
         "60557_00015",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "60557_00035",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "60557_00016",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "60557_00033",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "60557_00034",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "60557_00017",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 37,
        "rows": 36
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>checkpoint_dir_name</th>\n",
       "      <th>done</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>date</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>...</th>\n",
       "      <th>config/loss_fn</th>\n",
       "      <th>config/optimizer</th>\n",
       "      <th>config/scheduler</th>\n",
       "      <th>config/metrics</th>\n",
       "      <th>config/device</th>\n",
       "      <th>config/num_conv_layers</th>\n",
       "      <th>config/filters</th>\n",
       "      <th>config/kernel_size</th>\n",
       "      <th>config/stride</th>\n",
       "      <th>config/padding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60557_00005</th>\n",
       "      <td>0.865369</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>69.486</td>\n",
       "      <td>69.92</td>\n",
       "      <td>1.760821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-54-02</td>\n",
       "      <td>403.648981</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>2.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00001</th>\n",
       "      <td>0.892391</td>\n",
       "      <td>0.906145</td>\n",
       "      <td>68.366</td>\n",
       "      <td>68.94</td>\n",
       "      <td>1.760820e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-47-15</td>\n",
       "      <td>446.464680</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>2.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00023</th>\n",
       "      <td>0.929347</td>\n",
       "      <td>0.921948</td>\n",
       "      <td>67.404</td>\n",
       "      <td>68.42</td>\n",
       "      <td>1.760821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-52-50</td>\n",
       "      <td>349.034162</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>2.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00002</th>\n",
       "      <td>0.874895</td>\n",
       "      <td>0.901638</td>\n",
       "      <td>69.040</td>\n",
       "      <td>68.35</td>\n",
       "      <td>1.760821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-51-57</td>\n",
       "      <td>444.569682</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>2.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00004</th>\n",
       "      <td>0.881966</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>69.082</td>\n",
       "      <td>68.30</td>\n",
       "      <td>1.760821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-48-29</td>\n",
       "      <td>448.493500</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>2.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00022</th>\n",
       "      <td>0.924181</td>\n",
       "      <td>0.918177</td>\n",
       "      <td>67.724</td>\n",
       "      <td>67.77</td>\n",
       "      <td>1.760821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-49-01</td>\n",
       "      <td>425.717222</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>2.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00000</th>\n",
       "      <td>0.927062</td>\n",
       "      <td>0.930176</td>\n",
       "      <td>67.220</td>\n",
       "      <td>67.49</td>\n",
       "      <td>1.760816e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_21-32-53</td>\n",
       "      <td>241.713299</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00003</th>\n",
       "      <td>0.984557</td>\n",
       "      <td>0.966020</td>\n",
       "      <td>65.202</td>\n",
       "      <td>66.37</td>\n",
       "      <td>1.760816e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_21-33-31</td>\n",
       "      <td>244.656201</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00021</th>\n",
       "      <td>0.986069</td>\n",
       "      <td>0.977975</td>\n",
       "      <td>64.850</td>\n",
       "      <td>66.36</td>\n",
       "      <td>1.760816e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_21-33-55</td>\n",
       "      <td>239.280859</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00026</th>\n",
       "      <td>1.013175</td>\n",
       "      <td>0.958698</td>\n",
       "      <td>63.928</td>\n",
       "      <td>66.31</td>\n",
       "      <td>1.760821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-51-38</td>\n",
       "      <td>375.159240</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>3.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00011</th>\n",
       "      <td>0.993531</td>\n",
       "      <td>0.964723</td>\n",
       "      <td>64.558</td>\n",
       "      <td>65.88</td>\n",
       "      <td>1.760821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-53-33</td>\n",
       "      <td>329.163164</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>3.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00020</th>\n",
       "      <td>0.927927</td>\n",
       "      <td>0.970115</td>\n",
       "      <td>67.178</td>\n",
       "      <td>65.51</td>\n",
       "      <td>1.760821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-52-01</td>\n",
       "      <td>405.130414</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>2.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00025</th>\n",
       "      <td>1.045839</td>\n",
       "      <td>0.977771</td>\n",
       "      <td>62.334</td>\n",
       "      <td>65.29</td>\n",
       "      <td>1.760820e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-45-06</td>\n",
       "      <td>421.843226</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>3.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00018</th>\n",
       "      <td>0.962951</td>\n",
       "      <td>1.020427</td>\n",
       "      <td>65.514</td>\n",
       "      <td>64.36</td>\n",
       "      <td>1.760818e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-04-35</td>\n",
       "      <td>232.311574</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00019</th>\n",
       "      <td>0.885421</td>\n",
       "      <td>1.029633</td>\n",
       "      <td>68.870</td>\n",
       "      <td>64.15</td>\n",
       "      <td>1.760820e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-46-33</td>\n",
       "      <td>457.384629</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>2.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00028</th>\n",
       "      <td>1.089847</td>\n",
       "      <td>1.036056</td>\n",
       "      <td>61.066</td>\n",
       "      <td>63.51</td>\n",
       "      <td>1.760820e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-47-26</td>\n",
       "      <td>455.401146</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>3.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00010</th>\n",
       "      <td>1.035565</td>\n",
       "      <td>1.030021</td>\n",
       "      <td>63.292</td>\n",
       "      <td>63.40</td>\n",
       "      <td>1.760820e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-47-32</td>\n",
       "      <td>460.963418</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>3.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00007</th>\n",
       "      <td>1.024370</td>\n",
       "      <td>1.033446</td>\n",
       "      <td>63.736</td>\n",
       "      <td>63.39</td>\n",
       "      <td>1.760820e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-44-43</td>\n",
       "      <td>428.059075</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>3.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00006</th>\n",
       "      <td>1.113869</td>\n",
       "      <td>1.035604</td>\n",
       "      <td>60.232</td>\n",
       "      <td>63.36</td>\n",
       "      <td>1.760816e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_21-32-47</td>\n",
       "      <td>220.576060</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00029</th>\n",
       "      <td>1.069091</td>\n",
       "      <td>1.031484</td>\n",
       "      <td>61.854</td>\n",
       "      <td>63.27</td>\n",
       "      <td>1.760821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-53-09</td>\n",
       "      <td>374.020492</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>3.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00008</th>\n",
       "      <td>1.001430</td>\n",
       "      <td>1.093752</td>\n",
       "      <td>64.448</td>\n",
       "      <td>62.59</td>\n",
       "      <td>1.760821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-51-58</td>\n",
       "      <td>366.353342</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>3.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00024</th>\n",
       "      <td>1.149840</td>\n",
       "      <td>1.104672</td>\n",
       "      <td>58.796</td>\n",
       "      <td>60.98</td>\n",
       "      <td>1.760816e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_21-33-23</td>\n",
       "      <td>237.641645</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00027</th>\n",
       "      <td>1.168495</td>\n",
       "      <td>1.105388</td>\n",
       "      <td>58.074</td>\n",
       "      <td>60.81</td>\n",
       "      <td>1.760821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-51-44</td>\n",
       "      <td>114.766965</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00013</th>\n",
       "      <td>1.186760</td>\n",
       "      <td>1.105859</td>\n",
       "      <td>56.750</td>\n",
       "      <td>60.42</td>\n",
       "      <td>1.760820e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-44-22</td>\n",
       "      <td>424.947218</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00014</th>\n",
       "      <td>1.178127</td>\n",
       "      <td>1.128265</td>\n",
       "      <td>57.392</td>\n",
       "      <td>58.92</td>\n",
       "      <td>1.760821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-52-01</td>\n",
       "      <td>418.033754</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>4.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00009</th>\n",
       "      <td>1.097519</td>\n",
       "      <td>1.169296</td>\n",
       "      <td>60.686</td>\n",
       "      <td>58.66</td>\n",
       "      <td>1.760818e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-03-49</td>\n",
       "      <td>212.300878</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00032</th>\n",
       "      <td>1.200049</td>\n",
       "      <td>1.154506</td>\n",
       "      <td>56.698</td>\n",
       "      <td>57.98</td>\n",
       "      <td>1.760821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-51-33</td>\n",
       "      <td>425.666433</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>4.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00031</th>\n",
       "      <td>1.234217</td>\n",
       "      <td>1.196404</td>\n",
       "      <td>54.990</td>\n",
       "      <td>57.10</td>\n",
       "      <td>1.760820e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_22-46-44</td>\n",
       "      <td>441.850234</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00030</th>\n",
       "      <td>1.331818</td>\n",
       "      <td>1.264672</td>\n",
       "      <td>50.834</td>\n",
       "      <td>53.93</td>\n",
       "      <td>1.760816e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_21-33-09</td>\n",
       "      <td>225.987777</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00012</th>\n",
       "      <td>1.277412</td>\n",
       "      <td>1.286725</td>\n",
       "      <td>53.188</td>\n",
       "      <td>53.83</td>\n",
       "      <td>1.760816e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-10-18_21-31-42</td>\n",
       "      <td>221.817258</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00015</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00035</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00016</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00033</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00034</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60557_00017</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             train_loss  val_loss  train_accuracy  val_accuracy     timestamp  \\\n",
       "trial_id                                                                        \n",
       "60557_00005    0.865369  0.858346          69.486         69.92  1.760821e+09   \n",
       "60557_00001    0.892391  0.906145          68.366         68.94  1.760820e+09   \n",
       "60557_00023    0.929347  0.921948          67.404         68.42  1.760821e+09   \n",
       "60557_00002    0.874895  0.901638          69.040         68.35  1.760821e+09   \n",
       "60557_00004    0.881966  0.905660          69.082         68.30  1.760821e+09   \n",
       "60557_00022    0.924181  0.918177          67.724         67.77  1.760821e+09   \n",
       "60557_00000    0.927062  0.930176          67.220         67.49  1.760816e+09   \n",
       "60557_00003    0.984557  0.966020          65.202         66.37  1.760816e+09   \n",
       "60557_00021    0.986069  0.977975          64.850         66.36  1.760816e+09   \n",
       "60557_00026    1.013175  0.958698          63.928         66.31  1.760821e+09   \n",
       "60557_00011    0.993531  0.964723          64.558         65.88  1.760821e+09   \n",
       "60557_00020    0.927927  0.970115          67.178         65.51  1.760821e+09   \n",
       "60557_00025    1.045839  0.977771          62.334         65.29  1.760820e+09   \n",
       "60557_00018    0.962951  1.020427          65.514         64.36  1.760818e+09   \n",
       "60557_00019    0.885421  1.029633          68.870         64.15  1.760820e+09   \n",
       "60557_00028    1.089847  1.036056          61.066         63.51  1.760820e+09   \n",
       "60557_00010    1.035565  1.030021          63.292         63.40  1.760820e+09   \n",
       "60557_00007    1.024370  1.033446          63.736         63.39  1.760820e+09   \n",
       "60557_00006    1.113869  1.035604          60.232         63.36  1.760816e+09   \n",
       "60557_00029    1.069091  1.031484          61.854         63.27  1.760821e+09   \n",
       "60557_00008    1.001430  1.093752          64.448         62.59  1.760821e+09   \n",
       "60557_00024    1.149840  1.104672          58.796         60.98  1.760816e+09   \n",
       "60557_00027    1.168495  1.105388          58.074         60.81  1.760821e+09   \n",
       "60557_00013    1.186760  1.105859          56.750         60.42  1.760820e+09   \n",
       "60557_00014    1.178127  1.128265          57.392         58.92  1.760821e+09   \n",
       "60557_00009    1.097519  1.169296          60.686         58.66  1.760818e+09   \n",
       "60557_00032    1.200049  1.154506          56.698         57.98  1.760821e+09   \n",
       "60557_00031    1.234217  1.196404          54.990         57.10  1.760820e+09   \n",
       "60557_00030    1.331818  1.264672          50.834         53.93  1.760816e+09   \n",
       "60557_00012    1.277412  1.286725          53.188         53.83  1.760816e+09   \n",
       "60557_00015         NaN       NaN             NaN           NaN           NaN   \n",
       "60557_00035         NaN       NaN             NaN           NaN           NaN   \n",
       "60557_00016         NaN       NaN             NaN           NaN           NaN   \n",
       "60557_00033         NaN       NaN             NaN           NaN           NaN   \n",
       "60557_00034         NaN       NaN             NaN           NaN           NaN   \n",
       "60557_00017         NaN       NaN             NaN           NaN           NaN   \n",
       "\n",
       "             checkpoint_dir_name  done  training_iteration  \\\n",
       "trial_id                                                     \n",
       "60557_00005                  NaN  True                 3.0   \n",
       "60557_00001                  NaN  True                 3.0   \n",
       "60557_00023                  NaN  True                 3.0   \n",
       "60557_00002                  NaN  True                 3.0   \n",
       "60557_00004                  NaN  True                 3.0   \n",
       "60557_00022                  NaN  True                 3.0   \n",
       "60557_00000                  NaN  True                 3.0   \n",
       "60557_00003                  NaN  True                 3.0   \n",
       "60557_00021                  NaN  True                 3.0   \n",
       "60557_00026                  NaN  True                 3.0   \n",
       "60557_00011                  NaN  True                 3.0   \n",
       "60557_00020                  NaN  True                 3.0   \n",
       "60557_00025                  NaN  True                 3.0   \n",
       "60557_00018                  NaN  True                 3.0   \n",
       "60557_00019                  NaN  True                 3.0   \n",
       "60557_00028                  NaN  True                 3.0   \n",
       "60557_00010                  NaN  True                 3.0   \n",
       "60557_00007                  NaN  True                 3.0   \n",
       "60557_00006                  NaN  True                 3.0   \n",
       "60557_00029                  NaN  True                 3.0   \n",
       "60557_00008                  NaN  True                 3.0   \n",
       "60557_00024                  NaN  True                 3.0   \n",
       "60557_00027                  NaN  True                 3.0   \n",
       "60557_00013                  NaN  True                 3.0   \n",
       "60557_00014                  NaN  True                 3.0   \n",
       "60557_00009                  NaN  True                 3.0   \n",
       "60557_00032                  NaN  True                 3.0   \n",
       "60557_00031                  NaN  True                 3.0   \n",
       "60557_00030                  NaN  True                 3.0   \n",
       "60557_00012                  NaN  True                 3.0   \n",
       "60557_00015                  NaN   NaN                 NaN   \n",
       "60557_00035                  NaN   NaN                 NaN   \n",
       "60557_00016                  NaN   NaN                 NaN   \n",
       "60557_00033                  NaN   NaN                 NaN   \n",
       "60557_00034                  NaN   NaN                 NaN   \n",
       "60557_00017                  NaN   NaN                 NaN   \n",
       "\n",
       "                            date  time_this_iter_s  ...      config/loss_fn  \\\n",
       "trial_id                                            ...                       \n",
       "60557_00005  2025-10-18_22-54-02        403.648981  ...  CrossEntropyLoss()   \n",
       "60557_00001  2025-10-18_22-47-15        446.464680  ...  CrossEntropyLoss()   \n",
       "60557_00023  2025-10-18_22-52-50        349.034162  ...  CrossEntropyLoss()   \n",
       "60557_00002  2025-10-18_22-51-57        444.569682  ...  CrossEntropyLoss()   \n",
       "60557_00004  2025-10-18_22-48-29        448.493500  ...  CrossEntropyLoss()   \n",
       "60557_00022  2025-10-18_22-49-01        425.717222  ...  CrossEntropyLoss()   \n",
       "60557_00000  2025-10-18_21-32-53        241.713299  ...  CrossEntropyLoss()   \n",
       "60557_00003  2025-10-18_21-33-31        244.656201  ...  CrossEntropyLoss()   \n",
       "60557_00021  2025-10-18_21-33-55        239.280859  ...  CrossEntropyLoss()   \n",
       "60557_00026  2025-10-18_22-51-38        375.159240  ...  CrossEntropyLoss()   \n",
       "60557_00011  2025-10-18_22-53-33        329.163164  ...  CrossEntropyLoss()   \n",
       "60557_00020  2025-10-18_22-52-01        405.130414  ...  CrossEntropyLoss()   \n",
       "60557_00025  2025-10-18_22-45-06        421.843226  ...  CrossEntropyLoss()   \n",
       "60557_00018  2025-10-18_22-04-35        232.311574  ...  CrossEntropyLoss()   \n",
       "60557_00019  2025-10-18_22-46-33        457.384629  ...  CrossEntropyLoss()   \n",
       "60557_00028  2025-10-18_22-47-26        455.401146  ...  CrossEntropyLoss()   \n",
       "60557_00010  2025-10-18_22-47-32        460.963418  ...  CrossEntropyLoss()   \n",
       "60557_00007  2025-10-18_22-44-43        428.059075  ...  CrossEntropyLoss()   \n",
       "60557_00006  2025-10-18_21-32-47        220.576060  ...  CrossEntropyLoss()   \n",
       "60557_00029  2025-10-18_22-53-09        374.020492  ...  CrossEntropyLoss()   \n",
       "60557_00008  2025-10-18_22-51-58        366.353342  ...  CrossEntropyLoss()   \n",
       "60557_00024  2025-10-18_21-33-23        237.641645  ...  CrossEntropyLoss()   \n",
       "60557_00027  2025-10-18_22-51-44        114.766965  ...  CrossEntropyLoss()   \n",
       "60557_00013  2025-10-18_22-44-22        424.947218  ...  CrossEntropyLoss()   \n",
       "60557_00014  2025-10-18_22-52-01        418.033754  ...  CrossEntropyLoss()   \n",
       "60557_00009  2025-10-18_22-03-49        212.300878  ...  CrossEntropyLoss()   \n",
       "60557_00032  2025-10-18_22-51-33        425.666433  ...  CrossEntropyLoss()   \n",
       "60557_00031  2025-10-18_22-46-44        441.850234  ...  CrossEntropyLoss()   \n",
       "60557_00030  2025-10-18_21-33-09        225.987777  ...  CrossEntropyLoss()   \n",
       "60557_00012  2025-10-18_21-31-42        221.817258  ...  CrossEntropyLoss()   \n",
       "60557_00015                  NaN               NaN  ...                 NaN   \n",
       "60557_00035                  NaN               NaN  ...                 NaN   \n",
       "60557_00016                  NaN               NaN  ...                 NaN   \n",
       "60557_00033                  NaN               NaN  ...                 NaN   \n",
       "60557_00034                  NaN               NaN  ...                 NaN   \n",
       "60557_00017                  NaN               NaN  ...                 NaN   \n",
       "\n",
       "                            config/optimizer  \\\n",
       "trial_id                                       \n",
       "60557_00005  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00001  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00023  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00002  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00004  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00022  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00000  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00003  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00021  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00026  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00011  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00020  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00025  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00018  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00019  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00028  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00010  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00007  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00006  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00029  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00008  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00024  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00027  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00013  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00014  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00009  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00032  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00031  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00030  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00012  <class 'torch.optim.adam.Adam'>   \n",
       "60557_00015                              NaN   \n",
       "60557_00035                              NaN   \n",
       "60557_00016                              NaN   \n",
       "60557_00033                              NaN   \n",
       "60557_00034                              NaN   \n",
       "60557_00017                              NaN   \n",
       "\n",
       "                                              config/scheduler config/metrics  \\\n",
       "trial_id                                                                        \n",
       "60557_00005  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00001  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00023  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00002  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00004  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00022  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00000  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00003  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00021  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00026  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00011  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00020  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00025  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00018  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00019  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00028  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00010  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00007  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00006  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00029  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00008  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00024  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00027  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00013  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00014  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00009  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00032  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00031  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00030  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00012  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "60557_00015                                                NaN            NaN   \n",
       "60557_00035                                                NaN            NaN   \n",
       "60557_00016                                                NaN            NaN   \n",
       "60557_00033                                                NaN            NaN   \n",
       "60557_00034                                                NaN            NaN   \n",
       "60557_00017                                                NaN            NaN   \n",
       "\n",
       "             config/device  config/num_conv_layers config/filters  \\\n",
       "trial_id                                                            \n",
       "60557_00005            cpu                     2.0          152.0   \n",
       "60557_00001            cpu                     2.0          128.0   \n",
       "60557_00023            cpu                     2.0          152.0   \n",
       "60557_00002            cpu                     2.0          152.0   \n",
       "60557_00004            cpu                     2.0          128.0   \n",
       "60557_00022            cpu                     2.0          128.0   \n",
       "60557_00000            cpu                     2.0           64.0   \n",
       "60557_00003            cpu                     2.0           64.0   \n",
       "60557_00021            cpu                     2.0           64.0   \n",
       "60557_00026            cpu                     3.0          152.0   \n",
       "60557_00011            cpu                     3.0          152.0   \n",
       "60557_00020            cpu                     2.0          152.0   \n",
       "60557_00025            cpu                     3.0          128.0   \n",
       "60557_00018            cpu                     2.0           64.0   \n",
       "60557_00019            cpu                     2.0          128.0   \n",
       "60557_00028            cpu                     3.0          128.0   \n",
       "60557_00010            cpu                     3.0          128.0   \n",
       "60557_00007            cpu                     3.0          128.0   \n",
       "60557_00006            cpu                     3.0           64.0   \n",
       "60557_00029            cpu                     3.0          152.0   \n",
       "60557_00008            cpu                     3.0          152.0   \n",
       "60557_00024            cpu                     3.0           64.0   \n",
       "60557_00027            cpu                     3.0           64.0   \n",
       "60557_00013            cpu                     4.0          128.0   \n",
       "60557_00014            cpu                     4.0          152.0   \n",
       "60557_00009            cpu                     3.0           64.0   \n",
       "60557_00032            cpu                     4.0          152.0   \n",
       "60557_00031            cpu                     4.0          128.0   \n",
       "60557_00030            cpu                     4.0           64.0   \n",
       "60557_00012            cpu                     4.0           64.0   \n",
       "60557_00015            NaN                     NaN            NaN   \n",
       "60557_00035            NaN                     NaN            NaN   \n",
       "60557_00016            NaN                     NaN            NaN   \n",
       "60557_00033            NaN                     NaN            NaN   \n",
       "60557_00034            NaN                     NaN            NaN   \n",
       "60557_00017            NaN                     NaN            NaN   \n",
       "\n",
       "             config/kernel_size config/stride config/padding  \n",
       "trial_id                                                      \n",
       "60557_00005                 3.0           1.0            0.0  \n",
       "60557_00001                 2.0           1.0            0.0  \n",
       "60557_00023                 3.0           1.0            0.0  \n",
       "60557_00002                 2.0           1.0            0.0  \n",
       "60557_00004                 3.0           1.0            0.0  \n",
       "60557_00022                 3.0           1.0            0.0  \n",
       "60557_00000                 2.0           1.0            0.0  \n",
       "60557_00003                 3.0           1.0            0.0  \n",
       "60557_00021                 3.0           1.0            0.0  \n",
       "60557_00026                 2.0           1.0            0.0  \n",
       "60557_00011                 3.0           1.0            0.0  \n",
       "60557_00020                 2.0           1.0            0.0  \n",
       "60557_00025                 2.0           1.0            0.0  \n",
       "60557_00018                 2.0           1.0            0.0  \n",
       "60557_00019                 2.0           1.0            0.0  \n",
       "60557_00028                 3.0           1.0            0.0  \n",
       "60557_00010                 3.0           1.0            0.0  \n",
       "60557_00007                 2.0           1.0            0.0  \n",
       "60557_00006                 2.0           1.0            0.0  \n",
       "60557_00029                 3.0           1.0            0.0  \n",
       "60557_00008                 2.0           1.0            0.0  \n",
       "60557_00024                 2.0           1.0            0.0  \n",
       "60557_00027                 3.0           1.0            0.0  \n",
       "60557_00013                 2.0           1.0            0.0  \n",
       "60557_00014                 2.0           1.0            0.0  \n",
       "60557_00009                 3.0           1.0            0.0  \n",
       "60557_00032                 2.0           1.0            0.0  \n",
       "60557_00031                 2.0           1.0            0.0  \n",
       "60557_00030                 2.0           1.0            0.0  \n",
       "60557_00012                 2.0           1.0            0.0  \n",
       "60557_00015                 NaN           NaN            NaN  \n",
       "60557_00035                 NaN           NaN            NaN  \n",
       "60557_00016                 NaN           NaN            NaN  \n",
       "60557_00033                 NaN           NaN            NaN  \n",
       "60557_00034                 NaN           NaN            NaN  \n",
       "60557_00017                 NaN           NaN            NaN  \n",
       "\n",
       "[36 rows x 37 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_df.sort_values(\"val_accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99cc5d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-10-19 16:09:25</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:00.07        </td></tr>\n",
       "<tr><td>Memory:      </td><td>10.7/31.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 6.000: None | Iter 3.000: None<br>Logical resource usage: 0/20 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  filters</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">  kernel_size</th><th style=\"text-align: right;\">  num_conv_layers</th><th style=\"text-align: right;\">  padding</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  train_accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00018</td><td>TERMINATED</td><td>10.82.72.122:1821810</td><td style=\"text-align: right;\">      195</td><td style=\"text-align: right;\">          349</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         5586.59</td><td style=\"text-align: right;\">    0.391492</td><td style=\"text-align: right;\">  0.898231</td><td style=\"text-align: right;\">          86.108</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00008</td><td>TERMINATED</td><td>10.82.72.122:1821807</td><td style=\"text-align: right;\">      191</td><td style=\"text-align: right;\">          493</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         5373.15</td><td style=\"text-align: right;\">    0.391925</td><td style=\"text-align: right;\">  0.840546</td><td style=\"text-align: right;\">          85.932</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00009</td><td>TERMINATED</td><td>10.82.72.122:1821802</td><td style=\"text-align: right;\">      178</td><td style=\"text-align: right;\">          380</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         5270.22</td><td style=\"text-align: right;\">    0.388119</td><td style=\"text-align: right;\">  0.90601 </td><td style=\"text-align: right;\">          86.128</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00000</td><td>TERMINATED</td><td>10.82.72.122:1821795</td><td style=\"text-align: right;\">      184</td><td style=\"text-align: right;\">          474</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         5141.11</td><td style=\"text-align: right;\">    0.347752</td><td style=\"text-align: right;\">  0.931516</td><td style=\"text-align: right;\">          87.556</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00014</td><td>TERMINATED</td><td>10.82.72.122:1821806</td><td style=\"text-align: right;\">      190</td><td style=\"text-align: right;\">          505</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         5048.94</td><td style=\"text-align: right;\">    0.365697</td><td style=\"text-align: right;\">  0.848114</td><td style=\"text-align: right;\">          86.87 </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00015</td><td>TERMINATED</td><td>10.82.72.122:1821805</td><td style=\"text-align: right;\">      168</td><td style=\"text-align: right;\">          428</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         4983.77</td><td style=\"text-align: right;\">    0.38312 </td><td style=\"text-align: right;\">  0.855092</td><td style=\"text-align: right;\">          86.284</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00007</td><td>TERMINATED</td><td>10.82.72.122:1821803</td><td style=\"text-align: right;\">      174</td><td style=\"text-align: right;\">          359</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         4832.43</td><td style=\"text-align: right;\">    0.428741</td><td style=\"text-align: right;\">  0.840812</td><td style=\"text-align: right;\">          84.69 </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00012</td><td>TERMINATED</td><td>10.82.72.122:1821799</td><td style=\"text-align: right;\">      166</td><td style=\"text-align: right;\">          310</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         4769.79</td><td style=\"text-align: right;\">    0.415587</td><td style=\"text-align: right;\">  0.847215</td><td style=\"text-align: right;\">          85.112</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00001</td><td>TERMINATED</td><td>10.82.72.122:1821813</td><td style=\"text-align: right;\">      157</td><td style=\"text-align: right;\">          402</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         4742.13</td><td style=\"text-align: right;\">    0.412768</td><td style=\"text-align: right;\">  0.877463</td><td style=\"text-align: right;\">          85.364</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00017</td><td>TERMINATED</td><td>10.82.72.122:1821797</td><td style=\"text-align: right;\">      145</td><td style=\"text-align: right;\">          474</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         4458.35</td><td style=\"text-align: right;\">    0.416557</td><td style=\"text-align: right;\">  0.846482</td><td style=\"text-align: right;\">          85.112</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00002</td><td>TERMINATED</td><td>10.82.72.122:1821812</td><td style=\"text-align: right;\">      143</td><td style=\"text-align: right;\">          325</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         4074.16</td><td style=\"text-align: right;\">    0.479114</td><td style=\"text-align: right;\">  0.841691</td><td style=\"text-align: right;\">          82.956</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00019</td><td>TERMINATED</td><td>10.82.72.122:1821800</td><td style=\"text-align: right;\">      122</td><td style=\"text-align: right;\">          312</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3346.18</td><td style=\"text-align: right;\">    0.460384</td><td style=\"text-align: right;\">  0.845245</td><td style=\"text-align: right;\">          83.786</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00004</td><td>TERMINATED</td><td>10.82.72.122:1821798</td><td style=\"text-align: right;\">      100</td><td style=\"text-align: right;\">          378</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         2947.15</td><td style=\"text-align: right;\">    0.572131</td><td style=\"text-align: right;\">  0.815768</td><td style=\"text-align: right;\">          79.694</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00003</td><td>TERMINATED</td><td>10.82.72.122:1821811</td><td style=\"text-align: right;\">      115</td><td style=\"text-align: right;\">          482</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         2305.8 </td><td style=\"text-align: right;\">    0.688689</td><td style=\"text-align: right;\">  0.868932</td><td style=\"text-align: right;\">          75.836</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00006</td><td>TERMINATED</td><td>10.82.72.122:1821804</td><td style=\"text-align: right;\">      116</td><td style=\"text-align: right;\">          344</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         2179.25</td><td style=\"text-align: right;\">    0.776367</td><td style=\"text-align: right;\">  0.8768  </td><td style=\"text-align: right;\">          72.658</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00013</td><td>TERMINATED</td><td>10.82.72.122:1821801</td><td style=\"text-align: right;\">      103</td><td style=\"text-align: right;\">          420</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         2061.53</td><td style=\"text-align: right;\">    0.702574</td><td style=\"text-align: right;\">  0.86504 </td><td style=\"text-align: right;\">          75.224</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00005</td><td>TERMINATED</td><td>10.82.72.122:1821808</td><td style=\"text-align: right;\">      142</td><td style=\"text-align: right;\">          405</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         1802.23</td><td style=\"text-align: right;\">    0.992911</td><td style=\"text-align: right;\">  1.03594 </td><td style=\"text-align: right;\">          64.882</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00011</td><td>TERMINATED</td><td>10.82.72.122:1821794</td><td style=\"text-align: right;\">      134</td><td style=\"text-align: right;\">          426</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         1470.63</td><td style=\"text-align: right;\">    0.998834</td><td style=\"text-align: right;\">  1.03982 </td><td style=\"text-align: right;\">          64.382</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00010</td><td>TERMINATED</td><td>10.82.72.122:1821796</td><td style=\"text-align: right;\">      127</td><td style=\"text-align: right;\">          355</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         1424.65</td><td style=\"text-align: right;\">    1.00635 </td><td style=\"text-align: right;\">  1.07036 </td><td style=\"text-align: right;\">          64.234</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_c2308_00016</td><td>TERMINATED</td><td>10.82.72.122:1821809</td><td style=\"text-align: right;\">      116</td><td style=\"text-align: right;\">          373</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         1288.63</td><td style=\"text-align: right;\">    1.02545 </td><td style=\"text-align: right;\">  1.02085 </td><td style=\"text-align: right;\">          63.314</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 16:09:24,797\tINFO tune_controller.py:444 -- Restoring the run from the latest experiment state file: experiment_state-2025-10-19_14-42-37.json\n",
      "2025-10-19 16:09:25,008\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune/cnn_hyperparameter_hyperband' in 0.0677s.\n",
      "2025-10-19 16:09:25,021\tINFO tune.py:1041 -- Total run time: 0.24 seconds (0.00 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "trial_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "train_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "train_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "timestamp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "checkpoint_dir_name",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "done",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "training_iteration",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "time_this_iter_s",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "time_total_s",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pid",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hostname",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "node_ip",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "time_since_restore",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "iterations_since_restore",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "experiment_tag",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "config/epochs",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "config/data_dir",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "config/tune_dir",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "config/batch_size",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "config/input_size",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "config/output_size",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "config/hidden_size",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "config/dropout",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "config/num_fully_connected_layers",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "config/learning_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "config/loss_fn",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "config/optimizer",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "config/scheduler",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "config/metrics",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "config/device",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "config/num_conv_layers",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "config/filters",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "config/kernel_size",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "config/stride",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "config/padding",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "3ad0364e-2726-4e71-b609-1286528c9ec9",
       "rows": [
        [
         "c2308_00004",
         "0.5721307092577296",
         "0.8157684430954563",
         "79.694",
         "72.23",
         "1760873360",
         null,
         "True",
         "10",
         "2025-10-19_13-29-20",
         "225.44476890563965",
         "2947.1529953479767",
         "1821798",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "2947.1529953479767",
         "10",
         "4_filters=100,hidden_size=378,kernel_size=2,num_conv_layers=3,padding=0",
         "10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64",
         "3",
         "20",
         "378",
         "0",
         "2",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "3",
         "100",
         "2",
         "1",
         "0"
        ],
        [
         "c2308_00008",
         "0.39192452087350516",
         "0.8405463908128677",
         "85.932",
         "73.82",
         "1760875787",
         null,
         "True",
         "10",
         "2025-10-19_14-09-47",
         "264.1451916694641",
         "5373.148638248444",
         "1821807",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "5373.148638248444",
         "10",
         "8_filters=191,hidden_size=493,kernel_size=2,num_conv_layers=3,padding=0",
         "10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64",
         "3",
         "20",
         "493",
         "0",
         "2",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "3",
         "191",
         "2",
         "1",
         "0"
        ],
        [
         "c2308_00007",
         "0.42874079834088646",
         "0.8408123300333691",
         "84.69",
         "73.46",
         "1760875246",
         null,
         "True",
         "10",
         "2025-10-19_14-00-46",
         "320.4534487724304",
         "4832.431614398956",
         "1821803",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "4832.431614398956",
         "10",
         "7_filters=174,hidden_size=359,kernel_size=2,num_conv_layers=3,padding=0",
         "10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64",
         "3",
         "20",
         "359",
         "0",
         "2",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "3",
         "174",
         "2",
         "1",
         "0"
        ],
        [
         "c2308_00002",
         "0.47911362555783116",
         "0.8416911156693841",
         "82.956",
         "72.65",
         "1760874488",
         null,
         "True",
         "10",
         "2025-10-19_13-48-08",
         "258.5290598869324",
         "4074.1638712882996",
         "1821812",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "4074.1638712882996",
         "10",
         "2_filters=143,hidden_size=325,kernel_size=2,num_conv_layers=3,padding=0",
         "10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64",
         "3",
         "20",
         "325",
         "0",
         "2",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "3",
         "143",
         "2",
         "1",
         "0"
        ],
        [
         "c2308_00019",
         "0.4603839476052148",
         "0.8452453282987995",
         "83.786",
         "72.95",
         "1760873759",
         null,
         "True",
         "10",
         "2025-10-19_13-35-59",
         "246.38270950317383",
         "3346.182051181793",
         "1821800",
         "nlfij-l0040.rz.rijkzwaan.net",
         "10.82.72.122",
         "3346.182051181793",
         "10",
         "19_filters=122,hidden_size=312,kernel_size=2,num_conv_layers=3,padding=0",
         "10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10",
         "/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune",
         "64",
         "3",
         "20",
         "312",
         "0",
         "2",
         "0.001",
         "CrossEntropyLoss()",
         "<class 'torch.optim.adam.Adam'>",
         "<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>",
         "accuracy",
         "cpu",
         "3",
         "122",
         "2",
         "1",
         "0"
        ]
       ],
       "shape": {
        "columns": 37,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>checkpoint_dir_name</th>\n",
       "      <th>done</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>date</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>...</th>\n",
       "      <th>config/loss_fn</th>\n",
       "      <th>config/optimizer</th>\n",
       "      <th>config/scheduler</th>\n",
       "      <th>config/metrics</th>\n",
       "      <th>config/device</th>\n",
       "      <th>config/num_conv_layers</th>\n",
       "      <th>config/filters</th>\n",
       "      <th>config/kernel_size</th>\n",
       "      <th>config/stride</th>\n",
       "      <th>config/padding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c2308_00004</th>\n",
       "      <td>0.572131</td>\n",
       "      <td>0.815768</td>\n",
       "      <td>79.694</td>\n",
       "      <td>72.23</td>\n",
       "      <td>1760873360</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-10-19_13-29-20</td>\n",
       "      <td>225.444769</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2308_00008</th>\n",
       "      <td>0.391925</td>\n",
       "      <td>0.840546</td>\n",
       "      <td>85.932</td>\n",
       "      <td>73.82</td>\n",
       "      <td>1760875787</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-10-19_14-09-47</td>\n",
       "      <td>264.145192</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>3</td>\n",
       "      <td>191</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2308_00007</th>\n",
       "      <td>0.428741</td>\n",
       "      <td>0.840812</td>\n",
       "      <td>84.690</td>\n",
       "      <td>73.46</td>\n",
       "      <td>1760875246</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-10-19_14-00-46</td>\n",
       "      <td>320.453449</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2308_00002</th>\n",
       "      <td>0.479114</td>\n",
       "      <td>0.841691</td>\n",
       "      <td>82.956</td>\n",
       "      <td>72.65</td>\n",
       "      <td>1760874488</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-10-19_13-48-08</td>\n",
       "      <td>258.529060</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2308_00019</th>\n",
       "      <td>0.460384</td>\n",
       "      <td>0.845245</td>\n",
       "      <td>83.786</td>\n",
       "      <td>72.95</td>\n",
       "      <td>1760873759</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-10-19_13-35-59</td>\n",
       "      <td>246.382710</td>\n",
       "      <td>...</td>\n",
       "      <td>CrossEntropyLoss()</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>&lt;class 'torch.optim.lr_scheduler.ReduceLROnPla...</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>cpu</td>\n",
       "      <td>3</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             train_loss  val_loss  train_accuracy  val_accuracy   timestamp  \\\n",
       "trial_id                                                                      \n",
       "c2308_00004    0.572131  0.815768          79.694         72.23  1760873360   \n",
       "c2308_00008    0.391925  0.840546          85.932         73.82  1760875787   \n",
       "c2308_00007    0.428741  0.840812          84.690         73.46  1760875246   \n",
       "c2308_00002    0.479114  0.841691          82.956         72.65  1760874488   \n",
       "c2308_00019    0.460384  0.845245          83.786         72.95  1760873759   \n",
       "\n",
       "            checkpoint_dir_name  done  training_iteration  \\\n",
       "trial_id                                                    \n",
       "c2308_00004                None  True                  10   \n",
       "c2308_00008                None  True                  10   \n",
       "c2308_00007                None  True                  10   \n",
       "c2308_00002                None  True                  10   \n",
       "c2308_00019                None  True                  10   \n",
       "\n",
       "                            date  time_this_iter_s  ...      config/loss_fn  \\\n",
       "trial_id                                            ...                       \n",
       "c2308_00004  2025-10-19_13-29-20        225.444769  ...  CrossEntropyLoss()   \n",
       "c2308_00008  2025-10-19_14-09-47        264.145192  ...  CrossEntropyLoss()   \n",
       "c2308_00007  2025-10-19_14-00-46        320.453449  ...  CrossEntropyLoss()   \n",
       "c2308_00002  2025-10-19_13-48-08        258.529060  ...  CrossEntropyLoss()   \n",
       "c2308_00019  2025-10-19_13-35-59        246.382710  ...  CrossEntropyLoss()   \n",
       "\n",
       "                            config/optimizer  \\\n",
       "trial_id                                       \n",
       "c2308_00004  <class 'torch.optim.adam.Adam'>   \n",
       "c2308_00008  <class 'torch.optim.adam.Adam'>   \n",
       "c2308_00007  <class 'torch.optim.adam.Adam'>   \n",
       "c2308_00002  <class 'torch.optim.adam.Adam'>   \n",
       "c2308_00019  <class 'torch.optim.adam.Adam'>   \n",
       "\n",
       "                                              config/scheduler config/metrics  \\\n",
       "trial_id                                                                        \n",
       "c2308_00004  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "c2308_00008  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "c2308_00007  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "c2308_00002  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "c2308_00019  <class 'torch.optim.lr_scheduler.ReduceLROnPla...       accuracy   \n",
       "\n",
       "             config/device  config/num_conv_layers config/filters  \\\n",
       "trial_id                                                            \n",
       "c2308_00004            cpu                       3            100   \n",
       "c2308_00008            cpu                       3            191   \n",
       "c2308_00007            cpu                       3            174   \n",
       "c2308_00002            cpu                       3            143   \n",
       "c2308_00019            cpu                       3            122   \n",
       "\n",
       "             config/kernel_size config/stride config/padding  \n",
       "trial_id                                                      \n",
       "c2308_00004                   2             1              0  \n",
       "c2308_00008                   2             1              0  \n",
       "c2308_00007                   2             1              0  \n",
       "c2308_00002                   2             1              0  \n",
       "c2308_00019                   2             1              0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "\n",
    "config_hyperband = {\n",
    "    # Fixed parameters\n",
    "    \"epochs\": 10,\n",
    "    \"data_dir\": Path(DATADIR).resolve(),\n",
    "    \"tune_dir\": Path(TUNEDIR).resolve(),\n",
    "    \"batch_size\": 64,\n",
    "    \"input_size\": 3,\n",
    "    \"output_size\": 20,\n",
    "    \"hidden_size\": tune.randint(254, 512),\n",
    "    \"dropout\": 0,\n",
    "    \"num_fully_connected_layers\": 2,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"loss_fn\": torch.nn.CrossEntropyLoss(), # suitable for multi-class classification\n",
    "    \"optimizer\": torch.optim.Adam,\n",
    "    \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"metrics\": \"accuracy\",\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    # convolutional layer parameters\n",
    "    \"num_conv_layers\": tune.grid_search([3]),\n",
    "    \"filters\": tune.randint(100, 200),\n",
    "    \"kernel_size\": tune.randint(2, 3),\n",
    "    \"stride\": 1,\n",
    "    \"padding\": tune.randint(0, 1),  # typical options for padding\n",
    "}\n",
    "\n",
    "# Create an AsyncHyperBandScheduler for efficient hyperparameter search\n",
    "scheduler_hyperband = AsyncHyperBandScheduler(\n",
    "    time_attr=\"training_iteration\",  # attribute that tracks training progress\n",
    "    grace_period=3,                  # start terminating after 3 epochs\n",
    "    reduction_factor=2,              # half the number of models per epoch after grace_period\n",
    "    max_t=config_hyperband[\"epochs\"] # train for max 10 epochs\n",
    ")\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_and_evaluate_ray,\n",
    "    config=config_hyperband,\n",
    "    name=\"cnn_hyperparameter_hyperband\",\n",
    "    metric=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    storage_path=str(config_hyperband[\"tune_dir\"]),  # ensure path is string\n",
    "    num_samples=20,\n",
    "    verbose=1,\n",
    "    scheduler=scheduler_hyperband,\n",
    "    resume=True\n",
    ")\n",
    "tune_df_hyperband = analysis.results_df.sort_values(\"val_loss\")\n",
    "tune_df_hyperband.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d99889d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 10,\n",
       " 'data_dir': PosixPath('/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10'),\n",
       " 'tune_dir': PosixPath('/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune'),\n",
       " 'batch_size': 64,\n",
       " 'input_size': 3,\n",
       " 'output_size': 20,\n",
       " 'hidden_size': 378,\n",
       " 'dropout': 0,\n",
       " 'num_fully_connected_layers': 2,\n",
       " 'learning_rate': 0.001,\n",
       " 'loss_fn': CrossEntropyLoss(),\n",
       " 'optimizer': torch.optim.adam.Adam,\n",
       " 'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
       " 'metrics': 'accuracy',\n",
       " 'device': 'cpu',\n",
       " 'num_conv_layers': 3,\n",
       " 'filters': 100,\n",
       " 'kernel_size': 2,\n",
       " 'stride': 1,\n",
       " 'padding': 0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = analysis.get_best_config()\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66b11eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-19 16:09:25.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mBest config: {'epochs': 10, 'data_dir': PosixPath('/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/data/raw/cifar10'), 'tune_dir': PosixPath('/mnt/WORKSPACE/kiei_workspace/master/UOS3/portfolio-DLDEPL01_2025/4-hypertuning-ray/hypertune'), 'batch_size': 64, 'input_size': 3, 'output_size': 20, 'hidden_size': 378, 'dropout': 0, 'num_fully_connected_layers': 2, 'learning_rate': 0.001, 'loss_fn': CrossEntropyLoss(), 'optimizer': <class 'torch.optim.adam.Adam'>, 'scheduler': <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>, 'metrics': 'accuracy', 'device': 'cpu', 'num_conv_layers': 3, 'filters': 100, 'kernel_size': 2, 'stride': 1, 'padding': 0}\u001b[0m\n",
      "2025-10-19 16:09:25,248\tERROR experiment_analysis.py:467 -- No checkpoints have been found for trial train_and_evaluate_ray_c2308_00004.\n",
      "Training: 100%|██████████| 782/782 [00:28<00:00, 27.18it/s]\n",
      "\u001b[32m2025-10-19 16:10:02.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mEpoch [1/10], Train Loss: 1.6916, Test Loss: 1.4286, Train Acc: 37.46%, Test Acc: 47.07%\u001b[0m\n",
      "Training: 100%|██████████| 782/782 [00:32<00:00, 24.39it/s]\n",
      "\u001b[32m2025-10-19 16:10:36.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mEpoch [2/10], Train Loss: 1.2636, Test Loss: 1.2108, Train Acc: 54.40%, Test Acc: 56.80%\u001b[0m\n",
      "Training: 100%|██████████| 782/782 [00:31<00:00, 24.44it/s]\n",
      "\u001b[32m2025-10-19 16:11:10.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mEpoch [3/10], Train Loss: 1.0827, Test Loss: 1.0616, Train Acc: 61.43%, Test Acc: 62.33%\u001b[0m\n",
      "Training: 100%|██████████| 782/782 [00:32<00:00, 24.01it/s]\n",
      "\u001b[32m2025-10-19 16:11:45.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mEpoch [4/10], Train Loss: 0.9534, Test Loss: 0.9681, Train Acc: 66.24%, Test Acc: 65.59%\u001b[0m\n",
      "Training: 100%|██████████| 782/782 [00:33<00:00, 23.50it/s]\n",
      "\u001b[32m2025-10-19 16:12:21.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mEpoch [5/10], Train Loss: 0.8574, Test Loss: 0.9003, Train Acc: 69.52%, Test Acc: 68.50%\u001b[0m\n",
      "Training: 100%|██████████| 782/782 [00:33<00:00, 23.44it/s]\n",
      "\u001b[32m2025-10-19 16:12:56.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mEpoch [6/10], Train Loss: 0.7714, Test Loss: 0.8907, Train Acc: 72.64%, Test Acc: 68.94%\u001b[0m\n",
      "Training: 100%|██████████| 782/782 [00:33<00:00, 23.68it/s]\n",
      "\u001b[32m2025-10-19 16:13:32.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mEpoch [7/10], Train Loss: 0.7029, Test Loss: 0.8516, Train Acc: 75.18%, Test Acc: 70.75%\u001b[0m\n",
      "Training: 100%|██████████| 782/782 [00:33<00:00, 23.55it/s]\n",
      "\u001b[32m2025-10-19 16:14:07.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mEpoch [8/10], Train Loss: 0.6366, Test Loss: 0.8422, Train Acc: 77.43%, Test Acc: 71.89%\u001b[0m\n",
      "Training: 100%|██████████| 782/782 [00:33<00:00, 23.66it/s]\n",
      "\u001b[32m2025-10-19 16:14:42.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mEpoch [9/10], Train Loss: 0.5787, Test Loss: 0.8230, Train Acc: 79.77%, Test Acc: 72.21%\u001b[0m\n",
      "Training: 100%|██████████| 782/782 [00:32<00:00, 23.88it/s]\n",
      "\u001b[32m2025-10-19 16:15:17.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mEpoch [10/10], Train Loss: 0.5250, Test Loss: 0.8275, Train Acc: 81.43%, Test Acc: 72.89%\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAHHCAYAAAAVhJRcAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAlidJREFUeJzs3Xd8zPcfB/DXZUoiCxEJQWyxd62iaMxaLWqPtvbuoPYeP1RR1K7aFNXaq9SoHaOxZ5DYkYHM7++Pd+8uR0TGJd+73Ov5eNwjd9/7fr/3uYT7vu8z3m+NoigKiIiIiEh1Vmo3gIiIiIgEAzMiIiIiE8HAjIiIiMhEMDAjIiIiMhEMzIiIiIhMBAMzIiIiIhPBwIyIiIjIRDAwIyIiIjIRDMyIiIiITAQDMyIyOfnz50eXLl3UbgYRUYZjYEaUSS1fvhwajQanTp1Suylm5/Xr1/jhhx9QpUoVuLq6IkuWLChSpAj69u2Lq1evqt08IsrEbNRuABHRm65cuQIrK3W+Nz558gQNGjTA6dOn0aRJE7Rr1w5Zs2bFlStXsHbtWixcuBDR0dGqtI2IMj8GZkSUrmJjYxEfHw87O7tkH2Nvb5+OLUpaly5dcPbsWWzcuBGtWrUyeG78+PEYPny4UV4nNb8XIsr8OJRJZOHu37+Pbt26wdPTE/b29ihRogSWLl1qsE90dDRGjRqFChUqwNXVFU5OTqhZsyYOHDhgsN/t27eh0Wgwffp0zJo1CwULFoS9vT0CAwMxZswYaDQaXL9+HV26dIGbmxtcXV3RtWtXvHz50uA8b84x0w7LHjlyBIMHD4aHhwecnJzQokULPH782ODY+Ph4jBkzBt7e3nB0dESdOnUQGBiYrHlrx48fx7Zt29C9e/e3gjJAAsbp06frHteuXRu1a9d+a78uXbogf/787/29nD17FjY2Nhg7duxb57hy5Qo0Gg3mzp2r2xYaGoqBAwfCx8cH9vb2KFSoEKZOnYr4+Pgk3xcRmQ/2mBFZsIcPH+KDDz6ARqNB37594eHhgR07dqB79+4ICwvDwIEDAQBhYWFYvHgxPv/8c3z55ZcIDw/HkiVL4O/vjxMnTqBs2bIG5122bBlev36Nr776Cvb29siWLZvuudatW8PX1xeTJ0/GmTNnsHjxYuTMmRNTp059b3v79esHd3d3jB49Grdv38asWbPQt29frFu3TrfPsGHDMG3aNDRt2hT+/v44d+4c/P398fr16/eef+vWrQCAjh07JuO3l3Jv/l68vLxQq1YtrF+/HqNHjzbYd926dbC2tsZnn30GAHj58iVq1aqF+/fvo0ePHsibNy+OHj2KYcOGITg4GLNmzUqXNhNRBlOIKFNatmyZAkA5efLkO/fp3r274uXlpTx58sRge9u2bRVXV1fl5cuXiqIoSmxsrBIVFWWwz/PnzxVPT0+lW7duum23bt1SACguLi7Ko0ePDPYfPXq0AsBgf0VRlBYtWijZs2c32JYvXz6lc+fOb72XevXqKfHx8brtgwYNUqytrZXQ0FBFURQlJCREsbGxUZo3b25wvjFjxigADM6ZmBYtWigAlOfPnye5n1atWrWUWrVqvbW9c+fOSr58+XSPk/q9/PzzzwoA5cKFCwbb/fz8lI8++kj3ePz48YqTk5Ny9epVg/2GDh2qWFtbK3fv3k1Wm4nItHEok8hCKYqC3377DU2bNoWiKHjy5Inu5u/vjxcvXuDMmTMAAGtra91cqPj4eDx79gyxsbGoWLGibp+EWrVqBQ8Pj0Rft2fPngaPa9asiadPnyIsLOy9bf7qq6+g0WgMjo2Li8OdO3cAAPv27UNsbCx69+5tcFy/fv3ee24AujY4Ozsna/+USuz30rJlS9jY2Bj0+l28eBGBgYFo06aNbtuGDRtQs2ZNuLu7G/yt6tWrh7i4OBw6dChd2kxEGYtDmUQW6vHjxwgNDcXChQuxcOHCRPd59OiR7v4vv/yCGTNm4PLly4iJidFt9/X1feu4xLZp5c2b1+Cxu7s7AOD58+dwcXFJss1JHQtAF6AVKlTIYL9s2bLp9k2K9vXDw8Ph5ub23v1TKrHfS44cOVC3bl2sX78e48ePByDDmDY2NmjZsqVuv2vXruH8+fPvDHgT/q2IyHwxMCOyUNoJ4x06dEDnzp0T3ad06dIAgJUrV6JLly5o3rw5vvnmG+TMmRPW1taYPHkybty48dZxDg4O73xda2vrRLcrivLeNqfl2OQoVqwYAODChQuoWbPme/fXaDSJvnZcXFyi+7/r99K2bVt07doVAQEBKFu2LNavX4+6desiR44cun3i4+NRv359fPvtt4meo0iRIu9tLxGZPgZmRBbKw8MDzs7OiIuLQ7169ZLcd+PGjShQoAA2bdpkMJT45oR1teXLlw8AcP36dYPeqadPn+p61ZLStGlTTJ48GStXrkxWYObu7o6bN2++tV3bc5dczZs3R48ePXTDmVevXsWwYcMM9ilYsCAiIiLe+7ciIvPGOWZEFsra2hqtWrXCb7/9hosXL771fMI0FNqeqoS9Q8ePH8exY8fSv6EpULduXdjY2GD+/PkG2xOmnEhK1apV0aBBAyxevBhbtmx56/no6Gh8/fXXuscFCxbE5cuXDX5X586dw5EjR1LUbjc3N/j7+2P9+vVYu3Yt7Ozs0Lx5c4N9WrdujWPHjmHXrl1vHR8aGorY2NgUvSYRmSb2mBFlckuXLsXOnTvf2j5gwABMmTIFBw4cQJUqVfDll1/Cz88Pz549w5kzZ7B37148e/YMANCkSRNs2rQJLVq0QOPGjXHr1i0sWLAAfn5+iIiIyOi39E6enp4YMGAAZsyYgU8++QQNGjTAuXPnsGPHDuTIkcOgt+9dVqxYgY8//hgtW7ZE06ZNUbduXTg5OeHatWtYu3YtgoODdbnMunXrhpkzZ8Lf3x/du3fHo0ePsGDBApQoUSJZixkSatOmDTp06IB58+bB39//rTlu33zzDbZu3YomTZqgS5cuqFChAiIjI3HhwgVs3LgRt2/fNhj6JCLzxMCMKJN7s/dIq0uXLsiTJw9OnDiBcePGYdOmTZg3bx6yZ8+OEiVKGOQV69KlC0JCQvDzzz9j165d8PPzw8qVK7Fhwwb89ddfGfROkmfq1KlwdHTEokWLsHfvXlStWhW7d+9GjRo1kCVLlvce7+HhgaNHj2LevHlYt24dhg8fjujoaOTLlw+ffPIJBgwYoNu3ePHiWLFiBUaNGoXBgwfDz88Pv/76K1avXp3i38snn3wCBwcHhIeHG6zG1HJ0dMTBgwcxadIkbNiwAStWrICLiwuKFCmCsWPHwtXVNUWvR0SmSaMYa9YsEZGJCg0Nhbu7OyZMmGC0kkpEROmBc8yIKFN59erVW9u0WfETK59ERGRKOJRJRJnKunXrsHz5cjRq1AhZs2bF4cOHsWbNGnz88ceoXr262s0jIkoSAzMiylRKly4NGxsbTJs2DWFhYboFARMmTFC7aURE78U5ZkREREQmgnPMiIiIiEwEAzMiIiIiE2Fxc8xiY2Nx9uxZeHp6wsqKcSkREZE5iI+Px8OHD1GuXDnY2GTe8CXzvrN3OHv2LCpXrqx2M4iIiCgVTpw4gUqVKqndjHRjcYGZp6cnAPnDenl5qdwaIiIiSo7g4GBUrlxZdx3PrCwuMNMOX3p5eSFPnjwqt4aIiIhSIrNPQ8rc746IiIjIjDAwIyIiIjIRDMyIiIiITITFzTFLrri4OMTExKjdDDICOzu7TD8ngYjexs9x88PPawZmb1EUBSEhIQgNDVW7KWQkVlZW8PX1hZ2dndpNIaIMwM9x88XPawZmb9H+Z86ZMyccHR2h0WjUbhKlQXx8PB48eIDg4GDkzZuXf08iC8DPcfPEz2vBwCyBuLg43X/m7Nmzq90cMhIPDw88ePAAsbGxsLW1Vbs5RJSO+Dlu3vh5zcn/BrRzERwdHVVuCRmTtks8Li5O5ZYQUXrj57h54+c1A7NEWWr3aWbFvyeR5eH/e/PEvxsDMyIiIiKTwcCM3il//vyYNWuW2s0gIqJU4ue4+WFglgloNJokb2PGjEnVeU+ePImvvvoqTW2rXbs2Bg4cmKZzEBFldqb8Oa61Zs0aWFtbo0+fPkY5HyWOqzKNKDYWiIoCnJwy9nWDg4N199etW4dRo0bhypUrum1Zs2bV3VcUBXFxcbCxef+f3sPDw7gNJSKiRJnD5/iSJUvw7bff4ueff8aMGTOQJUuWRPdTFIBTxVKPPWZGEhEBnD8P3Lgh/ygzUq5cuXQ3V1dXaDQa3ePLly/D2dkZO3bsQIUKFWBvb4/Dhw/jxo0baNasGTw9PZE1a1ZUqlQJe/fuNTjvm13gGo0GixcvRosWLeDo6IjChQtj69ataWr7b7/9hhIlSsDe3h758+fHjBkzDJ6fN28eChcujCxZssDT0xOffvqp7rmNGzeiVKlScHBwQPbs2VGvXj1ERkamqT1ERGow9c/xW7du4ejRoxg6dCiKFCmCTZs2vbXP0qVLUbSofJ57eXmhb9++uudCQ0PRo0cPeHp6IkuWLChZsiT+/PPP1P/CMjH2mL2HogAvXyZvv6goIDISePAAcHNL+2s7OhrvW8fQoUMxffp0FChQAO7u7ggKCkKjRo0wceJE2NvbY8WKFWjatCmuXLmCvHnzvvM8Y8eOxbRp0/C///0Pc+bMQfv27XHnzh1ky5YtxW06ffo0WrdujTFjxqBNmzY4evQoevfujezZs6NLly44deoU+vfvj19//RXVqlXDs2fP8PfffwOQb5eff/45pk2bhhYtWiA8PBx///03lIyOionIbCT1vc3aGkjYAZTUvlZWgIND0vumx8iJmp/jy5YtQ+PGjeHq6op27Trg55+XoGbNdggPB3LnBlavno/BgwdjzJgpKFy4IXLnfoFjx44AkMSxDRs2RHh4OFauXImCBQsiMDAQ1tbWRv8dZQqKhQkKClIAKEFBQW899+rVKyUwMFB59eqVbltEhKJI2JXxt4iIlL+/ZcuWKa6urrrHBw4cUAAoW7Zsee+xJUqUUObMmaN7nC9fPuWHH37QPQagjBgxIsHvJkIBoOzYseOd56xVq5YyYMCARJ9r166dUr9+fYNt33zzjeLn56coiqL89ttviouLixIWFvbWsadPn1YAKLdv337v+0rs70pEmVNS/9+T+rxt1MhwX0fHd+9bq5bhvjlyvL1PWpja53hMTJySJ4+PsnjxFiUwUFH27Hms2NraKVu23FROnlSUu3cVxdvbWxk+fLgSF6co0dGGx+/atUuxsrJSrly58t72J/X3S+r6nZlwKNNCVKxY0eBxREQEvv76axQvXhxubm7ImjUrLl26hLt37yZ5ntKlS+vuOzk5wcXFBY8ePUpVmy5duoTq1asbbKtevTquXbuGuLg41K9fH/ny5UOBAgXQsWNHrFq1Ci//674sU6YM6tati1KlSuGzzz7DokWL8Pz581S1g4jIHGTU53hcHBAdrd9/x449CA+PRIkSjRAZCbi55UDVqvWxd+9S+PoCGs0jPHjwAHXr1oWVFfBmwv6AgADkyZMHRYoUSf2btyAcynwPR0eZP5Zc164B4eGAp6d076b1tY3F6Y1+9a+//hp79uzB9OnTUahQITg4OODTTz9FdML/jYl4s0SGRqNBfHy88RqagLOzM86cOYO//voLu3fvxqhRozBmzBicPHkSbm5u2LNnD44ePYrdu3djzpw5GD58OI4fPw5fX990aQ8RmbekPsvfHFVL6vum1RtdGrdvp7pJKZKen+ORkfG4f1+uXxJ8AQULyvO//roEL148Q40a+vHb+Ph43Lp1Hj/+OBZ2dg5IioND0s+TIQZm76HRpGyuQL58sgDg5UuZg/Dmf2BTceTIEXTp0gUtWrQAIN+8bmfUp8t/ihcvjiNHjrzVriJFiujmHtjY2KBevXqoV68eRo8eDTc3N+zfvx8tW7aERqNB9erVUb16dYwaNQr58uXD5s2bMXjw4Ax9H0RkHlLyWZ5e+xpTWj/Hg4OBsDDpIQsJkcdaUVHy8+nTp/j999+xdu1alChRQvd8XFwcatSogd27d6NBgwbInz8/9u3bhzp16rz1OqVLl8a9e/dw9epV9polAwMzI3N1lW7cmBggNBRIxZz4DFG4cGFs2rQJTZs2hUajwciRI9Ot5+vx48cICAgw2Obl5YUhQ4agUqVKGD9+PNq0aYNjx45h7ty5mDdvHgDgzz//xM2bN/Hhhx/C3d0d27dvR3x8PIoWLYrjx49j3759+Pjjj5EzZ04cP34cjx8/RvHixdPlPRARmZrkfo4rivQWvnpluD00VL9wwdparlfOznKzt5ftv/76K7Jnz47WrVu/VS6pUaNGWLJkCRo0aIAxY8agZ8+eyJkzp26i/5EjR9CvXz/UqlULH374IVq1aoWZM2eiUKFCuHz5MjQaDRo0aJAOvxnzZqL9OebLygrIkUPuP36sbluSMnPmTLi7u6NatWpo2rQp/P39Ub58+XR5rdWrV6NcuXIGt0WLFqF8+fJYv3491q5di5IlS2LUqFEYN24cunTpAgBwc3PDpk2b8NFHH6F48eJYsGAB1qxZgxIlSsDFxQWHDh1Co0aNUKRIEYwYMQIzZsxAw4YN0+U9EBGZmnd9jmsDseBgya95/z5w+TJw547h8Z6eMspjbQ34+AAFCgAeHrI6VRuDLV26FC1atEi0hmWrVq2wdetWPHnyBJ07d8asWbMwb948lChRAk2aNMG1a9d0+/7222+oVKkSPv/8c/j5+eHbb7+16ELlSdEoimXlF7h37x58fHwQFBSEPHnyGDz3+vVr3Lp1C76+vu9MnJcc0dGS0wwASpQwXFZNGc9Yf1ciMn2W/v89OFhub3ac2dhIT1iePPreMFOU1N8vqet3YuLi4jBmzBisXLkSISEh8Pb2RpcuXTBixAhdoKkoCkaPHo1FixYhNDQU1atXx/z581G4cOF0eX/JwaHMdGBnJxMnQ0OBJ0/kmwgREZExKIoMS4aHyxwxHx99DjZrawnKrK31w5LOztJBYGnZ+KdOnYr58+fjl19+QYkSJXDq1Cl07doVrq6u6N+/PwBg2rRpmD17Nn755Rf4+vpi5MiR8Pf3R2BgoGqBPQOzdOLhoQ/Mcuc23UUARERk2hIGYtpbwlFAV1d9YObuDmTNapmB2JuOHj2KZs2aoXHjxgCkCsKaNWtw4sQJANJbNmvWLIwYMQLNmjUDAKxYsQKenp7YsmUL2rZtq0q7GS6kExcX6TmLiwOePVO7NUREZC4UxXAoMiwMCAwEgoLkC39cnHzZd3WVoUkXF/2+trbGrRpjisLDwxEWFqa7RWmXkL6hWrVq2LdvH65evQoAOHfuHA4fPqybi3zr1i2EhISgXr16umNcXV1RpUoVHDt2LP3fyDuwxyydaDTSa3b/viwC0C4IICIiepN2JX9YmPSI5cghQRcg6TisreWndmjSySlzB19J8fPzM3g8evRojBkz5q39hg4dirCwMBQrVgzW1taIi4vDxIkT0b59ewBASEgIAMDT09PgOE9PT91zamBglo5y5JC6mZGRktfMmAljiYjIvMXFAS9eAE+fSkCWcClewmS4NjZA2bKWG4i9KTAwELkTZHC3f8dqhvXr12PVqlVYvXo1SpQogYCAAAwcOBDe3t7o3LlzRjU3xRiYpSNbW1kE8Py59Jrly6d2i4iIyBQoCnDxovSUaTk6yjVD2yOWEIMyPWdnZ7gkHL99h2+++QZDhw7VzRUrVaoU7ty5g8mTJ6Nz587IlSsXAODhw4fw8vLSHffw4UOULVs2XdqeHJxjls48POTn06eGkzWJiMgyKIqMnDx4oO8V02j0c5G9vCS1kp8f4O0tgRkXjKXdy5cvYfXGL9La2lqXhNfX1xe5cuXCvn37dM+HhYXh+PHjqFq1aoa2NSH2mKUzZ2dZLfP6tSwC0AZqRESUuUVFyZfyZ8/kGgDIhH1tb1jevBKAsTcsfTRt2hQTJ05E3rx5UaJECZw9exYzZ85Et27dAEiN0IEDB2LChAkoXLiwLl2Gt7c3mjdvrlq7GZilM+0igKAg/SIA/ickIsqcYmMlEHv6VF/uCJDPfTc3w8//Nwunk3HNmTMHI0eORO/evfHo0SN4e3ujR48eGDVqlG6fb7/9FpGRkfjqq68QGhqKGjVqYOfOnaomJ2ZglgGyZwfu3ZMFAC9fqlfw9n1q166NsmXLYtasWWo3hYjILEVGAnfv6h+7uEgNSnf3jAnE+Dmu5+zsjFmzZiX5u9BoNBg3bhzGjRuXcQ17D45iZwAbG30x8/Son9m0adN3FoL9+++/odFocF5bIyoNli9fDjc3tzSfh4jI3CmKrKi8eVPSImm5uMjNxwcoXRooUkRGSt4XlGXU57jWq1evkC1bNuTIkeOdecBIHQzMMoh2btmzZ9LVbUzdu3fHnj17cO/evbeeW7ZsGSpWrIjSpUsb90WJiCyMdhL/3bvAuXPAtWvymf7kieGk/iJFpEC4nV3yz53Rn+O//fYbSpQogWLFimHLli1GOy+lHQOzDOLkJCUy4uNl7oExNWnSBB4eHli+fLnB9oiICGzYsAHdu3fH06dP8fnnnyN37txwdHREqVKlsGbNGqO24+7du2jWrBmyZs0KFxcXtG7dGg8fPtQ9f+7cOdSpU0e31LlChQo4deoUAODOnTto2rQp3N3d4eTkhBIlSmD79u1GbR8RUWo9fCjpLS5dAh49ki/YNjZAzpxAwYJpP39Gf44vWbIEHTp0QIcOHbBkyZK3nv/333/RpEkTuLi4wNnZGTVr1sSNGzd0zy9duhQlSpSAvb09vLy80Ldv31S1g97GOWbvoygyMSyNNAA8HIF7z4And4CcycnanMy6GjY2NujUqROWL1+O4cOHQ/PfMRs2bEBcXBw+//xzREREoEKFCvjuu+/g4uKCbdu2oWPHjihYsCAqV66c5vcXHx+vC8oOHjyI2NhY9OnTB23atMFff/0FAGjfvj3KlSuH+fPnw9raGgEBAbC1tQUA9OnTB9HR0Th06BCcnJwQGBiIrFmzprldREQ6CWfjv8naWl9wEkBMaCRsbPQfwdHPgZhQwMYKcHW3gru3A1xc/ktrERkJvHmZSOFk4oz8HL9x4waOHTuGTZs2QVEUDBo0CHfu3EG+/5Jt3r9/Hx9++CFq166N/fv3w8XFBUeOHEHsf8M98+fPx+DBgzFlyhQ0bNgQL168wJEjR1L0fikJiooOHjyoNGnSRPHy8lIAKJs3b37vMa9fv1a+//57JW/evIqdnZ2SL18+ZcmSJcl+zaCgIAWAEhQU9NZzr169UgIDA5VXr17pN0ZEKIqEZxl/i4hI9vu6dOmSAkA5cOCAblvNmjWVDh06vPOYxo0bK0OGDNE9rlWrljJgwIB37r9s2TLF1dU10ed2796tWFtbK3fv3tVt+/fffxUAyokTJxRFURRnZ2dl+fLliR5fqlQpZcyYMe987bRI9O9KRJlSkv/fk/q8bdRIiY1VlCdPFOXqVUWJzeL47n1r1TI8b44cb++TChnxOa4oivL9998rzZs31z1u1qyZMnr0aN3jYcOGKb6+vkp0dHSix3t7eyvDhw9P+s2kUlJ/v6Su35mJqkOZkZGRKFOmDH766adkH9O6dWvs27cPS5YswZUrV7BmzRoULVo0HVtpHooVK4Zq1aph6dKlAIDr16/j77//Rvfu3QEAcXFxGD9+PEqVKoVs2bIha9as2LVrF+4mXD6UBpcuXYKPjw98fHx02/z8/ODm5oZLly4BAAYPHowvvvgC9erVw5QpUwy6xfv3748JEyagevXqGD16tFEnuRIRvc/LlzJv7NYtmdSvhoz4HI+Li8Mvv/yCDh066LZ16NABy5cv1yVeDQgIQM2aNXUjGgk9evQIDx48QN26ddPyVikJqg5lNmzYUFflPTl27tyJgwcP4ubNm8j23zLH/Pnzp1Pr/uPoaFi0LI1evgQuX5bu8ZIlpWxTkq+dAt27d0e/fv3w008/YdmyZShYsCBq1aoFAPjf//6HH3/8EbNmzUKpUqXg5OSEgQMHIjo6Og3vJmXGjBmDdu3aYdu2bdixYwdGjx6NtWvXokWLFvjiiy/g7++Pbdu2Yffu3Zg8eTJmzJiBfv36ZVj7iCiTe+OzPCoKuHJF5ospVtZQ4gF7e0lxFHPvEazflcrqzbT8t28brYnp/Tm+a9cu3L9/H23atDHYHhcXh3379qF+/fpwcHB45/FJPUfGYVaT/7du3YqKFSti2rRpyJ07N4oUKYKvv/4ar169eucxUVFRCAsL093Cw8NT9qIajcwVMNLN0cMJDjmcEJfFCU9evWf/FGaibd26NaysrLB69WqsWLEC3bp1081TOHLkCJo1a4YOHTqgTJkyKFCgAK5evZqy30USihcvjqCgIAQFBem2BQYGIjQ0FH5+frptRYoUwaBBg7B79260bNkSy5Yt0z3n4+ODnj17YtOmTRgyZAgWLVpktPYREb22dkJojP4z1s7dCZqsTrBydoKHTxYUKyZfmL29gSzZk/hsfjM4SWyfVErvz/ElS5agbdu2CAgIMLi1bdtWtwigdOnS+PvvvxGTsJDnf5ydnZE/f36DMkZkXGY1+f/mzZs4fPgwsmTJgs2bN+PJkyfo3bs3nj59anCBT2jy5MkYO3ZsBrc0aR4eMlf0yRMgVy7jVQLImjUr2rRpg2HDhiEsLAxdunTRPVe4cGFs3LgRR48ehbu7O2bOnImHDx8aBE3JERcXh4CAAINt9vb2qFevHkqVKoX27dtj1qxZiI2NRe/evVGrVi1UrFgRr169wjfffINPP/0Uvr6+uHfvHk6ePIlWrVoBAAYOHIiGDRuiSJEieP78OQ4cOIDixYun9VdCRBYuJkafif/lS5njX6aMvhRS4cKS1sJUalOm5+f448eP8ccff2Dr1q0oWbKkwXOdOnVCixYt8OzZM/Tt2xdz5sxB27ZtMWzYMLi6uuKff/5B5cqVUbRoUYwZMwY9e/ZEzpw50bBhQ4SHh+PIkSMc4TASE/mnmDzx8fHQaDRYtWoVKleujEaNGmHmzJn45Zdf3tlrNmzYMLx48UJ3CwwMzOBWv02bAToqCggLM+65u3fvjufPn8Pf3x/e3t667SNGjED58uXh7++P2rVrI1euXKmqBRYREYFy5coZ3Jo2bQqNRoPff/8d7u7u+PDDD1GvXj0UKFAA69atAyCFY58+fYpOnTqhSJEiaN26NRo2bKgLmuPi4tCnTx8UL14cDRo0QJEiRTBv3jyj/E6IyLLExwPPnwNXr8q8saAg/eL6rFkNc0lmyWI6QZlWen2Or1ixAk5OTonOD6tbty4cHBywcuVKZM+eHfv370dERARq1aqFChUqYNGiRbo5Z507d8asWbMwb948lChRAk2aNMG1a9fS/L5JaBRFmxZPXRqNBps3b07yH1nnzp1x5MgRXL9+Xbft0qVL8PPzw9WrV1G4cOH3vs69e/fg4+ODoKAg5MmTx+C5169f49atW/D19U33Oll370ouHDc3oFChdH0pi5eRf1ciUtfr169x9uwt2Nr6ApD/705OMm/M3f0983pJdUl9Xid1/c5MTOx7QtKqV6+OBw8eICLBBM6rV6/CysrK7P5I2koAoaFABs6/JyLKNOLjgcOHgT59gD179NudnGR40ttb5owVLy6JYBmUkTlQNTCLiIjQTTwEgFu3biEgIEC39HfYsGHo1KmTbv927dohe/bs6Nq1KwIDA3Ho0CF888036Natm9mtFHFwAJyd5f6TJ+q2hYjIXCgKcOoU8PXXQL58QM2awLx5QMLk9ba2MnfM29sgZyyRWVB18v+pU6dQp04d3ePBgwcDkCHL5cuXIzg42CA/S9asWbFnzx7069cPFStWRPbs2dG6dWtMmDAhw9tuDB4eQHi4FDb38jLeIgAioswmNhYYMwZYuxZIkAIRLi5A8+ZAgu/wAPh5SuZL1cCsdu3aSGqK25s1wwBJwLcnYZ+1GXNzk1prMTGS0NDNTe0WERGZjocPpRg4IJ+Vf/4pQZmjI9C0KdC2LdCgAXvFKHMxq3QZGSWj1kNYWQE5cgAhIfqFAGR8JrK+hYiS4c4dYN06uV26JMGZdtrH6NEyJ7dJk/enCuP/e/PEvxsDMwPapcAvX77MsDlrHh4SmIWFSfoMe/sMeVmLos2KbW1trXJLiCgxwcHAhg0yTHnsmH67tTVw8iTw0UfyuEWL959Ljc9xMh5+XjMwM2BtbQ03Nzc8evQIAODo6KjLuJyenJwk4WxwsCScJeOJj4/H48eP4ejoCBsb/nMnMjVr1gDt28ukfkDmhtWuLcOULVvKqEJKqPU5TmnHz2thue/8HXL9Fxlp/1NnhJcvZWXms2dyn58hxmVlZYW8efPyw5lIZS9eAFu2AHnyANocp9Wry8+qVSUY+/RTWU2ZFmp8jpNx8POagdlbNBoNvLy8kDNnzkTrhKWH2FigVy+ZZzZzJtCoUYa8rMWws7ODlaml9iayEJGRMml/7Vpg+3aZI9aokT4wy5sXuH9fVqYbixqf42Qc/LxmYPZO1tbWGTrG3agRMHYsMGeOdN8TEZmzrVtlmHLrVn05JECSvdaoYbivMYOyhDL6c5zIGCw7LDUhX3whqzT/+gu4fFnt1hARpUx8vOHj6dOll+zlS6BAAeD774Hz54F//wWGDVOnjUTmgIGZiciTR/LyAMDPP6vbFiKi5IiLAw4cAHr2BHLnlmTZWj17AkOGyKrK69eBiROBUqU4h5bofRiYmZCePeXn8uXAq1eqNoWIKFHx8cDRo8CAAfKF8qOP5MtkSIhM7Ndq1056zSpWZDBGlBKcY2ZCPv4YyJ8fuH0bWL8e6NxZ7RYREekdPw60bg0kqJQHd3egVSugTRtJc0FEacMeMxNiZQX06CH3589Xty1ERIGBEoxpFSwoKyizZgU6dJDVliEhwKJFQL16UjaJiNKGgZmJ6doVsLWVD8OzZ9VuDRFZGu18sNKlgRIlgK+/1j+XIwewf7+k9vn1V6BxY8DOTr22EmVGDMxMjKenPl0GFwEQUUYICgJmzAAqVQIKFwZGjAAuXJAvidmyAQlTgX34IcBKR0Tph4GZCerVS36uWgWEh6vbFiLK/Hr1kp6xU6ekPmX9+sCSJVJA/PffJUAjoozBwMwEffghUKwYEBEhwRkRkTHExwN79gCffy5zxbTatZPPnXnzgAcPgN27gW7dZGI/EWUsBmYmSKPRp85YsEBf3JeIKDWCgoBx42Ty/scfS+LXX37RP9+uHXDwoPSc5cypXjuJiIGZyerUCciSBTh3znBVFBFRcsTEABs3Ag0bAvnyAaNHSyoeV1egTx99QmsiMi0MzEyUuzvQtq3cX7BA3bYQkfl5+VK+4O3cKb3utWsDK1cCwcHA3LmShZ+ITA8DMxOmHc5ctw549kzdthCR6YqIkMn6X3yh3+bqCvTtKzUqr12T0knt23NFJZGpYzpAE1a5MlC2LBAQAKxYAQwcqHKDiMhkKArwzz8SkK1dC0RGyva+feVzAwCmTVOteUSUSuwxM2FcBEBEb3ryBJg5EyhZEqhWTQKzyEjJPzZ1qtSvJCLzxcDMxLVrJ+VPrlyRVVNEZNmOHAGGDJFySQ4OMo/s4EH5jPj2W8nOT0Tmi4GZiXN2lpp0ABcBEFma27dlNeWcOfptjRoBDRpIPd3gYEl78eGH0sNOROaPc8zMQM+eEpRt2iSZuD091W4REaWXqCjJtr94MbB3r0xhyJMH6N1bsvLb2gI7dqjdSiJKL+wxMwNlygAffCB5iZYtU7s1RJQe/v0XGDQIyJ0baNNGMvQrCvDRRzKJn3NMiSwDAzMzoV0E8PPPUlaFiDKX2bOBWbOAp08lOBsxArhxA9i3T0oo2XB8g8giMDAzE61bA25uMudk9261W0NEqaUoMoG/Wzfg5En99i++AFq0ALZtA+7cAcaPBwoUUK+dRKQOfgczEw4OQJcu8o16wQKZ/EtE5uPRI8lHuGQJcPmybLOxASpVkvuVKsk8UiKybOwxMyM9esjPP/4A7t1Tty1E9H7x8cD27UCrVjI8+c03EpQ5OsoXrW7d1G4hEZkaBmZmpFgxqXcXHy8rtojItCmKzA/dtAmIjZVqHgsXSpqLZctkUQ8RUUIMzMyMdhHAokXyQU9EpuH1a2DNGuCzz2QFNSDpLQYNknJqFy4Ax48DX34JuLio2lQiMmGcY2ZmWrQAPDyABw+AP/8EmjdXu0VElu3cOZk3tnIl8Py5bOvQAWjWTO4PGqRe24jSRXy8TJp88AC4fx+IiJClw1qTJgHff69e+8wcAzMzY2cHdO8OTJkiiwAYmBFlvLAwYPVqCchOndJv9/GReWMVKqjXNqI0CQuTgOvZMynGqvXdd1L768EDGYtPOGTj5AS0basvP8FJ0GnCwMwMffWVFCvetUvyHBUsqHaLiCzLrVtAr15y39ZWese++AKoV0+GL4lMTnQ08OQJ4O2t3/bTT8A//0ivV8LeL0BWqERE6IOty5dlLF5Lo5EyNLlzyzmjowF7e3muf/+MeU+ZFAMzM+TrK+kyduyQicRTp6rdIqLM7dIl4MwZoH17eVymDNCuHVCxogxbenio2z6yYIpiWCj199+Bs2f1gdaDB3J79OjtYGv3bmDr1rfP6eIiAderV3IMIGPyXbroA7Fcud6d9bhYMaO+RUujURTLKvRx7949+Pj4ICgoCHny5FG7Oam2dat8S8+RQ3qNtV9UiMh4Tp0CJk8GNm8GsmSRBM85c6rdKrI4p09Lj9X9+4a9Ww8eAKGhMrlRG2w1a5Z4sAXIXJjHj/WrTzZskH/U3t76gMvbG8iaNSPeVYplluv3+7DHzEw1aiSFje/dk6X4CeddElHqKYpMpZk0SepVajVoALx8qV67yMzExQGRkUB4uPRSRUYC5cvrn9+5EwgMlOe0+4SHAyEhMuR49qw+2Bo/XnrC3iU0FHB3l/sNGuiHGLXBlvZ+9uyGvWuffWb0t01px8DMTNnYyLL70aNlEQADM6K0u3hR5nAeOyaPra1lyPK774ASJdRtG6UjRQGioiQ4evVKVnFo/fWX9CpFRLwdRMXFAb/8ot+3a1eZYxIenngUHxcHWP2XpWrJEmDjxne3KWGwVbGinDNhz1bCn66u+uO0kx/JbDEwM2PduwPjxgGHDskXLz8/tVtEZN6yZ5dRI3t7WV35zTcyp5PMwMmTwMOHhoGT9qetrXSBanXvLtF3wv20qwxdXSUo0po4Edi7N/HXtLICli/X90KFh0sbErK2BpydZXjw9Wv9nK2aNWVoUfuc9mfOnBJsafcDpKL9iBFp+e2QGWFgZsZy5wY++UTmv/z8M/Djj2q3iMh8REUBv/4q88gWLJBtXl6SJLZqVblPJiQuDrh+Xbo1L1yQHqlp0/TP9+ljWBU+ITc3w8Dszh1Z0fGu10k4ob5yZRmiSBg8JfwZH69fijtlCjBqlOHz9vaGw4daXLlI78DJ/2Zu927A31++5D14YPgli4jeFhkplTOmT5f504AEZ8w9ZoKWLZOhxAsXJJB6/Vr/nIOD9FBpg6KuXSVoSyx4cnUFRo7UH3vypPSSvbmvk9O7VxqS6jLb9ftd+C/QmLZula/hGTihsl49oEAB4OZNYN06+Wwiorc9fy5pm2bNAp4+lW3e3sDXXwNFi6raNMv1/Lm+B+ziRfkg27FD38O0dSuwZYt+f0dHmexXsiRQqpTUvtIGZsuWJf91K1Uy2lsgMjYGZsayd68sU3ZwAIoUkURHGcDKCujRQyYnL1jAwIwoMSdPAnXrSgcLIEmZv/sO6NSJqWYy3JIlkqbh4kV9l2VC9+/LknNAVl5UqKAPxHx99ZPniTIpBmbGUqcO8PHHMrbYooVcCbJnz5CX7tpV5oWeOCFJMBOuyCayVFFR+qCrdGlJ3ZQvn5Tw++wzjlili9hYKUei7QHT/jx8WJ+F9/JlKVuilTevBF2lSkkAlrDCO9M5kAXiR5OxWFvLrOGKFaVey+efS5d8BtRn8fAAPv1UXv7nn+VGZKkuXZI52MePS0xgYyMB2uHDEgOww8UIFEVu2l/mr78CP/wgy8Ojot7e/99/gdq15f6nnwKFCkkgVqKEYaoHIgI/oowpWzaZD+HoKJkpv/8+w166Z0/5uWqV1KAlsjSnTgGtWsm1fsUK4MoVmTeulT8/g7JUef5ccvLMmyc5smrWlM+6Eyf0+7x8KQlRo6Lk869SJenKnzlTRhESduNXqSLzL6pVY1BGlAj2mBlb6dLA0qVA27aylLtCBaB163R/2Zo1geLFpbdg1SrmGCTLoCgSM0yaJNd/rRYtgGHDOMc7RV69kp8ODvJz82agX7/E54EB0h35wQdyv2FD2Z/zwIjSTNX/PYcOHULTpk3h7e0NjUaDLQlX37zHkSNHYGNjg7Jly6Zb+1KtTRvJTAnIt8bz59P9JTUafa/Z/PlywSLK7M6ckRGy3btl1kCnTjJqtmkTg7IkRUdLRDt2rHQzFi0q6SI2bdLv4+KiD8ry5QMaNwaGDgVWrgTOnQM6dtTvmzcv0Ly5rKpgUEaUJqr2mEVGRqJMmTLo1q0bWrZsmezjQkND0alTJ9StWxcP38yybComTwYCAmRIU7sYIFu2dH3Jjh3lc/PCBeCffyRJJlFmEhcnHTXaRc/ly8tqy6JF5btQ/vyqNs/0XbokHxL790serzddvaq/X6UKcPSojA0nnJBPROlK1cCsYcOGaNiwYYqP69mzJ9q1awdra+sU9bJlKO1igEqVJDdPu3bAtm3puhjA3V1GUJctk9QZDMwos9Bm6Z86FQgOlsTt2nrMu3ezkyZRYWESgLm4AB99JNucnSU3GCCrhurVk88o7YpIT0/98Vmz8kOESAVm93G2bNky3Lx5E6NHj07W/lFRUQgLC9PdwrWJjDJC9uwy78LBQZaHZ0CtM+1w5rp1wLNn6f5yROkqMlISwhYsCHz5pVTksbeXXjMtBmX/iYuTnvkJE/QT9Fu0kBIHWnnyyFyH06eBkBBg9Wpg0CAJ0HLlSrx0EJGZyp8/PzQazVu3Pn36AABev36NPn36IHv27MiaNStatWplEqNwZvWRdu3aNQwdOhQrV66ETTKTEE2ePBmurq66m19GV/ouU0YSKgKyhn/DhnR9uUqVgHLlpIfhl1/S9aWI0s2LFxJf5MsnccP9+5Klf+ZM6S2rVUvtFpoQRQG6dJHi15UrS+mhw4clUCtcWHrDEurZU8aAGdFSJnfy5EkEBwfrbnv27AEAfPZffrxBgwbhjz/+wIYNG3Dw4EE8ePAgRdOq0ovZ/M+Mi4tDu3btMHbsWBQpUiTZxw0bNgwvXrzQ3QIDA9Oxle/w+efAkCFyX1vPLZ0kXASwYAEXAZB5CgsDxo2T0kkFCwILF8qMgEGDZITNYr16Jb3vCYt3azTAvXvSRe7iIr1kCxbIL+zqVRn/JbJAHh4eyJUrl+72559/omDBgqhVqxZevHiBJUuWYObMmfjoo49QoUIFLFu2DEePHsU///yjbsMVEwFA2bx58zuff/78uQJAsba21t00Go1u2759+5L1OkFBQQoAJSgoyEgtT6aYGEWpW1fSMhYsqCjPnqXbS4WFKYqzs7zU/v3p9jJERnPrlqLMm2e4bcIERVm9Wv7rWKz4eEW5eFFRZsxQlI8/VpQsWbSpXRUlOFi/399/K8rhw4oSHa1eW4nSmfb6HRgYqLx48UJ3e/369XuPjYqKUrJnz65MnDhRURRF2bdvnwJAef78ucF+efPmVWbOnJkezU82s8lj5uLiggsXLhhsmzdvHvbv34+NGzfC19dXpZYlk40NsHatVAa4cUMWA/z5Z7osBnB2Bjp0kKkkCxZItSgiU6TN0r9qlYy8Va8uqQABYPhwddumusWLgTFj3s4jljs34O8PvH6t31ajRoY2jUhNb05JGj16NMaMGZPkMVu2bEFoaCi6dOkCAAgJCYGdnR3c3NwM9vP09ERISIgRW5tyqgZmERERuH79uu7xrVu3EBAQgGzZsiFv3rwYNmwY7t+/jxUrVsDKygolS5Y0OD5nzpzIkiXLW9tNVo4cUhmgWjVg505g1Chg4sR0eamePSUw27QJePjQcLEVkdpOnZKMMps364fb69VTt02qiYmR+lG7dgHt2wPFisn2LFkkKMuSRSbV+ftLPV4/P07SJ4sWGBiI3Llz6x7ba4viJmHJkiVo2LAhvL2907NpRqFqYHbq1CnUSdCdM3jwYABA586dsXz5cgQHB+Pu3btqNS99lC0r34Tbt5d05eXLS4JHIytdWuK/o0dl7UEGVocieqd794Bu3SS9n5ZFZum/eVMCsd27JaWFto6as7M+MGvUSJ6vUUOfjZ+I4OzsDJcU5Na7c+cO9u7di00JEijnypUL0dHRCA0NNeg1e/jwIXLlymXM5qacqgOpKlBtjtmbBg+WeSJOTjKHJB2sWCEvkS+fosTGpstLEKXIy5eK4umpKNbWitKxY7r90zddV64oSqFC+nli2lv27IrStq2i7NqldguJTFZqr9+jR49WcuXKpcQkmLAaGhqq2NraKhs3btRtu3z5sgJAOXbsmNHanBpmM8cs05k6VSoD7N8vpUxOngTeGOtOq08/BQYOlPQCu3bJF3CijKIowL59UsFn6VLJzuDgIIliCxWSkoqZVny8FPXetUsyP2uL1+bNK8OTNjbSpf3xxzJEyfQVROkiPj4ey5YtQ+fOnQ3SbLm6uqJ79+4YPHgwsmXLBhcXF/Tr1w9Vq1bFB9oasCphYKaWhIsBrl+Xoc2tW426GMDBQdIbzZwpiwAYmFFG0AZkY8YAR47ItsaNgf9SB6F+fdWalr4ePJAx2l275OeTJ7Ldz08fmGXJIr8cljkiyhB79+7F3bt30a1bt7ee++GHH2BlZYVWrVohKioK/v7+mDdvngqtNKRRFMvKdHXv3j34+PggKCgIefLkUbs5UoW5enVZYTViBDB+vFFPf+WKTFmxsgJu3ZIv7ETpQVGAvXslIDt6VLbZ28tClG+/lQSxmVbDhrKgJyFnZymF5O8vvwRO2CdKE5O7fqcT9piprXx5YNEiqUA+YYKk7Tdi5uGiReXasH+/rDkYN85opybSef4caNJEH5BlyQL06GHmAdmtW5La5vlzSd76/Ln+9vQpsH69vofb21sCr4oV9cOTH3wA2Nqq+x6IyOywx8xUDBokRQGzZpWl80YsHbVhA9C6NeDlJfPNeK0gY1MUqXd97py+h8zLS6XGxMcD4eH6gKpMGX0AtW2blCt6M9DS3i5d0ueW6d8fmDPn3a9z8qQEYgBw9y7g6CgpcYgoXZjs9dvI2GNmKqZNk8UAf/0liwFOnDDaYoBmzeRaExwM/PGHUTvkyAIpimRxmDVLpkm6ukpn0eLFQPbsRgrIFEUfXGlvCYOpAQMAOzvZd9o0+fahfS40VIIzrZAQfbC1a1fSwdbz5/p98+cHSpaUyfsJb9mySQCWII8S5wgQkbEwMDMVtrYyNFKhAnDtmqTu37rVKCu17OyA7t0lbdqCBQzMKHW0AdmYMYC2lNzs2VIzG5AYJknPnwOHDskwYGK9Vb//rg+2unQBVqx497k6dgS0uYbu3ZOMtW/KkkUCqchI/bY6deT/VMIgK2HQVaCAft/Bg+VGRJSBGJiZEg8PSYVeo4YMuYwdKzcj+PJLybS+Z48sAi1UyCinJQugKNLRNGaMjLIDEvP06iX/rpIt4SS0xCTsrXJ1lZ92dm8HT9myGX5h6d5dlnq+uV+WLG+/RosWciMiMlEMzExNhQrAwoVAp04yU79cORnaTKP8+WXh2Pbtcvpp09J8SrIAMTHSyaRNe6ENyL79Vt9hlShFkd6x8uVldSIAfPUV8PixfCt4M4hydwecnPTHT5woRTQdHN6/mrFMGbkREWUCnPxvqgYMkHEiZ2fppihePM2n/OMP4JNPZB7Q/fuSyoDofTp3llH2ZAVk0dGy8w8/SCqY2bOBfv3kubg46eli2ggiSgWzuX6nEVNNm6rp06VwcXi49Ji9eJHmUzZqBPj4yBSf335LexMpc1EUYMcOSUh/6ZJ++6RJkjli5swkgrJnz2Ss3NdX5n+dOSO9XaGh+n2srRmUERG9BwMzU6VdDJAnD3D1qlzsEq40SwVra/2coAULjNBGyhS0AdkHH0jwfuyYjCJq5c6dRECmKNIj5uMDfP+9ZL/PlUty8t29q18ZQEREycLAzJTlzCmLAeztZRzSCNlhu3eXAO3vv4F//zVCG8lsvRmQnTghnVxDhqRgDqJGI8HYy5dA2bLAL78At28Dw4czpxcRUSowMDN1FSvqu7fGjpUUGmng7S15zQDg55/T2DYya40bGwZkX38tQ5bTp+sXRxqIjpYK5BUrSkZ8rdGjpbTEmTOyaIWTF4mIUo2BmTno0gXo21fud+gAXL6cptP17Ck/V6wwTPFEmZuiyE2rRg3DgOx//3tHQPb0qUw0y59fAq/Tp4G5c/XPly4tSzc5f4yIKM0YmJmLmTOBmjVlMUCLFkBYWKpPVbcuULCgrCdYt86IbSSTpCiSFq9yZeDPP/Xb+/eXUcd3BmRXrshSTB8fGZoMDpa0/pMmASNGZFTziYgsCgMzc2FrK2VncueWHrNOnVK9GMDKSgpMA1wEkJklDMiaNJHk+P/7n/75rFllGmOioqKk+OWCBcCrV5JP79dfJZIbNkxyrhARkdExMDMnnp7Apk0yh+f332XlWyp16SJJ1U+elJEpyjwURXrGEgZkjo6Sg2zjxnccFBUlOVS0Y5329pIQ9pNPgAMH5B9Jhw76kklERJQuGJiZm8qVgfnz5f7o0YZjUyng4QF8+qnc5yKAzKVLF6BpU8OA7PZtYOrURHrInjyRAD9/fvkHsX+//rnJk+ULQO3anD9GRJRBGJiZo65dgd695X779jIXKBV69ZKfq1cbJX8tqURRpHSSVrNmUt3ou+/0AZmHxxsHXb4sq0B8fCTXWEiILNlNmBCWwRgRUYZjYGaufvhBltWFhUllgFQsBqheHShRQlZmrlpl/CZS+lIUSW9XsSLw44/67c2bS0A2ZUoiAdmzZ5Ino3hx6Sp9/VrqWa5cKUszW7XKwHdARERvYmBmruzsDBcDdO6c4sUAGo0+dcaCBYapFMh0KYqks6tYUaaAnTkDzJun//NbWb2R2zXhH9bNDbh5U/74zZoBBw/KmGf79pw/RkRkAhiYmbNcuWTCtp0dsGWLpDFIoY4dZR7ShQvA0aPGbyIZjzYgq1BBYqozZ2TIcuhQSRJr9eb/5sePgfHjgVKlZGUlIDstWiTD31u2AB9+yCFLIiITwsDM3FWpIt0lADBqlORHSAFXV+Dzz+U+U2eYtqFDJSA7e1ZSXQwbJkOWkye/0UN26ZLkQ8mbV/5N/PsvsHat/vkaNYDChTO6+URElAwMzDKD7t1lTFJRZEjq2rUUHa4dztywQRbpkWnq2BFwcZGA7NYt6SDVBWSKAuzZIzWW/PyAhQtl/liFCjKBsEMHVdtORETJw8Ass/jxR6BaNVle2by5VAhIpooV5fodFSU1qMk0/PmnTODXKllS6oUbBGRaN24AH38sVck1Gvk3cOiQJKpr104SFBMRkcljYJZZ2NlJ9lBvbyAwUJJZpWA2v7bX7OefU11QgIwkKgoYOFBykX3/PfD33/rnnJz+u/P4scwv1CpUCGjTBujXT3pMN2+WEl6cP0ZEZFYYmGUmXl5ysba1lQoBkycn+9C2bWWY7No1SfRO6rh2TSohadNfDBggOYV1AgOBL7+U/GNt2gBBQfrn1qwBZs+WQqhERGSWGJhlNh98APz0k9wfMQLYvj1Zh2XNKnOYAC4CUMvKlZJS7OxZKUX5xx+Srs7e7r/5Yw0bSuK5xYulW618ecNJgewdIyIyewzMMqMvv5RVeYoi84uuX0/WYdrC5lu2AMHB6dc8elufPhIYR0QAtWoB585JnUv8+68EYB9/DOzcKekuWrYEDh8Gjh+X4uJERJRpMDDLrH78UcbEtIsBIiLee0ipUlINIDYWWLo0/ZtIelWqSMw1diywb5/kDQYgw9M3bkiX5oABMtb522/yh2IPGRFRpsPALLOyt5cLuJeX9Lp07ZqsxQAJFwGkYGEnpZCiAPfu6R936gRcPB+PUX4bYd3jC/3fKls2mS94+zYwaxZQoIAazSUiogzCwCwz8/KSlZq2tvJz6tT3HvLpp1JQIChIyv28fJkB7bQwT58CLVrIdMAnTyDLYDdsQPG2ZYDPPgOWLAH279cfUK+eTDojIqJMj4FZZletGjBnjtz//nuZp5SELFlk0rmLC/DXXzKdKSoq/ZtpKf7+GyhbFvj9d+DJo3jc/t96oHRpoHVr4OJF+cWPGiXzyoiIyOIwMLMEPXrIggBFkfpLN24kuXvFirKY09ER2LVLsjLExGRQWzOpuDgpW1m7tgxhfpj/Lp77lELFaW1kqNnVFRg9WoYsx44F3N3VbjIREamAgZmlmDNHxs5CQ5O1GKB6dek5s7eX3p2OHSW4oJR78EBGI0eNklHLjh2BP8/mhoNNLODmJoHY7dvAmDEMyIiILBwDM0uhXQyQK5cMmXXr9t7FAB99JPPObW2BdeukJCerAqTcmJFx8P5rFfZb1cOvi15jxQrA2c1aipPevi0Rm5ub2s0kIiITwMDMknh76xcDbNgA/O9/7z2kUSNg7VrA2lrqaPbpk6JKT5YtNhZYuRLzD/lhFTqgTvw+dIhZpn++dGkZwiQiIvoPAzNLU726lO0BgGHDgN2733tIy5bAihWSNmvBAmDIEAZnSbl+ORa/NVsBxc8P6NgR1tevStqLiROB9u3Vbh4REZkwBmaWqEcP/bhk27bAzZvvPaRdO6kEBEiZoFGj0rmNZmrDkjDAzw+ttnaG5to1SXMxaZIMWX7/vay6JCIiegcGZpZIowHmzpXq2M+fy2KAyMj3HtatmxwGABMmSLxBABQFkZHy+2n9hQsuK0UQapMDoUOnALduSc+ks7ParSQiIjPAwMxSZckiM/s9PYELF6QHLRnjk3366KemDR8uyegtVkwMsHQpXhcqiUZl7mPZMol5rwxcgKyPb8Ft8ncMyIiIKEUYmFmy3LllEYCNjSy7nD49WYd9/bVkeACAQYOkfJNFiYmR7PxFiwLduyPLzUA0vvEjvL0lYf+QH/LAxi2r2q0kIiIzxMDM0tWsKQXPAWDoUGDPnmQdNnIk8N13cr9XL1kckOlFRwOLFgFFigBffAHcuoVo95z4WjMdx/1H49w5SSBLRESUWjZqN4BMQK9ewKlTwLJlshjg1CnA1zfJQzQaYPJk4NUrWeTZtauMjrZunUFtzmhxcUC5ckBgoDz29AS+/RZ2PXviswuOqFxZfidERERpwR4zkohi3jygUiXg2bNkLwbQaGSO2ZdfygLP9u2BrVvTvbUZJ2EdKmtrxPs3RETWXBhq/wMub78JDB4MODqiShUGZUREZByqBmaHDh1C06ZN4e3tDY1Ggy1btiS5/6ZNm1C/fn14eHjAxcUFVatWxa5duzKmsZldlixSGSBnTuD8eVliGBv73sM0GmD+fKBDB9n9s8+SlRrNtEVFyZsqWBA4cgQAEBwMND8zCh4RNzE1aiDW/O6ociOJiCgzUjUwi4yMRJkyZfDTTz8la/9Dhw6hfv362L59O06fPo06deqgadOmOHv2bDq31EL4+OgXA6xfn6yamoBUBVi2DGjVSqZhNW8OHDyY7q01vtevgZ9+AgoVAnr3BoKCgJ9+ws6dQJkywB8HXWDl6IDly6WsJRERkbFpFMU0crhrNBps3rwZzZs3T9FxJUqUQJs2bTAqmRlP7927Bx8fHwQFBSFPnjypaKkF2LRJxiVfvwbKlpVq5sn4XUVHS5WAbduArFllHcEHH6R/c9Ps9WvJnjtlCnD/vmzLnRuxXw/FyDtfYMqsLAAkOFu7FihWTMW2EhFZKFO7fufPnx/dunVDly5dkDdvXqOd16znmMXHxyM8PBzZsmVTuymZS8uWwF9/ybBmQABQpQqQjF5JOzspxVmvnnS0NWgAnDmT7q1Nu3r1gH79JCjLnVt6za5fx0K7vrqgrG9f4J9/GJQREZEYOHAgNm3ahAIFCqB+/fpYu3YtoqKi0nxesw7Mpk+fjoiICLROYilgVFQUwsLCdLfw8PAMbKEZq1IFOH4c8PMDHjyQtBp//vnew7JkAbZsAWrUAF68AD7+GLh4Mf2bmyKvXhlO7O/cWXoE580DbtyQYcwsWfDVV0DTpsDmzcCcOfLeiIiIAAnMAgICcOLECRQvXhz9+vWDl5cX+vbtizNp6ZVQTAQAZfPmzcnef9WqVYqjo6OyZ8+eJPcbPXq0AuCtW1BQUBpbbCGeP1eUunUVBVAUKytFmT07WYe9eKEolSvLYZ6einLlSvo2M1kiIxVl5kxFyZVLUZYs0W+PjlaU16+VyEhFGT9eUV6/Vq+JRESUuKCgIJO+fkdHRyuzZs1S7O3tFSsrK6VMmTLKkiVLlPj4+BSdxyx7zNauXYsvvvgC69evR7169ZLcd9iwYXjx4oXuFqjNQ0XJ4+YG7NihL3rev7/c4uKSPMzFBdi5U6aoPXwI1K0rZSNV8fIlMHMmUKCApLgICQFWrtQ/b2uLC1ftUamSJM4dNkyldhIRkdmJiYnB+vXr8cknn2DIkCGoWLEiFi9ejFatWuH7779H+/btU3Q+s0swu2bNGnTr1g1r165F48aN37u/vb097O3tdY/DwsLSs3mZk62tZLwvXFiqA8yZI1HWmjUyy/8d3N0ldUatWsClSxKcHTqUrHUExhEZCSxYAEybBjx6JNvy5ZMin507A5DyoAsXAgMHyhqAXLmAJk0yqH1ERGS2zpw5g2XLlmHNmjWwsrJCp06d8MMPP6BYgsnILVq0QKVKlVJ0XlUDs4iICFy/fl33+NatWwgICEC2bNmQN29eDBs2DPfv38eK/+r9rF69Gp07d8aPP/6IKlWqICQkBADg4OAAV1dXVd6DxdBopAZTwYJAx44y3+zDD2XFZu7c7zzMwwPYt092vX5dH5x5emZAm5s2BQ4ckPv580tA1qmTrFIAEBoqlZV++012adgQWL5c1jwQERElpVKlSqhfvz7mz5+P5s2bw9bW9q19fH190bZt25SdOJ2GWpPlwIEDic7/6ty5s6IoitK5c2elVq1auv1r1aqV5P7JYepj1Gbh2DFFyZlTJpDlzq0oZ8++95A7dxQlb145pGRJRXnyJP2bqZw5oyhFi8p8suhog6dOn1aUfPmkPTY2ijJ9uqLExWVAm4iIKFVM7fp9+/btdDmvyeQxyyimlgfFbN26BTRuLGOUTk7AunXyOAk3bsjizuBgoHx56UlzczNyu27elLlkWvHxgNXbUylv3pTSlzlySG6yFPY0ExFRBjO16/fJkycRHx+PKlWqGGw/fvw4rK2tUbFixVSd1ywn/5MJ8PUFjh6VscnISOCTT4C5c5M8pGBBCcY8PCS/WcOGgNGyl8TFycR+Pz9JOKaVICh7+VK/uUABYPt2Sc/GoIyIiFKqT58+CAoKemv7/fv30adPn1Sfl4EZpd6bKzb79QMGDEhyxWbx4sDevbIw4J9/JJ5LGDClSni41IH64Qepc3n8+Fu77N4tgWHCOp7Vq8vqUSIiopQKDAxE+fLl39perly5NGWAYGBGaaNdsTl5sjyePfu9NTZLl5YAycVFCgy0bCnxVKrcvSvZbP/8UzLArlsnweF/YmJkIam/v2TJmD49la9DRESUgL29PR4+fPjW9uDgYNjYpH5tJQMzSjuNRqKf9esBe3v9ik1t3clEVKwoQ4mOjsCuXUCbNobJ+JPl+HGgcmXg/HlZ5nnwIJCgCsTt2zKnbepUedy7N/D77yl/e0RERG/6+OOPdblStUJDQ/H999+jfv36qT4vAzMyns8+ky4wDw+ZvFWlitTafIfq1SXbhr29BEwdO743b61eQABQu7Zkry1dGjhxQoK0/1y/LgXUjx+XEdfffpMSmA4OqX97REREWtOnT0dQUBDy5cuHOnXqoE6dOvD19UVISAhmzJiR6vNyVSYZXwpXbG7fLqOfMTGS93Xp0kQXUhqKjwc+/RSIjQVWrQKcnXVPPX4sMdrt20CpUhL85ctnlHdGREQqMcXrd2RkJFatWoVz587BwcEBpUuXxueff55oTrPkYmBG6SM0FGjVCti/X6KsH38E+vZ95+6bNskoZFwc0LOn1BPXaN7Y6fVr+amtJv7qlSSLtbY22C0uTl5q717g8OEMSmZLRETpylKu32ZXkonMhHbFZq9e0gXWr5+ML86Y8VYgBcgCgBUrgA4dpIqSg4PsqgvOHj4EWrSQPBe//ipPvGNc0tpaArtnz4Ds2dPvLRIREQUGBuLu3buIjo422P7JJ5+k6nypCsyCgoKg0Wh0EeuJEyewevVq+Pn54auvvkpVQygTsrMDFi+WGpvDhkmv2c2bwOrVidbYbNdOOsW6d5fMF05OwPjxAC5elAKWd+7I8OitW4ZJZCHHzZoFDBkiC0U1GgZlRESUfm7evIkWLVrgwoUL0Gg00A5Aav7rUYhL9qRpQ6ma/N+uXTsc+K8GYUhICOrXr48TJ05g+PDhGDduXKoaQpmUdsXmunUyy/+PP2TF5oMHie7erZs+T+2ECcC6ztuBatUkKCtcWGbzvxGUxcYCbdtK7NepU3q/ISIiImDAgAHw9fXFo0eP4OjoiH///ReHDh1CxYoV8ddff6X6vKkKzC5evIjK/62AW79+PUqWLImjR49i1apVWL58eaobQ5lY69ZSUDzhis1z5xLdtU8f4H/TFPTHj/h0RVNJIFu7tmSkLVLEYN/4eOlh+/13ift69MiA90JERBbv2LFjGDduHHLkyAErKytYWVmhRo0amDx5Mvr375/q86YqMIuJiYG9vT0AYO/evbpx1GLFiiE4ODjVjaFMrmpVCa6KFQPu3ZPEsNu3J7rr10+H4UcMhDXisRjdsejTXUC2bAb7KAowaJDMTbO2BjZskPiNiIgIkPJIHTp0QPbs2eHg4IBSpUrh1KlTuucVRcGoUaPg5eUFBwcH1KtXD9euXUvWuePi4uD8X0aAHDly4MF/I0H58uXDlStXUt3mVAVmJUqUwIIFC/D3339jz549aNCgAQDgwYMHyM6JPZSUAgWkxuZHH0l1gKZNJcHYmxo0gGJvj211puNLLEKPfnZYscJwl7FjpdAAACxfLqciIiICgOfPn6N69eqwtbXFjh07EBgYiBkzZsDd3V23z7Rp0zB79mwsWLAAx48fh5OTE/z9/fFamwUgCSVLlsS5/0Z+qlSpgmnTpuHIkSMYN24cCrwx5SZFlFQ4cOCA4ubmplhZWSldu3bVbR82bJjSokWL1JwywwQFBSkAlKCgILWbYtmiohSlWzdFkY4vRRk4UFFevzbcJyhIiY9XlP79ZRcrK0VZt06emj1bf+jcuRnffCIiylgpvX5/9913So0aNd75fHx8vJIrVy7lf//7n25baGioYm9vr6xZs+a959+5c6fy22+/KYqiKNeuXVOKFi2qaDQaJUeOHMq+ffuS1cbEpDqPWVxcHMLCwgwiz9u3b8PR0RE5c+ZMfaSYziwlD4pZUBRgyhTg++/lsaOjlFWqWPGt3Xr0kJKcNjaSxd/JCWjWTNYVjBihQtuJiChDpfT67efnB39/f9y7dw8HDx5E7ty50bt3b3z55ZcAZFVlwYIFcfbsWZQtW1Z3XK1atVC2bFn8+OOPKW7js2fP4O7urluZmRqpGsp89eoVoqKidEHZnTt3MGvWLFy5csWkgzIyMRqNLKXs2VMev3wJ1K//1opNjQaYP19ynMXGSuWnuDjg33+B4cNVaDcREakmPDwcYWFhultUVFSi+928eRPz589H4cKFsWvXLvTq1Qv9+/fHL7/8AkCySgCA5xtZyD09PXXPvUtMTAxsbGxw8eJFg+3ZsmVLU1AGpDIwa9asGVb8N+EnNDQUVapUwYwZM9C8eXPMnz8/TQ0iCxIfL4HZggXy2M5OKgYksmLT2hro0kXituhoKeF0+3Yi1QGIiChT8/Pzg6urq+42efLkRPeLj49H+fLlMWnSJJQrVw5fffUVvvzySyzQXnPSwNbWFnnz5k11rrKkpCowO3PmDGrWrAkA2LhxIzw9PXHnzh2sWLECs7WzsYmSEhkpXV9TpsjjESOkCyzhis0dO3S7Hz8uQ5dnzgC1akk1piZNZJEnERFZjsDAQLx48UJ3GzZsWKL7eXl5wc/Pz2Bb8eLFcffuXQBArly5AAAPHz402Ofhw4e655IyfPhwfP/993j27Flq3sY7pSowe/nypW6J6O7du9GyZUtYWVnhgw8+wJ07d4zaQMqEHj+W6GrTJukl+/VXSfFfqJCs2KxTR1ZsNmkCzJuHixeBRo0klitXTnKW1asnuzRoIMEaERFZBmdnZ7i4uOhu2vRdb6pevfpbaSuuXr2KfPnyAQB8fX2RK1cu7Nu3T/d8WFgYjh8/jqpVq763HXPnzsWhQ4fg7e2NokWLonz58ga31EpVSaZChQphy5YtaNGiBXbt2oVBgwYBAB49egQXF5dUN4YshKsr4OwM5MgBbNkCVK+uf87dHdi5U+adLVuGm32m42On9ngW6YoqVYDNm6Wa05YtEpQdPgx8/DHw119AyZIqvR8iIjI5gwYNQrVq1TBp0iS0bt0aJ06cwMKFC7Fw4UIAUjpp4MCBmDBhAgoXLgxfX1+MHDkS3t7eaN68+XvPn5x9UiU1Szk3bNig2NraKlZWVkq9evV02ydNmqQ0aNAg1UtEMwLTZZiIp08V5ebNdz8fH688+G6WUgDXFUBRSjrfUp7ejTDY5cULRalcWVJmeHoqypUr6dxmIiJSTWqu33/88YdSsmRJxd7eXilWrJiycOFCg+fj4+OVkSNHKp6enoq9vb1St25d5YrKF5NUp8sICQlBcHAwypQpAysrGRE9ceIEXFxcUKxYMSOGjsbFdBkqUBRg2jTg4UNg5sxkHfLsmYx2XrwIFMBNHEZ1eJX3llqb3t66/Z4/l1y1AQFAnjzAoUOAr286vQ8iIlKNpVy/UzXHDJBJc+XKlcODBw9w7949AEDlypVNOigjFURHS2XyoUOBH36QscdksLIC3NwALy9g74bn8MoRK5PJqlQBzp/X7efuDuzeDRQvLmsG6taVn0REROnJysoK1tbW77ylVqrmmMXHx2PChAmYMWMGIiIiAMhkvCFDhmD48OG6HjSycE+eAK1aSTeWtTXw44+y2jIZ3NyAXbskpZlvoQpAuX+Axo2BK1dkTtqGDTLJDFIXfd8+4MMPgevXJTg7dAh4IzUNERGR0WzevNngcUxMDM6ePYtffvkFY8eOTfV5UzWUOWzYMCxZsgRjx45F9f8mbh8+fBhjxozBl19+iYkTJ6a6QenNUrpCVXf5sqyqvHEDcHEB1q8H/P2TPCQ2Fti2TdJiJOr5cwn0DhyQLrW5c4FevXRP370L1KwpP0uWlAUBLN1KRJQ5mMv1e/Xq1Vi3bh1+//331J0gNRPTvLy8lN9///2t7Vu2bFG8vb3TNOktvXHyfwbYs0dRXF1lVr6vr6L8++97D4mLU5QuXeSQsWOT2DEqSr8joCiDBytKbKzu6evXFcXLS54qX15Rnj9P87shIiITYC7X7xs3bihOTk6pPj5VY47Pnj1LdC5ZsWLFjJ5ojcxQeDjw4oUMOR4/DryR4O9NigJ8/TWwfLmMeJYuncTOdnbA0qWAtld25kzpRYuMBAAULCjDmh4eMiWtQQNZc0BERJTeXr16hdmzZyN37typPkeqArMyZcpg7ty5b22fO3cuSid5VSWL0KKFrJ7URkjvMXGirAsAgCVLpNxSkjQaKXy+di1gby8ZZ2vV0tXYLF4c2LtXFgYcPw6ULQvs35+md0RERGTA3d0d2bJl093c3d3h7OyMpUuX4n//+1+qz5uqOWYHDx5E48aNkTdvXl123GPHjiEoKAjbt2/XlWsyReYyRm1WwsKA/v2BceOAvHlTdOhPPwF9+8r9WbOAAQNS+NpHj8qktCdPAB8f4M8/dV1ugYFA69ZS6UmjAUaOBEaNkl45IiIyL6Z2/V6+fLlBwXIrKyt4eHigSpUqcHd3T/V5U53H7MGDB/jpp59w+fJlAFJ/6quvvsKECRN0WXVNkan9Yc3e7dtA06aScKxKFeDYsWRXFl+1CujQQe6PHg2MGZPKNty4oV+x6ewsCw3+W7H58qUEe4sXy661agGrVxukQiMiIjNgKdfvVAdmiTl37hzKly+fLtXWjcVS/rAZ4tgxGXd89AjIlQvYuhWoVCnZh8+eLUFT//7SW5bMeC5xz58DLVvKUkxra2DOHIMVm6tXAz16SH3NHDmkPOd/sRsREZkBU7t+L1u2DFmzZsVnn31msH3Dhg14+fIlOnfunKrzMuEYpc7q1VJs/NEjmcR14kSKgjJAArKDB2V+WZqCMkAmlO3aBXTpAsTFAb17A0OGyH0A7doBp09LU588ARo2lJy3MTFpfF0iIrJIkydPRo4cOd7anjNnTkyaNCnV52VgRimjKDLu2L49EBUFfPIJ8PffMr8rGS5cAEJD9Y8//FBSkhmFdsXmhAnyeOZMWYgQFAQAKFJEOvl695anp04FateWvGdEREQpcffuXfgmUgMwX758uJuGCwsDM0qZ169lxSUAfPMNsGkTkDVrsg69dEk62WrXlo62dKHRAMOHA2vWyIrNP/4ACheWtj57hixZZMHBhg2S9/boUelF27o1ndpDRESZUs6cOXE+QYlArXPnziF7GrKbp6gkU8uWLZN8PjRhVwhlTg4OEsUcOAB07Jjsw27fBurXB54+BQoUkNOkq7ZtpYts0CCpzzR9OrBokYxf9u+PTz91RPnystvJk7Kwc+BA6UWzs0vnthERkdn7/PPP0b9/fzg7O+PDDz8EIFkrBgwYgLZt26b6vCma/N+1a9dk7bds2bJUNyi9mdrkQbNw/rwUH9eOAaZQSIiUSrp+XXLNHjqUgaWSFAXYsUMCsgsXZJu3NzB2LNClC6LjbXT11QGgYkVg3ToJHomIyHSY2vU7OjoaHTt2xIYNG2BjI/1c8fHx6NSpExYsWAC7VH7LN+qqTHNgan9Yk7dtm3QrRURIT1nTpik6PDRUUlScPw/kzy/xXRoSIqdeXJwsWBg5ErhzR7YVKwZMmgQ0b46tf2jQpYss7nRxkUS3n36qQjuJiChRpnr9vnbtGgICAuDg4IBSpUohX758aTof55hR4hRFupE++USCso8+AmrUSNEpIiMlvdj584CnJ7Bnj0pBGSApNDp2lFxnP/wgXXaXL0uKjWrV8InbIQQEANWqSb7czz6TDsLXr1VqLxERmYXChQvjs88+Q5MmTdIclAEMzCgxMTFAz57A4MFAfDzw1VfAzp2SkiIFHj6UFY9ubsDu3UChQunT3BSxt5fJZDduACNGAI6OwD//ALVqIW+vxvhr9nkMHSq7zp8PfPABcPWqqi0mIiIT1KpVK0ydOvWt7dOmTXsrt1lKMDAjQ3FxMhN+4UJZ4ThzJrBgAWBrm+JTFSggQ5e7dr2nMLkaXF2B8eNl4luvXtKjtn07bCuVxeQHnXFg+R14eADnzgHly0uVAiIiIq1Dhw6hUaNGb21v2LAhDh06lOrzMjAjQ1u2yGR5R0cpDj5oUIqyvyqK1KbUypcPqFzZ+M00Gi8vYN48yeXRurW8gRUrUPurIrjZfDA+qfYEkZFSOuqLL6TEExERUURERKIT/G1tbREWFpbq8zIwI0MtWwLLlsk4Xgon+isK8N130sO0eXM6tS+9FC4syzFPnpT5dNHRyLroB2y5WBB760yEEyKxZIkUN0gYeBIRkWUqVaoU1q1b99b2tWvXws/PL9XnTVEeM7IAGo2UNUqFKVOA//1P7j97ZrwmZaiKFYG9e2WlwnffQRMQgLoHRuBptrkYFTsaMwO7o1IlW/z0k/ya0lxKioiIzNLIkSPRsmVL3LhxAx999BEAYN++fVi9ejU2btyY6vOyx4zEtm2SKyKV5s8Hvv9e7k+fDnTvbqR2qUGjAT7+WIprrl4N+PrC/lkIpob1wi3HEmj8agO6dVPQqRMQHq52Y4mISA1NmzbFli1bcP36dfTu3RtDhgzB/fv3sX//fhRKw2o3BmYEXLwoQ5glSwL376f48DVrgD595P7w4VI7PFOwsgI+/1zSasyZA3h4IM/La9iA1jiBKri/cj8qVpQFAkREZHkaN26MI0eOIDIyEjdv3kTr1q3x9ddfo0yZMqk+JwMzSxcTA3TuDERHy+Qwb+8UHb5tG9Cpk8wv691bFjpmOnZ2QN++kmJj9GjAyQmVcBL7URc/Xm2ALysFYMEC+R0QEZFlOXToEDp37gxvb2/MmDEDH330Ef75559Un4+BmaWbMgU4c0ZylGlTZKTA778DsbFAu3bSqZSp51w5OwNjxkiA1rcvFFtbNMAunIgpB+de7dGv8U28eKF2I4mIKL2FhIRgypQpuuSyLi4uiIqKwpYtWzBlyhRUqlQp1edWNTA7dOgQmjZtCm9vb2g0GmzZsuW9x/z1118oX7487O3tUahQISxfvjzd25lpBQQA48bJ/blzJXVECi1YAPz8M7B8uYz8WQRPT2DOHGguXYLy+ecAgPZYjZk7imFL3v4I2P1I5QYSEVF6adq0KYoWLYrz589j1qxZePDgAebMmWO086t6KY2MjESZMmXw008/JWv/W7duoXHjxqhTpw4CAgIwcOBAfPHFF9i1a1c6tzQTio6WIczYWKBFC5lLlUz370seWkCCsa++SlX+WfNXsCA0q1cDp08jtMrHsEMMOofNQUH/gvin4VgoYVwZQESU2ezYsQPdu3fH2LFj0bhxY1hbWxv1/KoGZg0bNsSECRPQokWLZO2/YMEC+Pr6YsaMGShevDj69u2LTz/9FD/88EM6tzQTmj5diljmyCHdXskcg7x7F6haVYYuo6PTuY3monx5uP2zC+Gb9+K6WwU4IwIf7ByDFx6FEDl1Ln9RRESZyOHDhxEeHo4KFSqgSpUqmDt3Lp48eWK085vV4NOxY8dQr149g23+/v44duzYO4+JiopCWFiY7hbO/AaiZ0+JrubNA3LmTNYhjx4B9esDQUES0/FXaci5eV0UfHICO7uuw3UUglv0IzgN7YfXvsWBtWul7igREZm1Dz74AIsWLUJwcDB69OiBtWvXwtvbG/Hx8dizZ0+a4wyzCsxCQkLg6elpsM3T0xNhYWF49epVosdMnjwZrq6uultasvFmKtmySQHIZBZaffECaNBACnrnzStFybNnT+c2miGNtRUaLG2NsH8CMdpjHkLgiSwPbgKffw6lYkVJXEtERGbPyckJ3bp1w+HDh3HhwgUMGTIEU6ZMQc6cOfHJJ5+k+rxmFZilxrBhw/DixQvdLTAwUO0mqSsgIMV5HV6+lOpMZ89K59qePYCPT/o0L7MoX8UWQ673wtBW1zEC4xEGZ2jOnpXEtfXqAadOqd1EIiIykqJFi2LatGm4d+8e1qxZk6ZzmVVglitXLjx8+NBg28OHD+Hi4gIHB4dEj7G3t4eLi4vu5uzsnBFNNU3//ANUqCDJZJM57yk6WjrV/v4bcHEBdu0CihRJ53ZmEi4uwLINWZFv4QiUsL+BHzAQ0bAF9u2Toptt2wLXr6vdTCIiMhJra2s0b94cW7duTfU5zCowq1q1Kvbt22ewbc+ePahatapKLTIjr15Jccf4eMnHZWeXrMPOnZM4wsFBksmWLZuurcx0NBrgyy+B7Sc9sLDYDyiKK1iJDlA0GimaXry4lE0ICVG7qUREZAJUDcwiIiIQEBCAgIAAAJIOIyAgAHfv3gUgw5CdOnXS7d+zZ0/cvHkT3377LS5fvox58+Zh/fr1GDRokBrNNy8jRgBXrkhm/x9/TPZhlSoBO3cCmzYBNWqkY/syuVKlZPSyVmdfdMSvKKucxfHsDSVdybx5QMGCwKhRQFiY2k0lIiIVqRqYnTp1CuXKlUO5cuUAAIMHD0a5cuUwatQoAEBwcLAuSAMAX19fbNu2DXv27EGZMmUwY8YMLF68GP7+/qq032z8/TegTSmyaJFk+X+PZ8/092vXlon/lDZOTpKId/ly4LpjGXzwdDtauB3Ai2KVZSLf+PESoP34IxAVpXZziYhIBRpFsawKf/fu3YOPjw+CgoKQJ08etZuT/iIjgTJlpIxQt27AkiXvPWTGDLnt3i11zcn4Ll8GWrcGLlwANFCwstVmfH5hGDRXr8oO+fNLoNaunQWVVCAiejdLuX7zEz+zGzpUgjIfH2DmzPfuHhIihwQHA3v3ZkD7LFSxYsDx41I1QYEG7X9riY9y/ovnU36W0li3bwMdO0ph+R07WCGdiMhCMDDL7Fq2BHx9pafM1fW9u69YIdOePvgAGDgw/ZtnyRwcpM7omjWyHuOvwzYo/L+vsHPudWDSJPl7nTsHNGok48kbN7KKABFRJsfALLOrU0fGzerXf++uiqIf6fzii3RuF+m0bQucOSOdY0+fAg1bOeKbZ8MQc/kGMGSIrKA9dEjyluTOLdssPR8fEVEmxcAss3r6VH8/makxjhyRzP5OTjL/iTJOoULA0aNAv37yePp0oGbz7Ljdd7rkOhs+XFbUPnkiQ9IlSgDVqwPLlsk8QiIiyhQYmGVGu3fL5PEFC1J0mLa3rE0bGVqjjGVvD8yeDfz2G+DmJnPQypUDtpz2ASZMAO7cAf74A2jWDLC2lkiuWzeZk9ajB3DiBOeiERGZOQZmmU1oKNC9OxARAVy6lOzDwsOB9evlfvfu6dM0Sp6WLaX8VeXK8uds0QLo3x8If2UDNGkCbNkileQnT5b0GuHhwMKFQJUqsgJ39mzDfCdERGQ2GJhlNoMHA/fuydjYpEnJPszJCdi+HfjmG4CFFNSXP7+kn/v6a3k8Zw5QuLAsFoiNhfSSDR0KXLsGHDgAdOgAZMki+TcGDJBhz3btgP37pdoDERGZBeYxy0z+/FOqjWs0clWvXl3tFpER7NghPWbasprFiwNTp0rnmUaTYMfnz4HVqyWJ8Llz+u0FCsiQZ5cusniAiMgMZerrdwLsMcssnj2TpFiA9JoxKMs0GjYE/v1XCgJkzy4j1J98IgtuT51KsKO7u9TdPHtWnujVSyqp37wpJbny5pXA/fffgZgY1d4PERG9GwOzzKJ/f8kKW7SoZIxPgXHjZPTr2rV0ahulmZ2dvtfs229locDBg1LLtH17yUero9EAFSpIDc7gYOCXX4CaNWVI888/gebNJUgbNox/dCIiE8PALDOIj5dJSXZ2chF2cEj2oVFRMld89mxJlUGmzc1NhjGvXJFpZYCMXhYrJgFbaOgbBzg6Ap06SR60y5dlEmHOnFLiYcoUoEgRSV67ciXw6lXGvhkiInoLA7PMwMpK0incvi0r81Jg61ZJeebtDbAWvPnIlw/49VcZsaxTRwLs//1PFmnOmvWOAgFFiwLTpsnikE2bpKKAlZV0vXXsKAsK+vYFAgIy+N0QEZEWAzNzFxenv+/lleLDtbnLunQBbGyM0yTKOBUqAPv2yQiln59MNRw0SBYIbNjwjrRmtraSg2PbNgnmx42TSO/FC+CnnyR5WsWKwPz5so2IiDIMAzNztn699JBdvJiqw+/elVy0gCzaI/Ok0QCNG8tCzJ9/Bjw9Zb5/69ZAtWpS0eGdfHyAkSPlgN27JbuwnR1w+jTQu7cE+507yypfy1rATUSkCgZm5urhQ7lwnj4tXSOpsGyZXGtr15YhMDJvNjayMPf6dWD0aJle9s8/QI0aQKtW75nnb2Ul9VTXrgXu3wd++EHKPr16JZXtP/xQJrL973/yb4+IiNIFAzNzpCiSCuHpU6BsWamjmELx8RKYAcz0n9lkzQqMGSOB2BdfSMy1aZMMdfbrBzx+/J4T5MgBDBwoyWqPHZOTODnJ6pBvvwXy5JHyBNu3Gw6lExFRmjEwM0erVwObN8tcoeXLk12kPKFXr2Soq0gR6U2hzMfbW59rtlEjqRgwd64UhZgyJRmLMDUa4IMP5CTBwcDixfI4Nlb+/TVuLKuBR416I18HERGlFjP/m5sHD4CSJSXL+/jxkjg0DRTljezxlGnt2yclnrSLLn18gIkTJQ+aVUq+ol28KKtGVqzQ1+TUaIB69aR3rVkzSbRGRGREZn/9Tib2mJkTRZFJRM+fy3K8oUPTfEoGZZajbl2ZkvjLLzIaGRQkKc4qVpSgLdlKlpQ5aA8eyJy0+vXl3+aePbJ4IHduWRqaykUpRESWjIGZOQkLk3ll2kSyqcxvsXMnsGsXpwdZIisrCcauXgUmT5aKTWfPSmdX48ZS+inZ7O0lENu9W1Z1jhwpQdnTp5JMrVQpoGpV6V2LiEivt0RElKkwMDMnrq7A4cOSxb1EiVSdQlGA774DGjQAli41cvvIbDg4SIfr9euSU9bGRubyly4tnbLBwSk8oa+v5EO7c0fyo7VsKSf95x8Z3vTykp9//SUv+vixZMUlIiIDnGNmYU6dkvqK9vZy8XV3V7tFZAquXpXSmZs2yWMnJ5mP9vXXssozVR4+lHloixe/u96XnZ1026Xm5uqqv+/gwHF5okzOUq7fDMzMweLFUhxx/HggS5Y0napXL2DBAuDzz2VxJ1FCR44AQ4YAx4/L41y5pCOsa9c0VIZQFOnpXbwY2L9fqgmEhxutzQAAa+u0B3cuLhKRpmglBBFlFLO8fqcCAzNTd/u2zNWJiJC0BV98kepTvXwpI0phYTLZ+6OPjNdMyjwUBdi4UYY6b96UbX5+UmazUSMjdUzFxcm/6bCwtN/i443QoP9oNICz8/sDumzZ9KWrHB2N9/pE9E5md/1OJVZHNGXx8VIrKSICqFkzzXWTfvtNrmO+vpLtnygxGg3w2WfAJ59Iuczx44HAQKBJEwnm//c/oHz5NL6ItbX0Vrm6pu08igJERqYtsHvxQn7Gxsr5tNuTw8ZGkjxXqya3qlUlDwmHVYkoldhjZsrmzpVU7Y6OkiW0UKE0na5WLVk3YIT0Z2RBnj+XFZw//ghER8u2Dh0kB1revOq2zWgUBXj9OvnBXHCwLGxIbJVE7twSoGkDtXLlmNeNyAjM6vqdBgzMTNX160CZMjL+OGeOLJ1Lg8hIqXd+6ZIsnDPlt06m6fZtqf6lnZtoby+Vm4YNS3vHl1lSFODuXeDoUSlddfSoZO99Mw+Nvb3kHdQGalWrypwCIkoRs7l+pxEDM1MUFydjjYcPA3XqAHv3GmVCsqIAly8DxYunvYlkuU6dktWaBw/K4+zZpWh6jx6pqg6WuURGyi9IG6gdOwY8efL2fvnzGw5/li6dhtUVRJbBLK7fRsDAzBRdvCgf2IoihaTz51e7RUQGFAX480+paX75smzT1uBs2ZJTrHQURXq/EwZqFy7I9oQcHYHKlQ171bJnV6fNRCbKLK7fRsDAzFTdvSsf4I0bp/lUQUGyiMzJyQjtIkogNlayYIweDTx6JNuqVQOmT5fYghIRFib5SLTB2j//yAKENxUpog/UqlWTpbFM5UEWzGyu32nE/+WmKm9eowRlgKwf8PKSFAhExmRjA/TsKZ1CI0dKntejRyWO+Owz2U5vcHGR+qKjRkl9tGfPpJd80SJJGFesmOx39SqwfLmMEZcqJdmg/f2BsWOlDFZiwRwR6YwZMwYajcbgVkz7/wvA69ev0adPH2TPnh1Zs2ZFq1at8PDhQxVbLNhjZkoWLpRhy48/NtopQ0Jkon9cnKQ84PwySk/370u8sWyZjNbZ2gK9e0vQxpG5FHj2THrStMOfx4/L/LWENBopzZawV61wYY4jU6aV0uv3mDFjsHHjRuzdu1e3zcbGBjly5AAA9OrVC9u2bcPy5cvh6uqKvn37wsrKCkeOHEm395AcDMxMxb//SnKo6GhJv16tmlFOO22a1MasWlU+44kywvnzMv9s1y557OoqKzr79Utz8QrLFBsrUxsSzlXTZv9NKHt2w1QdlSpxDgNlGqkJzLZs2YKAgIC3nnvx4gU8PDywevVqfPrppwCAy5cvo3jx4jh27Bg++OADYzc/2TiUaQpiYoDOnSUoa9zYaJNzFAVYskTud+9ulFMSJUvp0jJKt3u3ZH158UICtaJFZcROmw+NksnGRvKh9e4NrFwJ3Lgh3eGbNwPffAPUqCFpOZ4+lVUZ338vK7pdXSVVR79+kufk9u23Fx4QmZnw8HCEhYXpblFRUe/c99q1a/D29kaBAgXQvn173L17FwBw+vRpxMTEoF69erp9ixUrhrx58+LYsWPp/h6Swh4zUzBhgoz1uLvLXBNvb6Oc9u+/gQ8/lC/MwcFSaYYoo8XFSSwxfLgMdQIyhXLYMJlSxdyrRhIdLXnUjh7V37S/8IRy5dL3qH3wgUxA1Zaa4h+DTJj2+v2m0aNHY8yYMW9t37FjByIiIlC0aFEEBwdj7NixuH//Pi5evIg//vgDXbt2fSuoq1y5MurUqYOpU6em19t4LwZmajt3ToYbYmLk6tW+vdFO3aUL8MsvUslJ23NGpJaXL2Ua5dSp0tkDyPzHoUOlR5dDnOkgKMhw+PPMGRkWfRc7u+TVCn3fzcmJc93I6LTX78DAQOTOnVu33d7eHvbJ+FIRGhqKfPnyYebMmXBwcDDZwIwZDdUUHS1DmDExQPPmQLt2Rjv1q1f6VZgcxiRT4OgolQJ69JDhzKlTgXv3pKjFpEkSoH3xhazsJCPx8ZFb69by+NUr4PRpfaB2+rQsNNAuLIiOluHQp0/T9roajQRoaQ3ynJ2ZeJfe4uzsDBcXlxQf5+bmhiJFiuD69euoX78+oqOjERoaCjc3N90+Dx8+RK5cuYzY2pTjv3g1bdkiPWbZswMLFhj1G6aDg0zA3ryZ+aTItDg4AP37A199JT25U6ZIgNa/v9Tk/PZbec7RUe2WZkIODjIfrUYNw+1xcUBEROoLwYeH6wvCx8fLPLYXL4yT0sPRMXlBnpeXdMFqb1z0QG+IiIjAjRs30LFjR1SoUAG2trbYt28fWrVqBQC4cuUK7t69i6oqXzQ5lKm2DRtk+KBZM7VbQqSKqChJrzF5suRVBgBPT5nT3rMnr69mRVGkVy4twZ329vp12tri7m4YqOXJI72HCR9z4q1ZSen1++uvv0bTpk2RL18+PHjwAKNHj0ZAQAACAwPh4eGBXr16Yfv27Vi+fDlcXFzQr18/AMBRlVMYMDDLhBSF0zvI/ERHy5zISZNk8SAAeHhIXc7evYGsWVVtHmW06Oi3g7V33UJDZYXTvXsyry4iInmv4eLydrD25mMXF36gmoiUXr/btm2LQ4cO4enTp/Dw8ECNGjUwceJEFCxYEIAkmB0yZAjWrFmDqKgo+Pv7Y968eaoPZTIwU8OaNUDdukDOnOly+m+/Ba5ckRXzVaqky0sQpZuYGODXX4GJE/WpurJnB4YMkflo7OSg9woLkwDt3j3DW8JtyR1mzZr17WDtzQDOzY3BWwYwiet3BmBgltH++QeoXl2uNBcuyJiNEUVFAblz69MZGamqE1GGi4mR1FsTJuhLO2XLBgwaJGm5XF3VbR+ZufBwSSeSVAD3/HnyzuXomHhvW8Jt2bJlnuAtNlYuNtHRhj8T3reyMnrPgOrX7wzCwCwjvXolSSKvXAE6dJBuASNbvx5o00aCs9u3uaCJzF9sLLB2rQRoV67INjc3WeE5YIDcJ0oXkZESvL3Z25YwgEvuCtYsWd4fvOXIoQ/e4uKSDnzU3BYf//73mzu3/I6MyFICM162M9KIEXJl8fICZs9Ol5fQ5ivr0oVBGWUONjbyPebzz4F164Dx44HLl4ExY4CZMyU4GzhQOiSIjMrJCShSRG7v8uqVPnh7VwD36JEsZrh+Xd/9mxg7O/kHHxUlgZm5sLfX3+zs5KfK87TMGXvMMsrhw5KGX1GAbduARo2M/hJ37gC+vvISN24ABQoY/SWIVBcXJzn6xo+XErOAzDvr1w8YPJjF0skEvX4NPHjw7vlu9+7psy6/i52dPujR/kx4P7Ft73s+Ldu0921sMmyIlj1mZDyRkdKFpSiShj8dgjIAWL5cXqJOHQZllHlZW8tw/WefAZs2AePGyXTNSZOkI7pPH1ko4OGhdkuJ/pMli3woJ/XBHB0tK0vj498OiuzsMs/8NHovkyhi/tNPPyF//vzIkiULqlSpghMnTiS5/6xZs1C0aFE4ODjAx8cHgwYNwuu05rxJT1OmSBeWj4+MvaSD+HjJBQUw0z9ZBisr4NNPpTzkpk1A2bKSJWHqVCB/fsmD9uiRyo0kSi47OyBfPhn28PaW+WbOzhKcMSizKKoHZuvWrcPgwYMxevRonDlzBmXKlIG/vz8eveMTdfXq1Rg6dChGjx6NS5cuYcmSJVi3bh2+//77DG55CnzzjdSaWbIk3ZaSxcZKmoxatYCWLdPlJYhMkpUV0KKFlIH8/XegQgWpyzl9ugRoQ4a8f5SIiMhUqD7HrEqVKqhUqRLmzp0LAIiPj4ePjw/69euHoUOHvrV/3759cenSJezbt0+3bciQITh+/DgOHz783tezlDFqIkulKMD27cDYscDJk7ItSxap0fntt9IZQUTmx1Ku36r2mEVHR+P06dOoV6+ebpuVlRXq1auHY8eOJXpMtWrVcPr0ad1w582bN7F9+3Y0Sqd5W2ly6JBcJYgow2g0kr/v+HFgxw7ggw9k7vWPP8oUn379jL6Kn4jIaFQNzJ48eYK4uDh4vpFk1dPTEyHvGHto164dxo0bhxo1asDW1hYFCxZE7dq13zmUGRUVhbCwMN0tPDzc6O8jUbt3y7hiw4YyzpiONm4EFi6UZNdEJDQaoEED4OhR+e9YvbpkIZg7FyhYUMo8aWtzEhGZCtXnmKXUX3/9hUmTJmHevHk4c+YMNm3ahG3btmH8+PGJ7j958mS4urrqbn5+funfyBcv9DPwCxdO14RiiiJpA3r0AFasSLeXITJbGg1Qvz7w99/Avn2StSY6Gpg/HyhUSP7vaGtzEhGpTdXALEeOHLC2tsbDhw8Ntj98+PCdRURHjhyJjh074osvvkCpUqXQokULTJo0CZMnT0Z8ItmIhw0bhhcvXuhugYGB6fJeDAweLGMlBQvKisx0dPo0cP68LNxp3z5dX4rIrGk0wEcfAQcPAgcOSFqZmBjpbS5cWNbnaGtzEhGpRdXAzM7ODhUqVDCYyB8fH499+/ahatWqiR7z8uVLWFkZNtva2hoAkNg6Bnt7e7i4uOhuzuldAXnbNmDpUrkKLFsmmaPTkTbTf6tWgLt7ur4UUaZRuzawf79MA61XT2YbLFkiCd67dk06OTsRUXpSfShz8ODBWLRoEX755RdcunQJvXr1QmRkJLp27QoA6NSpE4YNG6bbv2nTppg/fz7Wrl2LW7duYc+ePRg5ciSaNm2qC9BU8/w58OWXcn/gQKBmzXR9uZcvpcgzwNxlRKlRsyawZw9w5Ajg7y9VBZYvB4oWBTp1Aq5eVbuFRGRpVM/836ZNGzx+/BijRo1CSEgIypYti507d+oWBNy9e9egh2zEiBHQaDQYMWIE7t+/Dw8PDzRt2hQTJ05U6y3oDRwomZuLFAEyoD2//SYT/n19pQeAiFKnWjVg507gn39kzub27cCvvwKrVgFt20qZ2+LF1W4lEVkC1fOYZbR0zYNy/Lh0XS1eLGv001nt2jJfZvx4uXAQkXGcPCmlnv78Ux5rNEDr1sDIkUCJEuq2jchSMY8ZpVyVKsC5cxkSlEVHA1mzAra2UoaTiIynUiXgjz9kcU2zZrL6ed06oGRJqdF54YLaLSSizIqBmbFl0Dw3Ozv5Nh8cDGTiLw5EqipfHtiyBTh7Vl/qbONGoHRpWeG5Zo0kryUiMhYGZmYue3a1W0CU+ZUtK3M6z5+XHjONRlJutGsH5M4NDBoE/Puv2q0kosyAgZkZunyZGcuJ1FCqFLB+PXDrFjBqlPRWP3sGzJolw5zVqkmWnMhItVtKROaKgZkZGjoUyJ8f+PlntVtCZJny5ZMi6bdvy5SCZs1kFsOxY0C3blIovVcvmaNGRJQSDMzMTEiIXAgUJd3TpBHRe1hbS8H0LVuAoCBg0iQplB4WBixYAFSsKPPU5s+XSm1ERO/DwMzMrFghSTA/+ADIiLKfRJQ8Xl7AsGHAtWtSk7NtW1mkc/asFEz39paqAkeOyBcrIqLEMDAzI4qiL8HETP9EpsnKSr9i8/59YOZMSU778qVUFahRQ+aj/fAD8OSJ2q0lIlPDwMyMHD4sJWKcnIA2bdRuDRG9T44c+hWbhw9LzkEHByAwEBg8WFZ0tm0rPWzx8Wq3lohMAQMzM6LtLWvdGkjvWuxEZDwaDVC9uqzYDA4G5s0DypWTRNHr1kkh9SJFgMmT5XkislwMzMxETIzU8gM4jElkzlxdZcXmmTOyarNnT/mideMG8P33gI8P0KIFsG2bzCclIsvCwMxM2NrKpOLVqyVXEhGZP+2KzeBgYOlSoGpVCca2bAGaNJG0OKNHA3fuqN1SIsooDMzMiLMz8PnnMixCRJmHk5Os2Dx6FLh4ERg4EMiWDbh3T4qp+/oCDRpI9YGYGLVbS0TpiYGZGYiK4vJ6IktRooSs2Lx/X3rIP/pI/v/v2gV8+qlUG/juO+lBJ6LMh4GZGRg6VGr1bd+udkuIKKNkySI95Pv2SRA2dCjg6Qk8egRMmyaLBWrXBlatYiF1osyEgZmJi4oCfv1Viiez14zIMhUqJCs2g4KATZuARo1kSsPBg0CHDpK8dsAAGQYlIvPGwMzEbd0KPH0qH7z+/mq3hojUZGurX7F55w4wZoys4nz+HJg9W4qsf/CBpNaJiFC7tUSUGgzMTJw2d1mXLoCNjapNISIT4uMjKzZv3QJ27ABatpTPiOPHgS++kBJRPXoAJ0+yt53InDAwM2F37gC7d8v9bt3UbQsRmSZra/2KzaAgYMoUGfqMiAAWLgQqV5Zktj/9BISGqt1aInofBmYmbPly+aZbpw5QsKDarSEiU5crl6zYvHoVOHAAaNcOsLcHzp0D+vaVKRGdOwN//81eNCJTxcDMRMXHS/kWgJn+iShlNBr9is0HD4BZsyQNx6tXwIoVwIcfAn5+wIwZssqTiEwHAzMTNm+efONt2VLtlhCRucqWTVZsXrgAHDsm0yIcHYHLl4Gvv5ZC6i1bAn/8AcTGqt1aItIoimV1aN+7dw8+Pj4ICgpCnjx51G4OEVGGCwsD1q4FFi0CTp3Sb8+VC+jUSaoQFCumXvuIEmMp12/2mBERWRgXF+Crr2TF5oULwODBgIcHEBIiyWuLF5eavIsWSRBHRBmHgZkJWrECGDYMuHlT7ZYQUWZXsqTMNbt3T5LXNm0qKz2PHZPgTduL9tdfMveViNIXAzMToyjyITllCkswEVHGsbOT5LVbt0qQNm2aDGe+eiXVR+rUAQoXBsaPB+7eVbu1RJkXAzMTc/q0lF+ytwfat1e7NURkiXLlAr75BggMlJ6zL78EnJ2lF3/UKCB/fuDjj2WeGut0EhkXAzMTo83037Il4O6ubluIyLJpNFLiaeFCmX+2YoX0nCkKsGePFFn38gL69JEvlZa1lIwofTAwMyEvXwKrV8t95i4jIlPi6Ah07Ajs3w/cuAGMHClloUJDJbVPxYpAmTKSM+3xY7VbS2S+GJiZkN9+kxVQvr7yrZSIyBQVKACMGyd1Onfvlp4ze3tZ4TlokORGa9UK+PNP5kYjSikGZiZEO4zZrRtgxb8MEZk4a2ugfn3p6Q8O1vecxcToV3j6+ABDhwJXrqjdWiLzwMu/iYiLk2Xr2bIBXbqo3RoiopRxdwd69ZLcaOfPS8+ZNjfa1KmywrN6dWDxYuZGI0oKAzMTYW0NzJ0rH2KZOKExEVmAUqWAmTP1udGaNJHPuKNHZYWnl5cUUz94kAsGiN7EwMzE2Nqq3QIiIuPQ5kb74w8gKEjfc/bypazwrF0bKFQImDBBniciBmYm4cwZ4PBhfnMkoszLywv49lvJjabtOdPmRhs5EsiXD/D3B9atY240smwMzEzAuHFAzZrApElqt4SIKH1pNEDVqpIbLThY33OmKLLCs21bwNsb6NtXvrTyCytZGgZmKgsJkSXlgHT5ExFZCicnyY124IBhbrTnz4GffgIqVADKlgV+/BF48kTt1hJlDAZmKluxQlZkfvAB4OendmuIiNTxZm60tm0lN9r588DAgdKL9umnwLZtzI1GmRsDMxUpij53GTP9ExHpc6OtWSNDndqes5gYScLdpAmQNy8wbBhw9ararSUyPgZmKjpyRD5YnJyANm3Ubg0RkWlxdwd69wZOnQLOnZOesxw5JGCbMgUoWhSoUUO+4L54oXZriYyDgZmKtL1lrVvL6iQiIkpc6dLADz8A9+/re86srOQL7hdfADlzAp98Avz6K4M0Mm8MzFQSHy/fAgEOYxIRJZedHdCypeRGu3dPcqMVLw5ER8u2Tp0kSGvalEEamScGZiqxspKu+UOHgGrV1G4NEZH5SZgb7eJFYPRoWUQVHS2r3RMGaStWAKGhareY6P00imJZWWLu3bsHHx8fBAUFIQ9rHxERZTr//gts2CC3wED9dltbSWL72Wcy7OnmploTKRUs5frNHjMVhIYCUVFqt4KIKHMqUQIYM0YCtH//lft+frKy888/pU5nzpwyT+2XX9iTRqaFgZkKxo6VQuW//KJ2S4iIMjc/PxniTBiklSghQdq2bUCXLgzSyLQwMMtgUVEyIfXJE1n2TUREGUMbpF28mHSQ1rgxgzRSj0kEZj/99BPy58+PLFmyoEqVKjhx4kSS+4eGhqJPnz7w8vKCvb09ihQpgu3bt2dQa9Nm61bg6VPJYu3vr3ZriIgsU8IgLTBQRjK0Qdr27YZB2vLlUiaKKCOoHpitW7cOgwcPxujRo3HmzBmUKVMG/v7+ePToUaL7R0dHo379+rh9+zY2btyIK1euYNGiRcidO3cGtzx1tLnLunQBbGxUbQoREUHSbYwaZRiklSypD9K6dgU8PRmkUcZQPTCbOXMmvvzyS3Tt2hV+fn5YsGABHB0dsXTp0kT3X7p0KZ49e4YtW7agevXqyJ8/P2rVqoUyZcpkcMtT7u5dqQEHAN26qdsWIiJ6mzZIu3Ah6SCtUSNg2TIGaeZkypQp0Gg0GDhwoG7b69ev0adPH2TPnh1Zs2ZFq1at8PDhQ/UaCZUDs+joaJw+fRr16tXTbbOyskK9evVw7NixRI/ZunUrqlatij59+sDT0xMlS5bEpEmTEBcXl+j+UVFRCAsL093Cw8PT5b0kx/LlUh+zTh2gYEHVmkFERMmQMEi7dEmKrGuDtB075At2zpwM0szByZMn8fPPP6N06dIG2wcNGoQ//vgDGzZswMGDB/HgwQO0bNlSpVYKVQOzJ0+eIC4uDp6engbbPT09ERISkugxN2/exMaNGxEXF4ft27dj5MiRmDFjBiZMmJDo/pMnT4arq6vu5ufnZ/T3kRyKIv9xAWb6JyIyN8WKASNHGgZppUoBsbGGQVrDhvJZ/+yZ2i0mrYiICLRv3x6LFi2Cu7u7bvuLFy+wZMkSzJw5Ex999BEqVKiAZcuW4ejRo/jnn39Ua6/qQ5kpFR8fj5w5c2LhwoWoUKEC2rRpg+HDh2PBggWJ7j9s2DC8ePFCdwtMmG0wA2k0kj/n22+lnAgREZknbZB2/jxw+TIwfrw+SNu5U4I0T08J0pYuZZCmtj59+qBx48YGo3MAcPr0acTExBhsL1asGPLmzfvOUbuMoOr08xw5csDa2vqt8dyHDx8iV65ciR7j5eUFW1tbWFtb67YVL14cISEhiI6Ohp2dncH+9vb2sLe31z0OCwsz4jtImRIlpK4bERFlDkWLAiNGyO3KFX3FgfPnJUjbuRPo0QOoV08qDjRvDmTLpnarzVt4eLjBtfzN63xCa9euxZkzZ3Dy5Mm3ngsJCYGdnR3c3igBkdSoXUZQtcfMzs4OFSpUwL59+3Tb4uPjsW/fPlStWjXRY6pXr47r168jPj5et+3q1avw8vJ6KygjIiLKKNog7dw5fU9a6dL6nrTu3aUnrUEDWaH/9KnaLTZPfn5+BlOUJk+enOh+QUFBGDBgAFatWoUsWbJkcCtTT/WhzMGDB2PRokX45ZdfcOnSJfTq1QuRkZHo2rUrAKBTp04YNmyYbv9evXrh2bNnGDBgAK5evYpt27Zh0qRJ6NOnj1pv4b1+/hn4/HPg+HG1W0JERBkhYZB25QowYYI+SNu1C/jiCyBXLgZpqREYGGgwRSlhjJDQ6dOn8ejRI5QvXx42NjawsbHBwYMHMXv2bNjY2MDT0xPR0dEIfSOTcFKjdhlB9Uxabdq0wePHjzFq1CiEhISgbNmy2Llzp25BwN27d2FlpY8ffXx8sGvXLgwaNAilS5dG7ty5MWDAAHz33XdqvYUkKQowb550a1evDlSponaLiIgoIxUpAgwfLrerV/XDnefOSZC2axfQsyfw0UdAq1ZA06aAl5farTZdzs7OcHFxee9+devWxYULFwy2de3aFcWKFcN3330HHx8f2NraYt++fWjVqhUA4MqVK7h79+47R+0ygkZRFEW1V1dBRlenP3UKqFQJsLcHgoOBBAtCiIjIgr0ZpCVUpQrQrJnciheXBWSWzhjX79q1a6Ns2bKYNWsWABmF2759O5YvXw4XFxf069cPAHD06FFjNTvFVB/KzOy0mf5btmRQRkREetqetIAAGe6cOBGoXFmeO34c+P57WTRWpAjw9dfA338D70jZSan0ww8/oEmTJmjVqhU+/PBD5MqVC5s2bVK1TewxS0cvX0p3dFgYsHcvULduur4cERFlAg8eAH/8Afz+O7BvHxAdrX8uRw6gSRPpSatfH3ByUq+dGS2jR7zUwh6zdPTbbxKU+fpKtn8iIqL38faWFBvbtwNPnshQZ4cOMury5IlUkWnRQoK0Tz6RkRmVqwiREak++T8zW7xYfnbtClgxBCYiohRydgY+/VRuMTHA4cPSk/b778Dt29Kz9scfMgetalXpSfvkE0mCS+aJ4UI6URRZWePnB3TponZriIjI3NnayujLrFnAzZuyYGDcOKBCBbnmHD0KfPedLBYoWlTuHz3KeWnmhnPMiIiIzNy9e8DWrdKTduCA9K5p5cwpHQXNmkkFAgcH9dqZFpZy/WaPGRERkZnLkwfo3Vtyoj1+DKxdK4nNXV2BR49kHtonnwDZs0tZqGXLZD8yPQzM0sHRo8DKlcCrV2q3hIiILI2rK9CmDbB6tQRle/YAffsCPj5yXfr9dym0nisXULMmMH06cO2a2q0mLQZm6WDaNKBjR2DMGLVbQkRElszOToYv58wB7twBzpwBRo8GypYF4uNlMcE330iuND8/YNgw4J9/5DlSB+eYGVlIiHQpx8UB//4r/9CJiIhMzZ07+nlpBw9KHU+tXLn089Lq1gVMoQY455hRqqxYIUHZBx8wKCMiItOVLx/Qr58kQH/8GFi1CmjdWlJ0hIQAixZJMtscOaSG54oVLLaeERiYGZGi6Eswde+ubluIiIiSy80NaNcOWLdOgrSdO4FevYDcuYHISGDTJqBzZ8DTE6hdG/jhB0nZQcbHoUwjOnxYJlI6OUnBcmdno56eiIgoQykKcPq0PqnthQuGz5csqS+2XqFC+iZT51AmpZi2t6xNGwZlRERk/jQaoGJFYPx44Px56SX74QfpNbO2Bi5e1Bdf9/GRXradO4GoKLVbbr4YmBmJouhzwnAYk4iIMiNfX2DgQEli++iRzDv79FMga1Ypvr5gAdCwoQx5RkSo3VrzxFqZRqLRAH/+Kd8mfH3Vbg0REVH6ypZNUkN17Ai8fi3B2u+/y0pPX18J1ijlGJgZWYECareAiIgoY2XJIj1lDRsC8+YBT56o3SLzxaFMIiIiMhorK6nPSanDwIyIiIjIRDAwIyIiIjIRDMyIiIiITAQDMyIiIiITwcCMiIiIyEQwMCMiIiIyEQzMiIiIiEwEAzMiIiIiE8HAjIiIiMhEMDAjIiIiMhEMzIiIiIhMBAMzIiIiIhPBwIyIiIjIRNio3YCMFh8fDwAIDg5WuSVERESUXNrrtvY6nllZXGD28OFDAEDlypVVbgkRERGl1MOHD5E3b161m5FuNIqiKGo3IiPFxsbi7Nmz8PT0hJUVR3ITEx4eDj8/PwQGBsLZ2Vnt5lg8/j1MC/8epod/E9OSXn+P+Ph4PHz4EOXKlYONTebtV7K4wIzeLywsDK6urnjx4gVcXFzUbo7F49/DtPDvYXr4NzEt/HukDbuMiIiIiEwEAzMiIiIiE8HAjN5ib2+P0aNHw97eXu2mEPj3MDX8e5ge/k1MC/8eacM5ZkREREQmgj1mRERERCaCgRkRERGRiWBgRkRERGQiGJgRERERmQgGZqQzefJkVKpUCc7OzsiZMyeaN2+OK1euqN0s+s+UKVOg0WgwcOBAtZtise7fv48OHToge/bscHBwQKlSpXDq1Cm1m2WR4uLiMHLkSPj6+sLBwQEFCxbE+PHjwfVsGefQoUNo2rQpvL29odFosGXLFoPnFUXBqFGj4OXlBQcHB9SrVw/Xrl1Tp7FmhIEZ6Rw8eBB9+vTBP//8gz179iAmJgYff/wxIiMj1W6axTt58iR+/vlnlC5dWu2mWKznz5+jevXqsLW1xY4dOxAYGIgZM2bA3d1d7aZZpKlTp2L+/PmYO3cuLl26hKlTp2LatGmYM2eO2k2zGJGRkShTpgx++umnRJ+fNm0aZs+ejQULFuD48eNwcnKCv78/Xr9+ncEtNS9Ml0Hv9PjxY+TMmRMHDx7Ehx9+qHZzLFZERATKly+PefPmYcKECShbtixmzZqldrMsztChQ3HkyBH8/fffajeFADRp0gSenp5YsmSJblurVq3g4OCAlStXqtgyy6TRaLB582Y0b94cgPSWeXt7Y8iQIfj6668BAC9evICnpyeWL1+Otm3bqtha08YeM3qnFy9eAACyZcumckssW58+fdC4cWPUq1dP7aZYtK1bt6JixYr47LPPkDNnTpQrVw6LFi1Su1kWq1q1ati3bx+uXr0KADh37hwOHz6Mhg0bqtwyAoBbt24hJCTE4HPL1dUVVapUwbFjx1RsmenLvOXZKU3i4+MxcOBAVK9eHSVLllS7ORZr7dq1OHPmDE6ePKl2UyzezZs3MX/+fAwePBjff/89Tp48if79+8POzg6dO3dWu3kWZ+jQoQgLC0OxYsVgbW2NuLg4TJw4Ee3bt1e7aQQgJCQEAODp6Wmw3dPTU/ccJY6BGSWqT58+uHjxIg4fPqx2UyxWUFAQBgwYgD179iBLlixqN8fixcfHo2LFipg0aRIAoFy5crh48SIWLFjAwEwF69evx6pVq7B69WqUKFECAQEBGDhwILy9vfn3ILPGoUx6S9++ffHnn3/iwIEDyJMnj9rNsVinT5/Go0ePUL58edjY2MDGxgYHDx7E7NmzYWNjg7i4OLWbaFG8vLzg5+dnsK148eK4e/euSi2ybN988w2GDh2Ktm3bolSpUujYsSMGDRqEyZMnq900ApArVy4AwMOHDw22P3z4UPccJY6BGekoioK+ffti8+bN2L9/P3x9fdVukkWrW7cuLly4gICAAN2tYsWKaN++PQICAmBtba12Ey1K9erV30ofc/XqVeTLl0+lFlm2ly9fwsrK8BJmbW2N+Ph4lVpECfn6+iJXrlzYt2+fbltYWBiOHz+OqlWrqtgy08ehTNLp06cPVq9ejd9//x3Ozs66eQCurq5wcHBQuXWWx9nZ+a35fU5OTsiePTvn/alg0KBBqFatGiZNmoTWrVvjxIkTWLhwIRYuXKh20yxS06ZNMXHiROTNmxclSpTA2bNnMXPmTHTr1k3tplmMiIgIXL9+Xff41q1bCAgIQLZs2ZA3b14MHDgQEyZMQOHCheHr64uRI0fC29tbt3KT3kEh+g+ARG/Lli1Tu2n0n1q1aikDBgxQuxkW648//lBKliyp2NvbK8WKFVMWLlyodpMsVlhYmDJgwAAlb968SpYsWZQCBQoow4cPV6KiotRumsU4cOBAoteMzp07K4qiKPHx8crIkSMVT09Pxd7eXqlbt65y5coVdRttBpjHjIiIiMhEcI4ZERERkYlgYEZERERkIhiYEREREZkIBmZEREREJoKBGREREZGJYGBGREREZCIYmBERERGZCAZmREQANBoNtmzZonYziMjCMTAjItV16dIFGo3mrVuDBg3UbhoRUYZirUwiMgkNGjTAsmXLDLbZ29ur1BoiInWwx4yITIK9vT1y5cplcHN3dwcgw4zz589Hw4YN4eDggAIFCmDjxo0Gx1+4cAEfffQRHBwckD17dnz11VeIiIgw2Gfp0qUoUaIE7O3t4eXlhb59+xo8/+TJE7Ro0QKOjo4oXLgwtm7dmr5vmojoDQzMiMgsjBw5Eq1atcK5c+fQvn17tG3bFpcuXQIAREZGwt/fH+7u7jh58iQ2bNiAvXv3GgRe8+fPR58+ffDVV1/hwoUL2Lp1KwoVKmTwGmPHjkXr1q1x/vx5NGrUCO3bt8ezZ88y9H0SkYVTu4o6EVHnzp0Va2trxcnJyeA2ceJERVEUBYDSs2dPg2OqVKmi9OrVS1EURVm4cKHi7u6uRERE6J7ftm2bYmVlpYSEhCiKoije3t7K8OHD39kGAMqIESN0jyMiIhQAyo4dO4z2PomI3odzzIjIJNSpUwfz58832JYtWzbd/apVqxo8V7VqVQQEBAD4f/v272psGMdx/HOfGLhjEtlsYmBhYjPZFJtklZLFzl/AX2AUZbAyGJVsJvwDEqMUC2d4Suk86Zyn5zjX0/N+TdePu7vvtX267u8trVYrxeNx2bZ930+lUrper9psNrIsS9vtVplM5mkNsVjsPrZtW16vV/v9/k+PBABfRjADYATbtj98WvxbXC7Xp55zOp0Pc8uydL1ev6MkAPgteswA/BPm8/mHeSQSkSRFIhEtl0udTqf7/mw209vbm8LhsDwej0KhkKbT6UtrBoCv4sYMgBEul4t2u93DmsPhkM/nkyQNh0MlEgml02n1ej0tFgt1u11JUrFYVLPZVLlcVqvV0uFwUK1WU6lUUiAQkCS1Wi1VKhX5/X5ls1kdj0fNZjPVarXXHhQAniCYATDCeDxWMBh8WAuHw1qv15J+/TE5GAxUrVYVDAbV7/cVjUYlSW63W5PJRPV6XclkUm63W/l8Xu12+/6ucrms8/msTqejRqMhn8+nQqHwugMCwCdYt9vt9tNFAMAzlmVpNBopl8v9dCkA8K3oMQMAADAEwQwAAMAQ9JgBMB4dFwD+F9yYAQAAGIJgBgAAYAiCGQAAgCEIZgAAAIYgmAEAABiCYAYAAGAIghkAAIAhCGYAAACGIJgBAAAY4h3LqlWWvLqmswAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Get the best config from the hyperband search\n",
    "best_config = analysis.get_best_config(metric=\"val_loss\", mode=\"min\")\n",
    "\n",
    "logger.info(f\"Best config: {best_config}\")\n",
    "\n",
    "# Instantiate the model with the best hyperparameters\n",
    "best_model = SimpleCNN(\n",
    "    input_size=best_config[\"input_size\"],\n",
    "    hidden_size=best_config[\"hidden_size\"],\n",
    "    output_size=best_config[\"output_size\"],\n",
    "    dropout=best_config[\"dropout\"],\n",
    "    num_conv_layers=best_config[\"num_conv_layers\"],\n",
    "    filters=best_config[\"filters\"],\n",
    "    kernel_size=best_config[\"kernel_size\"],\n",
    "    stride=best_config[\"stride\"],\n",
    "    padding=best_config[\"padding\"],\n",
    "    num_fully_connected_layers=best_config[\"num_fully_connected_layers\"]\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "device = best_config[\"device\"]\n",
    "best_model.to(device)\n",
    "\n",
    "# Optionally, you can load weights from a checkpoint if available:\n",
    "checkpoint_path = analysis.get_best_checkpoint(trial=analysis.get_best_trial(metric=\"val_loss\", mode=\"min\"))\n",
    "if checkpoint_path:\n",
    "    best_model.load_state_dict(torch.load(checkpoint_path)[\"model_state_dict\"])\n",
    "\n",
    "# Now you can further train the model using your existing train_and_evaluate function:\n",
    "# Example:\n",
    "train_and_evaluate(best_model, best_config, logger)\n",
    "best_model.plot_learning_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fae3fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, config, logger):\n",
    "    train_loader, test_loader = get_data_loaders_transforms(config[\"batch_size\"], config[\"data_dir\"])\n",
    "    device = config[\"device\"]\n",
    "    model.to(device)\n",
    "    optimizer = config[\"optimizer\"](model.parameters(), lr=config[\"learning_rate\"])\n",
    "    loss_fn = config[\"loss_fn\"]\n",
    "    num_epochs = config[\"epochs\"]\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "        val_loss, val_accuracy = evaluate(model, test_loader, loss_fn, device)\n",
    "\n",
    "        model.train_losses.append(train_loss)\n",
    "        model.val_losses.append(val_loss)\n",
    "        model.train_accuracies.append(train_accuracy)\n",
    "        model.val_accuracies.append(val_accuracy)\n",
    "\n",
    "        logger.info(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {val_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Test Acc: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    return model.train_losses[-1], model.val_losses[-1], model.val_accuracies[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610a491d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-10-19 16:51:10</td></tr>\n",
       "<tr><td>Running for: </td><td>00:03:53.68        </td></tr>\n",
       "<tr><td>Memory:      </td><td>28.1/31.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 6.000: None | Iter 3.000: None<br>Logical resource usage: 20.0/20 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  filters</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">  kernel_size</th><th style=\"text-align: right;\">  num_conv_layers</th><th style=\"text-align: right;\">  padding</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  train_accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00018</td><td>RUNNING </td><td>10.82.72.122:1864818</td><td style=\"text-align: right;\">      143</td><td style=\"text-align: right;\">          445</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         681.14 </td><td style=\"text-align: right;\">     1.7059 </td><td style=\"text-align: right;\">   1.40326</td><td style=\"text-align: right;\">          36.69 </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00013</td><td>RUNNING </td><td>10.82.72.122:1864819</td><td style=\"text-align: right;\">      160</td><td style=\"text-align: right;\">          382</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         664.678</td><td style=\"text-align: right;\">     1.671  </td><td style=\"text-align: right;\">   1.33049</td><td style=\"text-align: right;\">          38.112</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00010</td><td>RUNNING </td><td>10.82.72.122:1864830</td><td style=\"text-align: right;\">      147</td><td style=\"text-align: right;\">          353</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         653.708</td><td style=\"text-align: right;\">     1.65169</td><td style=\"text-align: right;\">   1.2974 </td><td style=\"text-align: right;\">          38.63 </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00002</td><td>RUNNING </td><td>10.82.72.122:1864831</td><td style=\"text-align: right;\">      147</td><td style=\"text-align: right;\">          503</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         625.987</td><td style=\"text-align: right;\">     1.6873 </td><td style=\"text-align: right;\">   1.37118</td><td style=\"text-align: right;\">          37.396</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00016</td><td>RUNNING </td><td>10.82.72.122:1864793</td><td style=\"text-align: right;\">      139</td><td style=\"text-align: right;\">          421</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         608.2  </td><td style=\"text-align: right;\">     1.63993</td><td style=\"text-align: right;\">   1.26658</td><td style=\"text-align: right;\">          39.434</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00011</td><td>RUNNING </td><td>10.82.72.122:1864850</td><td style=\"text-align: right;\">      144</td><td style=\"text-align: right;\">          323</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         578.023</td><td style=\"text-align: right;\">     1.67529</td><td style=\"text-align: right;\">   1.33638</td><td style=\"text-align: right;\">          37.978</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00015</td><td>RUNNING </td><td>10.82.72.122:1864867</td><td style=\"text-align: right;\">      135</td><td style=\"text-align: right;\">          484</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         577.514</td><td style=\"text-align: right;\">     1.68338</td><td style=\"text-align: right;\">   1.3314 </td><td style=\"text-align: right;\">          37.976</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00004</td><td>RUNNING </td><td>10.82.72.122:1864832</td><td style=\"text-align: right;\">      126</td><td style=\"text-align: right;\">          392</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         492.688</td><td style=\"text-align: right;\">     1.72805</td><td style=\"text-align: right;\">   1.353  </td><td style=\"text-align: right;\">          36.006</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00017</td><td>RUNNING </td><td>10.82.72.122:1864890</td><td style=\"text-align: right;\">      132</td><td style=\"text-align: right;\">          330</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         476.203</td><td style=\"text-align: right;\">     1.7197 </td><td style=\"text-align: right;\">   1.4176 </td><td style=\"text-align: right;\">          35.954</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00007</td><td>RUNNING </td><td>10.82.72.122:1864856</td><td style=\"text-align: right;\">      133</td><td style=\"text-align: right;\">          330</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         474.738</td><td style=\"text-align: right;\">     1.6899 </td><td style=\"text-align: right;\">   1.30172</td><td style=\"text-align: right;\">          37.482</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00001</td><td>RUNNING </td><td>10.82.72.122:1864873</td><td style=\"text-align: right;\">      111</td><td style=\"text-align: right;\">          380</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         445.306</td><td style=\"text-align: right;\">     1.72616</td><td style=\"text-align: right;\">   1.39039</td><td style=\"text-align: right;\">          36.146</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00019</td><td>RUNNING </td><td>10.82.72.122:1864844</td><td style=\"text-align: right;\">      122</td><td style=\"text-align: right;\">          351</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         423.121</td><td style=\"text-align: right;\">     1.67497</td><td style=\"text-align: right;\">   1.29154</td><td style=\"text-align: right;\">          37.768</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00014</td><td>RUNNING </td><td>10.82.72.122:1864770</td><td style=\"text-align: right;\">      100</td><td style=\"text-align: right;\">          474</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         368.509</td><td style=\"text-align: right;\">     1.69742</td><td style=\"text-align: right;\">   1.39074</td><td style=\"text-align: right;\">          36.892</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00008</td><td>RUNNING </td><td>10.82.72.122:1859999</td><td style=\"text-align: right;\">      146</td><td style=\"text-align: right;\">          415</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         725.352</td><td style=\"text-align: right;\">     1.65467</td><td style=\"text-align: right;\">   1.39178</td><td style=\"text-align: right;\">          38.708</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00000</td><td>RUNNING </td><td>10.82.72.122:1860012</td><td style=\"text-align: right;\">      159</td><td style=\"text-align: right;\">          327</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         682.026</td><td style=\"text-align: right;\">     1.65312</td><td style=\"text-align: right;\">   1.40164</td><td style=\"text-align: right;\">          38.922</td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00006</td><td>RUNNING </td><td>10.82.72.122:1869798</td><td style=\"text-align: right;\">      170</td><td style=\"text-align: right;\">          489</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00012</td><td>RUNNING </td><td>10.82.72.122:1869799</td><td style=\"text-align: right;\">      184</td><td style=\"text-align: right;\">          347</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00009</td><td>RUNNING </td><td>10.82.72.122:1869862</td><td style=\"text-align: right;\">      182</td><td style=\"text-align: right;\">          362</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00005</td><td>RUNNING </td><td>10.82.72.122:1869802</td><td style=\"text-align: right;\">      192</td><td style=\"text-align: right;\">          355</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_and_evaluate_ray_0a1fb_00003</td><td>RUNNING </td><td>10.82.72.122:1869803</td><td style=\"text-align: right;\">      173</td><td style=\"text-align: right;\">          264</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">                </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 16:47:16,350\tINFO tune_controller.py:444 -- Restoring the run from the latest experiment state file: experiment_state-2025-10-19_16-30-59.json\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "\n",
    "config_hyperband = {\n",
    "    # Fixed parameters\n",
    "    \"epochs\": 10,\n",
    "    \"data_dir\": Path(DATADIR).resolve(),\n",
    "    \"tune_dir\": Path(TUNEDIR).resolve(),\n",
    "    \"batch_size\": 64,\n",
    "    \"input_size\": 3,\n",
    "    \"output_size\": 20,\n",
    "    \"hidden_size\": tune.randint(254, 512),\n",
    "    \"dropout\": 0,\n",
    "    \"num_fully_connected_layers\": 2,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"loss_fn\": torch.nn.CrossEntropyLoss(), # suitable for multi-class classification\n",
    "    \"optimizer\": torch.optim.Adam,\n",
    "    \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"metrics\": \"accuracy\",\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    # convolutional layer parameters\n",
    "    \"num_conv_layers\": tune.grid_search([3]),\n",
    "    \"filters\": tune.randint(100, 200),\n",
    "    \"kernel_size\": tune.randint(2, 3),\n",
    "    \"stride\": 1,\n",
    "    \"padding\": tune.randint(0, 1),  # typical options for padding\n",
    "}\n",
    "\n",
    "# Create an AsyncHyperBandScheduler for efficient hyperparameter search\n",
    "scheduler_hyperband = AsyncHyperBandScheduler(\n",
    "    time_attr=\"training_iteration\",  # attribute that tracks training progress\n",
    "    grace_period=3,                  # start terminating after 3 epochs\n",
    "    reduction_factor=2,              # half the number of models per epoch after grace_period\n",
    "    max_t=config_hyperband[\"epochs\"] # train for max 10 epochs\n",
    ")\n",
    "\n",
    "# To avoid running out of memory, set 'reuse_actors' to True and limit 'max_concurrent_trials'.\n",
    "# You can also reduce 'num_samples' or batch size if needed.\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_and_evaluate_ray,\n",
    "    config=config_hyperband,\n",
    "    name=\"cnn_hyperparameter_hyperband_transforms\",\n",
    "    metric=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    storage_path=str(config_hyperband[\"tune_dir\"]),  # ensure path is string\n",
    "    num_samples=20,\n",
    "    verbose=1,\n",
    "    scheduler=scheduler_hyperband,\n",
    "    resume=True,\n",
    "    reuse_actors=True,              # Reuse actors to save memory\n",
    "    max_concurrent_trials=5         # Limit concurrent trials (adjust as needed)\n",
    ")\n",
    "tune_df_hyperband = analysis.results_df.sort_values(\"val_loss\")\n",
    "tune_df_hyperband.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a175e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Get the best config from the hyperband search\n",
    "best_config = analysis.get_best_config(metric=\"val_loss\", mode=\"min\")\n",
    "\n",
    "logger.info(f\"Best config: {best_config}\")\n",
    "\n",
    "# Instantiate the model with the best hyperparameters\n",
    "best_model = SimpleCNN(\n",
    "    input_size=best_config[\"input_size\"],\n",
    "    hidden_size=best_config[\"hidden_size\"],\n",
    "    output_size=best_config[\"output_size\"],\n",
    "    dropout=best_config[\"dropout\"],\n",
    "    num_conv_layers=best_config[\"num_conv_layers\"],\n",
    "    filters=best_config[\"filters\"],\n",
    "    kernel_size=best_config[\"kernel_size\"],\n",
    "    stride=best_config[\"stride\"],\n",
    "    padding=best_config[\"padding\"],\n",
    "    num_fully_connected_layers=best_config[\"num_fully_connected_layers\"]\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "device = best_config[\"device\"]\n",
    "best_model.to(device)\n",
    "\n",
    "# Optionally, you can load weights from a checkpoint if available:\n",
    "checkpoint_path = analysis.get_best_checkpoint(trial=analysis.get_best_trial(metric=\"val_loss\", mode=\"min\"))\n",
    "if checkpoint_path:\n",
    "    best_model.load_state_dict(torch.load(checkpoint_path)[\"model_state_dict\"])\n",
    "\n",
    "# Now you can further train the model using your existing train_and_evaluate function:\n",
    "# Example:\n",
    "train_and_evaluate(best_model, best_config, logger)\n",
    "best_model.plot_learning_curve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio-example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
