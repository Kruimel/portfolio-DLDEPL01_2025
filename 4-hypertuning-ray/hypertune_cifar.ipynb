{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62314dbc",
   "metadata": {},
   "source": [
    "# Hypertune cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518083dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = (\"data/raw/cifar10/\")\n",
    "TUNEDIR = (\"hypertune\")\n",
    "from loguru import logger\n",
    "import ray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2c8596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import datasets, transforms\n",
    "# from loguru import logger\n",
    "from pathlib import Path\n",
    "\n",
    "# # Ensure the data directory exists before downloading dataset\n",
    "data_dir = Path(DATADIR).resolve()\n",
    "if not data_dir.exists():\n",
    "    data_dir.mkdir(parents=True)\n",
    "    logger.info(f\"Created {data_dir}\")\n",
    "\n",
    "tune_dir = Path(TUNEDIR).resolve()\n",
    "if not tune_dir.exists():\n",
    "    tune_dir.mkdir(parents=True)\n",
    "    logger.info(f\"Created {tune_dir}\")\n",
    "\n",
    "# # Create transformer to convert images to tensors\n",
    "# transformer = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# # Download CIFAR10 dataset\n",
    "# train_dataset = datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transformer)\n",
    "# test_dataset = datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transformer)\n",
    "\n",
    "# logger.info(\n",
    "#     f\"Dataset is now available:\\n\"\n",
    "#     f\"TRAIN: {train_dataset}\\n\"\n",
    "#     f\"TEST: {test_dataset}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd31bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8454e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # Create data loaders for training and testing\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# # Inspect the shape of a batch of training data\n",
    "# for images, labels in train_loader:\n",
    "#     logger.info(f\"Image batch dimensions: {images.shape}\")\n",
    "#     logger.info(f\"Image label dimensions: {labels.shape}\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee91836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(batch_size, data_dir):\n",
    "    from filelock import FileLock\n",
    "    from torchvision import datasets, transforms\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    with FileLock(data_dir / \".lock\"):\n",
    "        # Create transformer to convert images to tensors\n",
    "        transformer = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "        # Download CIFAR10 dataset\n",
    "        train_dataset = datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transformer, )\n",
    "        test_dataset = datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transformer)\n",
    "\n",
    "        # Create data loaders for training and testing\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ecbf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "config = {\n",
    "    # Fixed parameters\n",
    "    \"epochs\": 5,\n",
    "    \"data_dir\": Path(DATADIR).resolve(),\n",
    "    \"batch_size\": 64,\n",
    "    \"input_size\": 3,\n",
    "    \"output_size\": 20,\n",
    "    \"hidden_size\": 128,\n",
    "    \"dropout\": 0,\n",
    "    \"num_layers\": 5,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"loss_fn\": torch.nn.CrossEntropyLoss(), # suitable for multi-class classification\n",
    "    \"optimizer\": torch.optim.Adam,\n",
    "    # \"scheduler\": torch.optim.lr_scheduler.LRScheduler,\n",
    "    \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"metrics\": \"accuracy\",\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\", \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabab42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for simple neural network with learning curve plotting\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple feedforward neural network for image classification.\n",
    "\n",
    "    Args:\n",
    "        input_size (int): Number of input channels (e.g., 3 for RGB images).\n",
    "        hidden_size (int): Number of units in hidden layers.\n",
    "        output_size (int): Number of output classes.\n",
    "        dropout (float): Dropout probability for regularization.\n",
    "        num_layers (int): Number of hidden layers.\n",
    "\n",
    "    Methods:\n",
    "        forward(x): Forward pass through the network.\n",
    "        summary(): Prints a summary of the network architecture.\n",
    "        plot_learning_curve(): Plots the learning curve (loss and accuracy).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout, num_layers, use_residual=False, use_batchnorm=False):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.use_residual = use_residual\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        # For learning curve\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "\n",
    "        layers = []\n",
    "        # Flatten input image\n",
    "        layers.append(nn.Flatten())\n",
    "        # First linear layer from input to hidden\n",
    "        layers.append(nn.Linear(input_size * 32 * 32, hidden_size))\n",
    "        if self.use_batchnorm:\n",
    "            layers.append(nn.BatchNorm1d(hidden_size))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # Additional hidden layers with optional residual and batchnorm\n",
    "        for i in range(num_layers - 1):\n",
    "            linear = nn.Linear(hidden_size, hidden_size)\n",
    "            block = [linear]\n",
    "            if self.use_batchnorm:\n",
    "                block.append(nn.BatchNorm1d(hidden_size))\n",
    "            block.append(nn.ReLU())\n",
    "            block.append(nn.Dropout(dropout))\n",
    "            if self.use_residual:\n",
    "                # Residual block as a custom nn.Module\n",
    "                block = [ResidualBlock(hidden_size, block)]\n",
    "            layers.extend(block)\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(hidden_size, output_size))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, input_size, 32, 32).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output logits.\n",
    "        \"\"\"\n",
    "        return self.network(x) \n",
    "\n",
    "    def summary(self):\n",
    "        \"\"\"\n",
    "        Prints a summary of the network architecture using torchsummary.\n",
    "        \"\"\"\n",
    "        summary(self.network, (self.input_size, 32, 32))\n",
    "\n",
    "    def plot_learning_curve(self):\n",
    "        \"\"\"\n",
    "        Plots the learning curve (loss and accuracy).\n",
    "        \"\"\"\n",
    "        epochs = range(1, len(self.train_losses) + 1)\n",
    "        fig, ax1 = plt.subplots()\n",
    "        ax1.plot(epochs, self.train_losses, 'b-', label='Train Loss')\n",
    "        ax1.plot(epochs, self.val_losses, 'r-', label='Val Loss')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend(loc='upper left')\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(epochs, self.train_accuracies, 'b--', label='Train Acc')\n",
    "        ax2.plot(epochs, self.val_accuracies, 'r--', label='Val Acc')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.legend(loc='upper right')\n",
    "        plt.title('Learning Curve')\n",
    "        plt.show()\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, hidden_size, block_layers):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(*block_layers)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "\n",
    "model_NN = SimpleNN(\n",
    "    input_size=config[\"input_size\"],\n",
    "    hidden_size=config[\"hidden_size\"],\n",
    "    output_size=config[\"output_size\"],\n",
    "    dropout=config[\"dropout\"],\n",
    "    num_layers=config[\"num_layers\"]\n",
    ")\n",
    "model_NN_with_residual = SimpleNN(\n",
    "    input_size=config[\"input_size\"],\n",
    "    hidden_size=config[\"hidden_size\"],\n",
    "    output_size=config[\"output_size\"],\n",
    "    dropout=config[\"dropout\"],\n",
    "    num_layers=config[\"num_layers\"],\n",
    "    use_residual=True\n",
    ")\n",
    "model_NN_with_batchnorm = SimpleNN(\n",
    "    input_size=config[\"input_size\"],\n",
    "    hidden_size=config[\"hidden_size\"],\n",
    "    output_size=config[\"output_size\"],\n",
    "    dropout=config[\"dropout\"],\n",
    "    num_layers=config[\"num_layers\"],\n",
    "    use_batchnorm=True\n",
    ")\n",
    "\n",
    "# Show a summary of the model architecture\n",
    "model_NN.summary(); model_NN_with_residual.summary(); model_NN_with_batchnorm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace8f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_one_epoch(model, train_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def evaluate(model, test_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def train_and_evaluate(model, config, logger):\n",
    "    train_loader, test_loader = get_data_loaders(config[\"batch_size\"], config[\"data_dir\"])\n",
    "    device = config[\"device\"]\n",
    "    model.to(device)\n",
    "    optimizer = config[\"optimizer\"](model.parameters(), lr=config[\"learning_rate\"])\n",
    "    loss_fn = config[\"loss_fn\"]\n",
    "    num_epochs = config[\"epochs\"]\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "        val_loss, val_accuracy = evaluate(model, test_loader, loss_fn, device)\n",
    "\n",
    "        model.train_losses.append(train_loss)\n",
    "        model.val_losses.append(val_loss)\n",
    "        model.train_accuracies.append(train_accuracy)\n",
    "        model.val_accuracies.append(val_accuracy)\n",
    "\n",
    "        logger.info(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {val_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Test Acc: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    return model.train_losses[-1], model.val_losses[-1], model.val_accuracies[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94ffb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_evaluate(model_NN, config, logger)\n",
    "# model_NN.plot_learning_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_evaluate(model_NN_with_residual, config, logger)\n",
    "# model_NN_with_residual.plot_learning_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d423f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_evaluate(model_NN_with_batchnorm, config, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2783ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mltrainer import Trainer, ReportTypes, TrainerSettings\n",
    "\n",
    "# model_NN2 = SimpleNN(\n",
    "#     input_size=config[\"input_size\"],\n",
    "#     hidden_size=config[\"hidden_size\"],\n",
    "#     output_size=config[\"output_size\"],\n",
    "#     dropout=config[\"dropout\"],\n",
    "#     num_layers=config[\"num_layers\"]\n",
    "# )\n",
    "\n",
    "# model_NN2.to(device)\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model_NN2,\n",
    "#     settings=TrainerSettings(\n",
    "#         epochs=config[\"epochs\"],\n",
    "#         metrics=[config[\"metrics\"]],\n",
    "#         logdir=Path(\"./logs\"),\n",
    "#         train_steps=len(train_loader),\n",
    "#         valid_steps=len(test_loader),\n",
    "#         reporttypes=[ReportTypes.TOML],\n",
    "#         scheduler_kwargs={\"patience\": 5},\n",
    "#         earlystop_kwargs={\"patience\": 5},\n",
    "#     ),\n",
    "#     loss_fn=config[\"loss_fn\"],\n",
    "#     optimizer=torch.optim.Adam,\n",
    "#     traindataloader=train_loader,\n",
    "#     validdataloader=test_loader,\n",
    "#     scheduler=config[\"scheduler\"],\n",
    "#     device=device,\n",
    "# )\n",
    "# trainer.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6bb182",
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\n",
    "    # Fixed parameters\n",
    "    \"epochs\": 5,\n",
    "    \"data_dir\": Path(DATADIR).resolve(),\n",
    "    \"batch_size\": 64,\n",
    "    \"input_size\": 3,\n",
    "    \"output_size\": 20,\n",
    "    \"hidden_size\": 128,\n",
    "    \"dropout\": 0,\n",
    "    \"num_fully_connected_layers\": 2,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"loss_fn\": torch.nn.CrossEntropyLoss(), # suitable for multi-class classification\n",
    "    \"optimizer\": torch.optim.Adam,\n",
    "    # \"scheduler\": torch.optim.lr_scheduler.LRScheduler,\n",
    "    \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"metrics\": \"accuracy\",\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \n",
    "    # convolutional layer parameters\n",
    "    \"num_conv_layers\": 3,\n",
    "    \"filters\": 64,\n",
    "    \"kernel_size\": 3,\n",
    "    \"stride\": 1,\n",
    "    \"padding\": 1,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d474d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for simple neural network\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple Convolutional Neural Network (CNN) for image classification.\n",
    "    Args:\n",
    "        input_size (int): Number of input channels (e.g., 3 for RGB images).\n",
    "        hidden_size (int): Number of units in the fully connected hidden layer.\n",
    "        output_size (int): Number of output classes.\n",
    "        dropout (float): Dropout probability for regularization.\n",
    "        num_conv_layers (int): Number of convolutional layers.\n",
    "        filters (int): Number of filters in each convolutional layer.\n",
    "        kernel_size (int): Size of the convolutional kernels.\n",
    "        stride (int): Stride for the convolutional layers.\n",
    "        padding (int): Padding for the convolutional layers.\n",
    "        num_fully_connected_layers (int): Number of fully connected layers.\n",
    "    Methods:\n",
    "        forward(x): Forward pass through the network.\n",
    "        summary(): Prints a summary of the network architecture.\n",
    "        plot_learning_curve(): Plots the training/validation loss and accuracy curves.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout, num_conv_layers, filters, kernel_size, stride, padding, num_fully_connected_layers):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        # For learning curve\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "\n",
    "        layers = []\n",
    "        in_channels = input_size\n",
    "\n",
    "        # Add convolutional layers\n",
    "        for _ in range(num_conv_layers):\n",
    "            layers.append(nn.Conv2d(in_channels, filters, kernel_size, stride, padding))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.MaxPool2d(2))\n",
    "            in_channels = filters\n",
    "\n",
    "        layers.append(nn.Flatten())\n",
    "\n",
    "        # Dynamically compute feature size after conv/pool layers\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, input_size, 32, 32)\n",
    "            for layer in layers:\n",
    "                dummy = layer(dummy)\n",
    "            feature_size = dummy.shape[1]\n",
    "\n",
    "        # Add the first fully connected layer\n",
    "        layers.append(nn.Linear(feature_size, hidden_size))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # Add additional fully connected layers if num_fully_connected_layers > 1\n",
    "        for _ in range(num_fully_connected_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(hidden_size, output_size))\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the network.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, input_size, 32, 32).\n",
    "        Returns:\n",
    "            torch.Tensor: Output logits.\n",
    "        \"\"\"\n",
    "        return self.network(x) \n",
    "\n",
    "    def summary(self):\n",
    "        \"\"\"\n",
    "        Prints a summary of the network architecture using torchsummary.\n",
    "        \"\"\"\n",
    "        summary(self.network, (self.input_size, 32, 32))\n",
    "    \n",
    "    def plot_learning_curve(self):\n",
    "        \"\"\"\n",
    "        Plots the learning curve (loss and accuracy).\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        epochs = range(1, len(self.train_losses) + 1)\n",
    "        fig, ax1 = plt.subplots()\n",
    "        ax1.plot(epochs, self.train_losses, 'b-', label='Train Loss')\n",
    "        ax1.plot(epochs, self.val_losses, 'r-', label='Val Loss')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend(loc='upper left')\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(epochs, self.train_accuracies, 'b--', label='Train Acc')\n",
    "        ax2.plot(epochs, self.val_accuracies, 'r--', label='Val Acc')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.legend(loc='upper right')\n",
    "        plt.title('Learning Curve')\n",
    "        plt.show()\n",
    "\n",
    "model_CNN = SimpleCNN(\n",
    "    input_size=config2[\"input_size\"],\n",
    "    hidden_size=config2[\"hidden_size\"],\n",
    "    output_size=config2[\"output_size\"],\n",
    "    dropout=config2[\"dropout\"],\n",
    "    num_conv_layers=config2[\"num_conv_layers\"],\n",
    "    filters=config2[\"filters\"],\n",
    "    kernel_size=config2[\"kernel_size\"],\n",
    "    stride=config2[\"stride\"],\n",
    "    padding=config2[\"padding\"],\n",
    "    num_fully_connected_layers=config2[\"num_fully_connected_layers\"]\n",
    ")\n",
    "\n",
    "# Show a summary of the model architecture\n",
    "model_CNN.summary(); model_CNN.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c102cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_evaluate(model_CNN, config2, logger)\n",
    "# model_CNN.plot_learning_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a9df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mltrainer import Trainer, ReportTypes, TrainerSettings, metrics\n",
    "# model_CNN = SimpleNN(\n",
    "#     input_size=config2[\"input_size\"],\n",
    "#     hidden_size=config2[\"hidden_size\"],\n",
    "#     output_size=config2[\"output_size\"],\n",
    "#     dropout=config2[\"dropout\"],\n",
    "#     num_layers=config2[\"num_layers\"]\n",
    "# )\n",
    "\n",
    "# model_CNN.to(config2[\"device\"])\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model_CNN,\n",
    "#     settings=TrainerSettings(\n",
    "#         epochs=config2[\"epochs\"],\n",
    "#         metrics=[\n",
    "#             metrics.Accuracy()\n",
    "#         ],\n",
    "#         logdir=Path(\"./logs\"),\n",
    "#         train_steps=len(train_loader),\n",
    "#         valid_steps=len(test_loader),\n",
    "#         reporttypes=[ReportTypes.TOML],\n",
    "#         scheduler_kwargs={\"patience\": 5},\n",
    "#         earlystop_kwargs={\"patience\": 5},\n",
    "#     ),\n",
    "#     loss_fn=config2[\"loss_fn\"],\n",
    "#     optimizer=torch.optim.Adam,\n",
    "#     traindataloader=train_loader,\n",
    "#     validdataloader=test_loader,\n",
    "#     scheduler=config2[\"scheduler\"],\n",
    "#     device=config2[\"device\"],\n",
    "# )\n",
    "# trainer.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca44cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "\n",
    "def train_and_evaluate_ray(config: dict):\n",
    "    model = SimpleCNN(\n",
    "        input_size=config[\"input_size\"],\n",
    "        hidden_size=config[\"hidden_size\"],\n",
    "        output_size=config[\"output_size\"],\n",
    "        dropout=config[\"dropout\"],\n",
    "        num_conv_layers=config[\"num_conv_layers\"],\n",
    "        filters=config[\"filters\"],\n",
    "        kernel_size=config[\"kernel_size\"],\n",
    "        stride=config[\"stride\"],\n",
    "        padding=config[\"padding\"],\n",
    "        num_fully_connected_layers=config[\"num_fully_connected_layers\"]\n",
    "    )\n",
    "    train_loader, test_loader = get_data_loaders(config[\"batch_size\"], config[\"data_dir\"])\n",
    "    device = config[\"device\"]\n",
    "    model.to(device)\n",
    "    optimizer = config[\"optimizer\"](model.parameters(), lr=config[\"learning_rate\"])\n",
    "    loss_fn = config[\"loss_fn\"]\n",
    "    num_epochs = config[\"epochs\"]\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "        val_loss, val_accuracy = evaluate(model, test_loader, loss_fn, device)\n",
    "\n",
    "        model.train_losses.append(train_loss)\n",
    "        model.val_losses.append(val_loss)\n",
    "        model.train_accuracies.append(train_accuracy)\n",
    "        model.val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        ray.train.report({\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"val_accuracy\": val_accuracy\n",
    "        })\n",
    "        # logger.info(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {val_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Test Acc: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    return model.train_losses[-1], model.val_losses[-1], model.val_accuracies[-1]\n",
    "\n",
    "config_structure = {\n",
    "    \n",
    "    # Fixed parameters\n",
    "    \"epochs\": 3,\n",
    "    \"data_dir\": Path(DATADIR).resolve(),\n",
    "    \"tune_dir\": Path(TUNEDIR).resolve(),\n",
    "    \"batch_size\": 64,\n",
    "    \"input_size\": 3,\n",
    "    \"output_size\": 20,\n",
    "    \"hidden_size\": 350,\n",
    "    \"dropout\": 0,\n",
    "    \"num_fully_connected_layers\": tune.grid_search([2,4]),\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"loss_fn\": torch.nn.CrossEntropyLoss(), # suitable for multi-class classification\n",
    "    \"optimizer\": torch.optim.Adam,\n",
    "    # \"scheduler\": torch.optim.lr_scheduler.LRScheduler,\n",
    "    \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"metrics\": \"accuracy\",\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \n",
    "    # convolutional layer parameters\n",
    "    \"num_conv_layers\": tune.grid_search([2,3,4]),\n",
    "    \"filters\": tune.grid_search([64,128,152]),\n",
    "    \"kernel_size\": tune.grid_search([2,3]),\n",
    "    \"stride\": 1,\n",
    "    \"padding\": 0,\n",
    "}\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_and_evaluate_ray,\n",
    "    config=config_structure,\n",
    "    name=\"cnn_hyperparameter_gridsearch\",\n",
    "    metric=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    storage_path=str(config_structure[\"tune_dir\"]),  # ensure path is string\n",
    "    stop={\"training_iteration\": config_structure[\"epochs\"]},\n",
    "    verbose=1,\n",
    "    resume=True   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e4a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import graph_objects as go\n",
    "\n",
    "def plot_contour(df, x, y, z, start=None, end=None, size=None, colorscale=\"plasma\", colorbar_title=None):\n",
    "    # Set defaults for contour range if not provided\n",
    "    z_min, z_max = df[z].min(), df[z].max()\n",
    "    if start is None:\n",
    "        start = z_min\n",
    "    if end is None:\n",
    "        end = z_max\n",
    "    if size is None:\n",
    "        size = (end - start) / 20 if end > start else 0.01\n",
    "    if colorbar_title is None:\n",
    "        colorbar_title = z\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Contour(\n",
    "            z=df[z],\n",
    "            x=df[x],\n",
    "            y=df[y],\n",
    "            contours=dict(\n",
    "                coloring='heatmap',\n",
    "                showlabels=True,  # show labels on contouz_max\n",
    "                start=start,       # start of the contour range\n",
    "                end=end,          # end of the contour range\n",
    "                size=size,\n",
    "            ),\n",
    "            colorscale=\"plasma\",\n",
    "            colorbar=dict(\n",
    "                title='Accuracy'\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[x],\n",
    "            y=df[y],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                color='black',\n",
    "                size=8,\n",
    "                symbol='circle'\n",
    "            ),\n",
    "            customdata=df[z],\n",
    "            hovertemplate=(\n",
    "                f'{x}: %{{x}}<br>'\n",
    "                f'{y}: %{{y}}<br>'\n",
    "                f'{z}: %{{customdata:.4f}}<extra></extra>'\n",
    "            ),\n",
    "            name='Data Points'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Contour Plot of {z} by {x} and {y}\",\n",
    "        xaxis_title=x,\n",
    "        yaxis_title=y,\n",
    "        xaxis=dict(showgrid=False),\n",
    "        yaxis=dict(showgrid=False),\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white'\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b5b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = analysis.results_df\n",
    "results_df.info()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac19c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_kernels = plot_contour(\n",
    "    analysis.results_df,\n",
    "    x=\"config/kernel_size\",\n",
    "    y=\"config/filters\",\n",
    "    z=\"val_accuracy\",\n",
    ")\n",
    "img_kernels.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb1357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_layers = plot_contour(\n",
    "    analysis.results_df,\n",
    "    x=\"config/num_conv_layers\",\n",
    "    y=\"config/num_fully_connected_layers\",\n",
    "    z=\"val_accuracy\",\n",
    ")\n",
    "img_layers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_fc_units = plot_contour(\n",
    "    analysis.results_df,\n",
    "    x=\"config/hidden_size\",\n",
    "    y=\"config/num_fully_connected_layers\",\n",
    "    z=\"val_accuracy\",\n",
    ")\n",
    "img_fc_units.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb41c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(\"val_accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cc5d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "\n",
    "config_hyperband = {\n",
    "    # Fixed parameters\n",
    "    \"epochs\": 10,\n",
    "    \"data_dir\": Path(DATADIR).resolve(),\n",
    "    \"tune_dir\": Path(TUNEDIR).resolve(),\n",
    "    \"batch_size\": 64,\n",
    "    \"input_size\": 3,\n",
    "    \"output_size\": 20,\n",
    "    \"hidden_size\": tune.randint(254, 512),\n",
    "    \"dropout\": 0,\n",
    "    \"num_fully_connected_layers\": 2,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"loss_fn\": torch.nn.CrossEntropyLoss(), # suitable for multi-class classification\n",
    "    \"optimizer\": torch.optim.Adam,\n",
    "    \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"metrics\": \"accuracy\",\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    # convolutional layer parameters\n",
    "    \"num_conv_layers\": tune.grid_search([3]),\n",
    "    \"filters\": tune.randint(100, 200),\n",
    "    \"kernel_size\": tune.randint(2, 3),\n",
    "    \"stride\": 1,\n",
    "    \"padding\": tune.grid_search([0, 1]),  # typical options for padding\n",
    "}\n",
    "\n",
    "# Create an AsyncHyperBandScheduler for efficient hyperparameter search\n",
    "scheduler_hyperband = AsyncHyperBandScheduler(\n",
    "    time_attr=\"training_iteration\",  # attribute that tracks training progress\n",
    "    grace_period=3,                  # minimum number of iterations before stopping trials\n",
    "    reduction_factor=3,              # controls how aggressively to cut underperforming trials\n",
    "    max_t=config_hyperband[\"epochs\"] # maximum number of training iterations\n",
    ")\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_and_evaluate_ray,\n",
    "    config=config_hyperband,\n",
    "    metric=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    storage_path=str(config_structure[\"tune_dir\"]),  # ensure path is string\n",
    "    num_samples=20,\n",
    "    stop={\"training_iteration\": config_structure[\"epochs\"]},\n",
    "    verbose=1,\n",
    "    scheduler=scheduler_hyperband,\n",
    "    resume=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d99889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = analysis.get_best_config()\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b11eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "best.plot_learning_curve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio-example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
