{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from mltrainer import rnn_models, Trainer\n",
    "from torch import optim\n",
    "\n",
    "from mads_datasets import datatools\n",
    "import mltrainer\n",
    "mltrainer.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Iterators\n",
    "We will be using an interesting dataset. [link](https://tev.fbk.eu/resources/smartwatch)\n",
    "\n",
    "From the site:\n",
    "> The SmartWatch Gestures Dataset has been collected to evaluate several gesture recognition algorithms for interacting with mobile applications using arm gestures. Eight different users performed twenty repetitions of twenty different gestures, for a total of 3200 sequences. Each sequence contains acceleration data from the 3-axis accelerometer of a first generation Sony SmartWatchâ„¢, as well as timestamps from the different clock sources available on an Android device. The smartwatch was worn on the user's right wrist. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import PaddedPreprocessor\n",
    "preprocessor = PaddedPreprocessor()\n",
    "\n",
    "gesturesdatasetfactory = DatasetFactoryProvider.create_factory(DatasetType.GESTURES)\n",
    "streamers = gesturesdatasetfactory.create_datastreamer(batchsize=32, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()\n",
    "x, y = next(iter(trainstreamer))\n",
    "x.shape, y.shape, x, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you make sense of the shape?\n",
    "What does it mean that the shapes are sometimes (32, 27, 3), but a second time might look like (32, 30, 3)? In other words, the second (or first, if you insist on starting at 0) dimension changes. Why is that? How does the model handle this? Do you think this is already padded, or still has to be padded?\n",
    "\n",
    "\n",
    "# 2 Excercises\n",
    "Lets test a basemodel, and try to improve upon that.\n",
    "\n",
    "Fill the gestures.gin file with relevant settings for `input_size`, `hidden_size`, `num_layers` and `horizon` (which, in our case, will be the number of classes...)\n",
    "\n",
    "As a rule of thumbs: start lower than you expect to need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltrainer import TrainerSettings, ReportTypes\n",
    "from mltrainer.metrics import Accuracy\n",
    "\n",
    "accuracy = Accuracy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnn_models.BaseRNN(\n",
    "    input_size=3,      # Number of features per time step (accelerometer axes: x, y, z)\n",
    "    hidden_size=64,    # Number of hidden units in the RNN layer\n",
    "    num_layers=1,      # Number of stacked RNN layers\n",
    "    horizon=20,        # Number of output classes (gesture types)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model. What is the output shape you need? Remember, we are doing classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model(x)\n",
    "yhat.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(y, yhat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think of the accuracy? What would you expect from blind guessing?\n",
    "\n",
    "Check shape of `y` and `yhat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And look at the output of yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this make sense to you? If you are unclear, go back to the classification problem with the MNIST, where we had 10 classes.\n",
    "\n",
    "We have a classification problem, so we need Cross Entropy Loss.\n",
    "Remember, [this has a softmax built in](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss = loss_fn(yhat, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(\"using cuda\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"using cpu\")\n",
    "\n",
    "# on my mac, at least for the BaseRNN model, mps does not speed up training\n",
    "# probably because the overhead of copying the data to the GPU is too high\n",
    "# so i override the device to cpu\n",
    "device = \"cpu\"\n",
    "# however, it might speed up training for larger models, with more parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the settings for the trainer and the different types of logging you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = TrainerSettings(\n",
    "    epochs=10, # increase this to about 100 for training\n",
    "    metrics=[accuracy],           # List of metrics to evaluate during training (here, accuracy)\n",
    "    logdir=Path(\"gestures\"),      # Directory to save logs and model checkpoints\n",
    "    train_steps=len(train),       # Number of training steps per epoch (batches in train dataloader)\n",
    "    valid_steps=len(valid),       # Number of validation steps per epoch (batches in valid dataloader)\n",
    "    reporttypes=[ReportTypes.TOML, ReportTypes.TENSORBOARD, ReportTypes.MLFLOW], # Types of reports/logs to generate\n",
    "    scheduler_kwargs={\"factor\": 0.5, \"patience\": 5}, # Learning rate scheduler settings\n",
    "    earlystop_kwargs = {\n",
    "        \"save\": True,            # Whether to save the best model during early stopping\n",
    "        \"verbose\": True,\n",
    "        \"patience\": 5, # number of epochs with no improvement after which training will be stopped\n",
    "        \"delta\": 0.0, # minimum change to be considered an improvement\n",
    "    }\n",
    ")\n",
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    input_size: int      # Number of input features per time step\n",
    "    hidden_size: int     # Number of hidden units in the RNN\n",
    "    num_layers: int      # Number of stacked RNN/LSTM layers\n",
    "    output_size: int     # Number of output classes\n",
    "    dropout: float = 0.0 # Dropout rate between RNN layers\n",
    "\n",
    "class GRUmodel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        # GRU layer for sequence modeling\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=config.input_size,\n",
    "            hidden_size=config.hidden_size,\n",
    "            dropout=config.dropout,\n",
    "            batch_first=True,\n",
    "            num_layers=config.num_layers,\n",
    "        )\n",
    "        # Linear layer to map hidden state to output classes\n",
    "        self.linear = nn.Linear(config.hidden_size, config.output_size)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x, _ = self.rnn(x)           # x: (batch, seq_len, hidden_size)\n",
    "        last_step = x[:, -1, :]      # Take the last time step's hidden state\n",
    "        yhat = self.linear(last_step) # Map to output classes\n",
    "        return yhat\n",
    "    \n",
    "class LSTMmodel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        # LSTM layer for sequence modeling\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=config.input_size,\n",
    "            hidden_size=config.hidden_size,\n",
    "            dropout=config.dropout,\n",
    "            batch_first=True,\n",
    "            num_layers=config.num_layers,\n",
    "        )\n",
    "        # Linear layer to map hidden state to output classes\n",
    "        self.linear = nn.Linear(config.hidden_size, config.output_size)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x, _ = self.rnn(x)           # x: (batch, seq_len, hidden_size)\n",
    "        last_step = x[:, -1, :]      # Take the last time step's hidden state\n",
    "        yhat = self.linear(last_step) # Map to output classes\n",
    "        return yhat\n",
    "    \n",
    "\n",
    "class GRUConv1DModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        # Conv1d expects (batch, channels, seq_len)\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=config.input_size, \n",
    "            out_channels=16, \n",
    "            kernel_size=3, \n",
    "            padding=1\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        # Update input_size for RNN to match conv1 out_channels\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=16,\n",
    "            hidden_size=config.hidden_size,\n",
    "            dropout=config.dropout,\n",
    "            batch_first=True,\n",
    "            num_layers=config.num_layers,\n",
    "        )\n",
    "        self.linear = nn.Linear(config.hidden_size, config.output_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (batch, seq_len, features)\n",
    "        x = x.permute(0, 2, 1)  # (batch, features, seq_len)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = x.permute(0, 2, 1)  # (batch, seq_len, channels)\n",
    "        x, _ = self.rnn(x)\n",
    "        last_step = x[:, -1, :]\n",
    "        yhat = self.linear(last_step)\n",
    "        return yhat\n",
    "\n",
    "\n",
    "class LSTMConv1DModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        # Conv1d expects (batch, channels, seq_len)\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=config.input_size, \n",
    "            out_channels=16, \n",
    "            kernel_size=3, \n",
    "            padding=1\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        # Update input_size for RNN to match conv1 out_channels\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=16,\n",
    "            hidden_size=config.hidden_size,\n",
    "            dropout=config.dropout,\n",
    "            batch_first=True,\n",
    "            num_layers=config.num_layers,\n",
    "        )\n",
    "        self.linear = nn.Linear(config.hidden_size, config.output_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (batch, seq_len, features)\n",
    "        x = x.permute(0, 2, 1)  # (batch, features, seq_len)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = x.permute(0, 2, 1)  # (batch, seq_len, channels)\n",
    "        x, _ = self.rnn(x)\n",
    "        last_step = x[:, -1, :]\n",
    "        yhat = self.linear(last_step)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from datetime import datetime\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "experiment_name = \"gestures_10epochs\"\n",
    "if not mlflow.get_experiment_by_name(experiment_name):\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "modeldir = Path(experiment_name).resolve()\n",
    "if not modeldir.exists():\n",
    "    modeldir.mkdir(parents=True)\n",
    "\n",
    "# for i in range(10):\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"model\", \"notebook_epochs_10\")\n",
    "    mlflow.set_tag(\"dev\", \"kim\")\n",
    "    mlflow.set_active_model(name=\"GRU_epochs_10\")\n",
    "    mlflow.set_tag(\"run_name\", f\"GRU_Conv1_run\" + datetime.now().strftime(\"%Y%m%d-%H%M\"))\n",
    "    # mlflow.set_tag(\"run_name\", f\"LSTM_Conv1D_run\" + datetime.now().strftime(\"%Y%m%d-%H%M\"))\n",
    "    config = ModelConfig(\n",
    "        input_size=3,   # Number of input features per time step\n",
    "        hidden_size=64, # Number of hidden units in the RNN\n",
    "        num_layers=2,   # Number of stacked RNN/LSTM layers\n",
    "        output_size=20, # Number of output classes\n",
    "        dropout=0.1,    # Dropout rate between RNN layers\n",
    "    )\n",
    "    mlflow.log_params(config.__dict__)\n",
    "\n",
    "    # model = GRUmodel(\n",
    "    #     config=config,\n",
    "    # )\n",
    "\n",
    "    # model = LSTMmodel(\n",
    "    #     config=config,\n",
    "    # )\n",
    "\n",
    "    model = GRUConv1DModel(\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    # model = LSTMConv1DModel(\n",
    "    #     config=config,\n",
    "    # )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optim.Adam,\n",
    "        traindataloader=trainstreamer,\n",
    "        validdataloader=validstreamer,\n",
    "        scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        device=device,\n",
    "    )\n",
    "    trainer.loop()\n",
    "\n",
    "    if not settings.earlystop_kwargs[\"save\"]:\n",
    "        tag = datetime.now().strftime(\"%Y%m%d-%H%M-\")\n",
    "        modelpath = modeldir / (tag + \"model.pt\")\n",
    "        torch.save(model, modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot accuracy for both LSTM and GRU models against number of layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "runs = mlflow.search_runs(experiment_ids=[\"2\"])\n",
    "runs_df = pd.DataFrame(runs)\n",
    "runs_df\n",
    "runs_df[['params.num_layers', 'metrics.metric/Accuracy', 'tags.run_name']]\n",
    "runs_df['params.num_layers'] = runs_df['params.num_layers'].astype(int)\n",
    "runs_df['metrics.metric/Accuracy'] = runs_df['metrics.metric/Accuracy'].astype(float)\n",
    "gru_runs = runs_df[runs_df['tags.run_name'].str.contains(\"GRU_run\")]\n",
    "lstm_runs = runs_df[runs_df['tags.run_name'].str.contains(\"LSTM_run\")]\n",
    "gru_conv = runs_df[runs_df['tags.run_name'].str.contains(\"GRU_Conv1\")]\n",
    "lstm_conv = runs_df[runs_df['tags.run_name'].str.contains(\"LSTM_Conv1\")]\n",
    "gru_runs = gru_runs.sort_values(by='params.num_layers')\n",
    "lstm_runs = lstm_runs.sort_values(by='params.num_layers')\n",
    "gru_conv = gru_conv.sort_values(by='params.num_layers')\n",
    "lstm_conv = lstm_conv.sort_values(by='params.num_layers')\n",
    "plt.plot(gru_runs['params.num_layers'], gru_runs['metrics.metric/Accuracy'], marker='o', label='GRU')\n",
    "plt.plot(lstm_runs['params.num_layers'], lstm_runs['metrics.metric/Accuracy'], marker='o', label='LSTM')\n",
    "plt.plot(gru_conv['params.num_layers'], gru_conv['metrics.metric/Accuracy'], marker='o', label='GRU Conv1D')\n",
    "plt.plot(lstm_conv['params.num_layers'], lstm_conv['metrics.metric/Accuracy'], marker='o', label='LSTM Conv1D')\n",
    "plt.xlabel('Number of Layers')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.xlim(0.8, 3.2)\n",
    "plt.title('GRU vs LSTM Validation Accuracy by Number of Layers')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to update the code above by changing the hyperparameters.\n",
    "    \n",
    "To discern between the changes, also modify the tag mlflow.set_tag(\"model\", \"new-tag-here\") where you add\n",
    "a new tag of your choice. This way you can keep the models apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.loop() # if you want to pick up training, loop will continue from the last epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio-example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
